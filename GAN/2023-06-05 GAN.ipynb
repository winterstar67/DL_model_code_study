{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "코드 블로그: https://tyami.github.io/deep%20learning/GAN-2-implementation-GAN/"
      ],
      "metadata": {
        "id": "1MfWjsJfUsIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.utils as utils\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "34Y6eWxTPzey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('numpy: ' + np.__version__)\n",
        "print('pandas: ' + pd.__version__)\n",
        "print('matplotlib: ' + matplotlib.__version__)\n",
        "print('numpy: ' + torch.__version__)\n",
        "print('numpy: ' + torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UGCU-Y0PzdB",
        "outputId": "1c0e5f8c-1fcb-4f0a-aefc-fcf6f0c9bde0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy: 1.22.4\n",
            "pandas: 1.5.3\n",
            "matplotlib: 3.7.1\n",
            "numpy: 2.0.1+cu118\n",
            "numpy: 0.15.2+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과 재현을 위한 Random seed"
      ],
      "metadata": {
        "id": "pgAgH5_RRFfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "manualSeed = 1\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzrm9MD6PzbG",
        "outputId": "d7a84d83-b629-491d-a8d6-9091d71752c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f85f1121a90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if is_cuda else 'cpu')\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tBsQ-aBPzY9",
        "outputId": "aab7d0aa-7f83-4c5e-962d-6f3d5dcf128c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KElAT2-4PzW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST 데이터 다운"
      ],
      "metadata": {
        "id": "-rqC4QTuRqEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "standardizer = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = 0, std = 1)\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(root='../data/', train=True, transform=standardizer, download = True)\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "vfYgtxqQPzU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "잘 불러와 지는지 이미지 시각화"
      ],
      "metadata": {
        "id": "OtYlwZARSXCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tc_imshow(img, lbl=\"\"):\n",
        "  if img.size(0) == 1:\n",
        "    plt.imshow(img.squeeze(), cmap='gray')\n",
        "  else:\n",
        "    plt.imshow(np.transpose(img, (1,2,0)))\n",
        "\n",
        "  plt.title(lbl)\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "6Y3rnhIEPzTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mini_batch_img, mini_batch_lbl = next(iter(train_data_loader))\n",
        "\n",
        "plt.figure(figsize=(4,8))\n",
        "for i in range(16):\n",
        "  plt.subplot(4,4,i+1)\n",
        "  tc_imshow(img=mini_batch_img[i],\n",
        "            lbl=train_data.classes[mini_batch_lbl[i].numpy()]\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "_oiG5no8Sn7e",
        "outputId": "0b819644-83d7-4780-a35f-742631912e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x800 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqMQAEGtTAWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤 노이즈를 샘플링할 분포 정의"
      ],
      "metadata": {
        "id": "cgkonGcLTaoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim_noise = 100\n",
        "\n",
        "def random_sample_z_space(batch_size=1, dim_noise=100):\n",
        "    return torch.randn(batch_size, dim_noise, device=device)"
      ],
      "metadata": {
        "id": "AyzmpianSoMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fKwLeNLtSoQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative model 정의"
      ],
      "metadata": {
        "id": "TCEg8tDYTiIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim_hidden = 256\n",
        "sz_output = 28\n",
        "num_channels = 1\n",
        "\n",
        "dim_output = sz_output**2\n",
        "img_shape = (num_channels, sz_output, sz_output)"
      ],
      "metadata": {
        "id": "lJYVePDvSoTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(dim_noise, dim_hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(dim_hidden, dim_hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(dim_hidden, dim_output),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  def forward(self,z):\n",
        "    img = self.model(z)\n",
        "    img = img.view(img.size(0), *img_shape) # 아마 (batch_size, color, width, height) 순의 shape일듯\n",
        "#    img_for_print = img.view(*img_shape)     만약 이미지 보고싶으면 이 주석 풀어서 보면 됨\n",
        "    return img#, img_for_print\n"
      ],
      "metadata": {
        "id": "9j-GLRgCSoWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤 노이즈 -> 생성 모델로부터 나온 데이터"
      ],
      "metadata": {
        "id": "b2wOAQvkbLuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = Generator()\n",
        "z = random_sample_z_space()\n",
        "z.to(device)\n",
        "G.to(device)\n",
        "img = G(z)\n",
        "utils.save_image(img[:25].cpu().detach(), \"./2-G(z).png\", nrow=5, normalize=True)\n",
        "# plt.imshow(np.transpose(img_for_print.cpu().detach(),(1,2,0)), cmap='gray')  # 이미지 보고싶으면 이 주석 풀어서 보면 됨"
      ],
      "metadata": {
        "id": "YsJ_IExgSoZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 아직 Generator의 학습이 되지 않아서, 노이즈로부터 Generator로 매핑을 해도 의미없는 output이 나온다."
      ],
      "metadata": {
        "id": "HRrk0rOrbRh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminative model D"
      ],
      "metadata": {
        "id": "cBPUJIMKbcRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(dim_output, dim_hidden), # generator의 output을 받아서 discriminate를 하는 것이기 때문에 Linear의 처음 input shape가 dim_output이다.\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(dim_hidden, dim_hidden),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Dropout(0.1),\n",
        "        nn.Linear(dim_hidden,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, img):\n",
        "    flat_img = img.view(img.size(0),-1) # 원래 (batch_size, color, width, height) 였는데, 여기서 color는 1이라 없는 셈 치면 width,height를 그냥 linear로 합친 꼴\n",
        "    check_validity = self.model(flat_img) # reshape 하고 model에 입력으로 넣는거\n",
        "\n",
        "    return check_validity"
      ],
      "metadata": {
        "id": "bt1yRzzISogh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator와 Discriminator 학습"
      ],
      "metadata": {
        "id": "ihUbJbendQif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.1 모델 선언"
      ],
      "metadata": {
        "id": "9oPzwqhWdWF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)"
      ],
      "metadata": {
        "id": "JN1r6Ba_SokR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.2 Loss function 과 Optimizer 선언"
      ],
      "metadata": {
        "id": "uWWZGSdIdY8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0002\n",
        "beta1 = 0.9 # beta는 Adam의 설정인데, 해당 내용 파악 필요"
      ],
      "metadata": {
        "id": "vJyjigbqSonR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_loss = nn.BCELoss()"
      ],
      "metadata": {
        "id": "9FAL6stfdgEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_G = optim.Adam(generator.parameters(), lr = lr, betas = (beta1, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr = lr, betas = (beta1, 0.999))\n"
      ],
      "metadata": {
        "id": "YNo928A5dgCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3 Train models"
      ],
      "metadata": {
        "id": "TdncdjTzgSWb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "epoch과 어느 시점에 image를 save할지 지정 (여기서는 batch_size 1000마다 저장한다.)"
      ],
      "metadata": {
        "id": "SYxF2N71gpQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 200\n",
        "interval_save_img = 1000"
      ],
      "metadata": {
        "id": "PUBGp_P2dgAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RAh3Bwb4hD6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tensor = torch.cuda.FloatTensor if is_cuda else torch.FloatTensor # 데이터 타입 정의인듯."
      ],
      "metadata": {
        "id": "RPumHDHHdf-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsXRMsTPP0Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Variable(Tensor(mini_batch_img.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "#Variable(imgs.type(Tensor))"
      ],
      "metadata": {
        "id": "ZocFIshfP0Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training 시작"
      ],
      "metadata": {
        "id": "QQIdIUNuhGwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.makedirs(\"./result/GAN/1-GAN\")"
      ],
      "metadata": {
        "id": "RcCos4IwQDPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "for idx_epoch in range(num_epochs):\n",
        "  for idx_batch, (imgs, _) in enumerate(train_data_loader):\n",
        "    real_ground_truth = Variable(Tensor(imgs.size(0),1).fill_(1.0), requires_grad=False) # 진짜 데이터는 label 1로 지정\n",
        "    fake_ground_truth = Variable(Tensor(imgs.size(0),1).fill_(0.0), requires_grad=False) # 가짜로 생성한 데이터는 label 0으로 지정\n",
        "\n",
        "    real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    z = random_sample_z_space(imgs.size(0))\n",
        "\n",
        "    gen_imgs = generator(z)\n",
        "    \n",
        "    loss_G = adversarial_loss(discriminator(gen_imgs), real_ground_truth)\n",
        "\n",
        "    loss_G.backward()\n",
        "    optimizer_G.step()\n",
        "\n",
        "    optimizer_D.zero_grad()\n",
        "    loss_real = adversarial_loss(discriminator(real_imgs), real_ground_truth)\n",
        "    loss_fake = adversarial_loss(discriminator(gen_imgs.detach()), fake_ground_truth)\n",
        "    loss_D = (loss_real + loss_fake)/2\n",
        "    \n",
        "    loss_D.backward()\n",
        "    optimizer_D.step()\n",
        "\n",
        "\n",
        "    losses.append([loss_G.item(), loss_D.item()])\n",
        "\n",
        "    # Print progress\n",
        "    if idx_batch % 10 == 0:\n",
        "        print(\"[Epoch {}/{}] [Batch {}/{}] loss_G: {:.6f}, loss_D: {:.6f}\".format(idx_epoch, num_epochs,\n",
        "                                                                                  idx_batch, len(train_data_loader),\n",
        "                                                                                  loss_G, loss_D))\n",
        "\n",
        "    batches_done = idx_epoch * len(train_data_loader) + idx_batch\n",
        "    if batches_done % interval_save_img == 0:\n",
        "        utils.save_image(gen_imgs.data[:25], \"./result/GAN/1-GAN/3-{}.png\".format(batches_done), nrow=5, normalize=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gxfh84Wvdf6b",
        "outputId": "0dac25f9-ae36-4a22-d3b3-985d34dc79b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "[Epoch 138/200] [Batch 560/938] loss_G: 2.710628, loss_D: 0.227972\n",
            "[Epoch 138/200] [Batch 570/938] loss_G: 3.265527, loss_D: 0.232800\n",
            "[Epoch 138/200] [Batch 580/938] loss_G: 3.032933, loss_D: 0.149995\n",
            "[Epoch 138/200] [Batch 590/938] loss_G: 2.865847, loss_D: 0.198826\n",
            "[Epoch 138/200] [Batch 600/938] loss_G: 3.007118, loss_D: 0.175332\n",
            "[Epoch 138/200] [Batch 610/938] loss_G: 2.759622, loss_D: 0.183408\n",
            "[Epoch 138/200] [Batch 620/938] loss_G: 3.403048, loss_D: 0.223142\n",
            "[Epoch 138/200] [Batch 630/938] loss_G: 2.743292, loss_D: 0.298534\n",
            "[Epoch 138/200] [Batch 640/938] loss_G: 2.812739, loss_D: 0.218135\n",
            "[Epoch 138/200] [Batch 650/938] loss_G: 2.982703, loss_D: 0.175029\n",
            "[Epoch 138/200] [Batch 660/938] loss_G: 3.030822, loss_D: 0.211547\n",
            "[Epoch 138/200] [Batch 670/938] loss_G: 3.361161, loss_D: 0.180678\n",
            "[Epoch 138/200] [Batch 680/938] loss_G: 2.914903, loss_D: 0.219517\n",
            "[Epoch 138/200] [Batch 690/938] loss_G: 2.660020, loss_D: 0.271265\n",
            "[Epoch 138/200] [Batch 700/938] loss_G: 2.965844, loss_D: 0.197021\n",
            "[Epoch 138/200] [Batch 710/938] loss_G: 2.674024, loss_D: 0.273302\n",
            "[Epoch 138/200] [Batch 720/938] loss_G: 3.088837, loss_D: 0.268829\n",
            "[Epoch 138/200] [Batch 730/938] loss_G: 2.807591, loss_D: 0.259871\n",
            "[Epoch 138/200] [Batch 740/938] loss_G: 2.411479, loss_D: 0.277870\n",
            "[Epoch 138/200] [Batch 750/938] loss_G: 3.508056, loss_D: 0.222788\n",
            "[Epoch 138/200] [Batch 760/938] loss_G: 2.975477, loss_D: 0.227581\n",
            "[Epoch 138/200] [Batch 770/938] loss_G: 2.875175, loss_D: 0.227409\n",
            "[Epoch 138/200] [Batch 780/938] loss_G: 3.097709, loss_D: 0.176564\n",
            "[Epoch 138/200] [Batch 790/938] loss_G: 2.853993, loss_D: 0.265411\n",
            "[Epoch 138/200] [Batch 800/938] loss_G: 3.039954, loss_D: 0.152233\n",
            "[Epoch 138/200] [Batch 810/938] loss_G: 2.905775, loss_D: 0.232447\n",
            "[Epoch 138/200] [Batch 820/938] loss_G: 2.760725, loss_D: 0.271124\n",
            "[Epoch 138/200] [Batch 830/938] loss_G: 3.084004, loss_D: 0.203035\n",
            "[Epoch 138/200] [Batch 840/938] loss_G: 2.902490, loss_D: 0.164136\n",
            "[Epoch 138/200] [Batch 850/938] loss_G: 3.054810, loss_D: 0.194580\n",
            "[Epoch 138/200] [Batch 860/938] loss_G: 3.277196, loss_D: 0.196697\n",
            "[Epoch 138/200] [Batch 870/938] loss_G: 3.183048, loss_D: 0.182396\n",
            "[Epoch 138/200] [Batch 880/938] loss_G: 3.020787, loss_D: 0.182170\n",
            "[Epoch 138/200] [Batch 890/938] loss_G: 2.825071, loss_D: 0.314083\n",
            "[Epoch 138/200] [Batch 900/938] loss_G: 3.042570, loss_D: 0.252877\n",
            "[Epoch 138/200] [Batch 910/938] loss_G: 3.395844, loss_D: 0.171505\n",
            "[Epoch 138/200] [Batch 920/938] loss_G: 2.967854, loss_D: 0.253913\n",
            "[Epoch 138/200] [Batch 930/938] loss_G: 2.723938, loss_D: 0.189502\n",
            "[Epoch 139/200] [Batch 0/938] loss_G: 2.558082, loss_D: 0.201656\n",
            "[Epoch 139/200] [Batch 10/938] loss_G: 2.850181, loss_D: 0.271735\n",
            "[Epoch 139/200] [Batch 20/938] loss_G: 2.757666, loss_D: 0.146448\n",
            "[Epoch 139/200] [Batch 30/938] loss_G: 3.122489, loss_D: 0.247759\n",
            "[Epoch 139/200] [Batch 40/938] loss_G: 3.051985, loss_D: 0.175314\n",
            "[Epoch 139/200] [Batch 50/938] loss_G: 3.046985, loss_D: 0.178311\n",
            "[Epoch 139/200] [Batch 60/938] loss_G: 3.327860, loss_D: 0.217143\n",
            "[Epoch 139/200] [Batch 70/938] loss_G: 2.754959, loss_D: 0.217541\n",
            "[Epoch 139/200] [Batch 80/938] loss_G: 2.930633, loss_D: 0.228649\n",
            "[Epoch 139/200] [Batch 90/938] loss_G: 2.995663, loss_D: 0.154275\n",
            "[Epoch 139/200] [Batch 100/938] loss_G: 3.024075, loss_D: 0.238117\n",
            "[Epoch 139/200] [Batch 110/938] loss_G: 2.908595, loss_D: 0.195584\n",
            "[Epoch 139/200] [Batch 120/938] loss_G: 3.145906, loss_D: 0.284121\n",
            "[Epoch 139/200] [Batch 130/938] loss_G: 3.031515, loss_D: 0.119623\n",
            "[Epoch 139/200] [Batch 140/938] loss_G: 2.479493, loss_D: 0.267681\n",
            "[Epoch 139/200] [Batch 150/938] loss_G: 3.116418, loss_D: 0.161253\n",
            "[Epoch 139/200] [Batch 160/938] loss_G: 3.048206, loss_D: 0.183132\n",
            "[Epoch 139/200] [Batch 170/938] loss_G: 2.785969, loss_D: 0.306837\n",
            "[Epoch 139/200] [Batch 180/938] loss_G: 3.363119, loss_D: 0.186839\n",
            "[Epoch 139/200] [Batch 190/938] loss_G: 3.113491, loss_D: 0.225459\n",
            "[Epoch 139/200] [Batch 200/938] loss_G: 3.261867, loss_D: 0.198428\n",
            "[Epoch 139/200] [Batch 210/938] loss_G: 3.356042, loss_D: 0.179265\n",
            "[Epoch 139/200] [Batch 220/938] loss_G: 2.579533, loss_D: 0.256285\n",
            "[Epoch 139/200] [Batch 230/938] loss_G: 2.860210, loss_D: 0.166720\n",
            "[Epoch 139/200] [Batch 240/938] loss_G: 3.017156, loss_D: 0.219163\n",
            "[Epoch 139/200] [Batch 250/938] loss_G: 3.162956, loss_D: 0.158331\n",
            "[Epoch 139/200] [Batch 260/938] loss_G: 3.067955, loss_D: 0.228672\n",
            "[Epoch 139/200] [Batch 270/938] loss_G: 2.896993, loss_D: 0.153973\n",
            "[Epoch 139/200] [Batch 280/938] loss_G: 3.343985, loss_D: 0.243908\n",
            "[Epoch 139/200] [Batch 290/938] loss_G: 3.016973, loss_D: 0.184084\n",
            "[Epoch 139/200] [Batch 300/938] loss_G: 3.162841, loss_D: 0.110295\n",
            "[Epoch 139/200] [Batch 310/938] loss_G: 3.192941, loss_D: 0.193632\n",
            "[Epoch 139/200] [Batch 320/938] loss_G: 2.965536, loss_D: 0.202321\n",
            "[Epoch 139/200] [Batch 330/938] loss_G: 2.870573, loss_D: 0.143672\n",
            "[Epoch 139/200] [Batch 340/938] loss_G: 2.744641, loss_D: 0.172522\n",
            "[Epoch 139/200] [Batch 350/938] loss_G: 2.830314, loss_D: 0.235489\n",
            "[Epoch 139/200] [Batch 360/938] loss_G: 2.859679, loss_D: 0.226102\n",
            "[Epoch 139/200] [Batch 370/938] loss_G: 2.940684, loss_D: 0.181820\n",
            "[Epoch 139/200] [Batch 380/938] loss_G: 2.766744, loss_D: 0.312133\n",
            "[Epoch 139/200] [Batch 390/938] loss_G: 3.013188, loss_D: 0.202204\n",
            "[Epoch 139/200] [Batch 400/938] loss_G: 3.037022, loss_D: 0.276919\n",
            "[Epoch 139/200] [Batch 410/938] loss_G: 3.106323, loss_D: 0.236997\n",
            "[Epoch 139/200] [Batch 420/938] loss_G: 3.093452, loss_D: 0.219731\n",
            "[Epoch 139/200] [Batch 430/938] loss_G: 3.224958, loss_D: 0.209239\n",
            "[Epoch 139/200] [Batch 440/938] loss_G: 2.732310, loss_D: 0.203350\n",
            "[Epoch 139/200] [Batch 450/938] loss_G: 2.830205, loss_D: 0.267992\n",
            "[Epoch 139/200] [Batch 460/938] loss_G: 2.709925, loss_D: 0.271282\n",
            "[Epoch 139/200] [Batch 470/938] loss_G: 3.082973, loss_D: 0.206110\n",
            "[Epoch 139/200] [Batch 480/938] loss_G: 3.256445, loss_D: 0.180309\n",
            "[Epoch 139/200] [Batch 490/938] loss_G: 3.025628, loss_D: 0.139657\n",
            "[Epoch 139/200] [Batch 500/938] loss_G: 2.813005, loss_D: 0.179622\n",
            "[Epoch 139/200] [Batch 510/938] loss_G: 3.214880, loss_D: 0.199666\n",
            "[Epoch 139/200] [Batch 520/938] loss_G: 2.632229, loss_D: 0.200928\n",
            "[Epoch 139/200] [Batch 530/938] loss_G: 2.690998, loss_D: 0.297127\n",
            "[Epoch 139/200] [Batch 540/938] loss_G: 3.025160, loss_D: 0.214009\n",
            "[Epoch 139/200] [Batch 550/938] loss_G: 3.373727, loss_D: 0.164717\n",
            "[Epoch 139/200] [Batch 560/938] loss_G: 3.251597, loss_D: 0.280522\n",
            "[Epoch 139/200] [Batch 570/938] loss_G: 2.657236, loss_D: 0.208736\n",
            "[Epoch 139/200] [Batch 580/938] loss_G: 3.027782, loss_D: 0.250732\n",
            "[Epoch 139/200] [Batch 590/938] loss_G: 2.752635, loss_D: 0.279736\n",
            "[Epoch 139/200] [Batch 600/938] loss_G: 2.891792, loss_D: 0.203083\n",
            "[Epoch 139/200] [Batch 610/938] loss_G: 3.112940, loss_D: 0.118267\n",
            "[Epoch 139/200] [Batch 620/938] loss_G: 2.722662, loss_D: 0.271999\n",
            "[Epoch 139/200] [Batch 630/938] loss_G: 2.798978, loss_D: 0.174846\n",
            "[Epoch 139/200] [Batch 640/938] loss_G: 3.312255, loss_D: 0.179901\n",
            "[Epoch 139/200] [Batch 650/938] loss_G: 3.079184, loss_D: 0.239562\n",
            "[Epoch 139/200] [Batch 660/938] loss_G: 2.853523, loss_D: 0.215452\n",
            "[Epoch 139/200] [Batch 670/938] loss_G: 2.723360, loss_D: 0.283083\n",
            "[Epoch 139/200] [Batch 680/938] loss_G: 2.992826, loss_D: 0.204112\n",
            "[Epoch 139/200] [Batch 690/938] loss_G: 3.174364, loss_D: 0.212379\n",
            "[Epoch 139/200] [Batch 700/938] loss_G: 3.113524, loss_D: 0.162059\n",
            "[Epoch 139/200] [Batch 710/938] loss_G: 3.110786, loss_D: 0.219934\n",
            "[Epoch 139/200] [Batch 720/938] loss_G: 3.262091, loss_D: 0.172646\n",
            "[Epoch 139/200] [Batch 730/938] loss_G: 2.842562, loss_D: 0.210535\n",
            "[Epoch 139/200] [Batch 740/938] loss_G: 3.251766, loss_D: 0.185920\n",
            "[Epoch 139/200] [Batch 750/938] loss_G: 2.892785, loss_D: 0.246527\n",
            "[Epoch 139/200] [Batch 760/938] loss_G: 2.818149, loss_D: 0.202186\n",
            "[Epoch 139/200] [Batch 770/938] loss_G: 2.667202, loss_D: 0.196433\n",
            "[Epoch 139/200] [Batch 780/938] loss_G: 3.042804, loss_D: 0.223754\n",
            "[Epoch 139/200] [Batch 790/938] loss_G: 3.604712, loss_D: 0.222676\n",
            "[Epoch 139/200] [Batch 800/938] loss_G: 3.316810, loss_D: 0.177012\n",
            "[Epoch 139/200] [Batch 810/938] loss_G: 2.958524, loss_D: 0.225517\n",
            "[Epoch 139/200] [Batch 820/938] loss_G: 2.630483, loss_D: 0.193547\n",
            "[Epoch 139/200] [Batch 830/938] loss_G: 3.441774, loss_D: 0.214256\n",
            "[Epoch 139/200] [Batch 840/938] loss_G: 2.981170, loss_D: 0.254136\n",
            "[Epoch 139/200] [Batch 850/938] loss_G: 2.962295, loss_D: 0.172858\n",
            "[Epoch 139/200] [Batch 860/938] loss_G: 2.736262, loss_D: 0.268714\n",
            "[Epoch 139/200] [Batch 870/938] loss_G: 3.374156, loss_D: 0.225145\n",
            "[Epoch 139/200] [Batch 880/938] loss_G: 3.054075, loss_D: 0.202851\n",
            "[Epoch 139/200] [Batch 890/938] loss_G: 2.845581, loss_D: 0.184995\n",
            "[Epoch 139/200] [Batch 900/938] loss_G: 3.452303, loss_D: 0.193052\n",
            "[Epoch 139/200] [Batch 910/938] loss_G: 3.120382, loss_D: 0.141606\n",
            "[Epoch 139/200] [Batch 920/938] loss_G: 3.240634, loss_D: 0.271469\n",
            "[Epoch 139/200] [Batch 930/938] loss_G: 3.171273, loss_D: 0.151801\n",
            "[Epoch 140/200] [Batch 0/938] loss_G: 2.911717, loss_D: 0.283971\n",
            "[Epoch 140/200] [Batch 10/938] loss_G: 3.040522, loss_D: 0.264225\n",
            "[Epoch 140/200] [Batch 20/938] loss_G: 3.161301, loss_D: 0.128156\n",
            "[Epoch 140/200] [Batch 30/938] loss_G: 2.728617, loss_D: 0.150020\n",
            "[Epoch 140/200] [Batch 40/938] loss_G: 3.123527, loss_D: 0.125102\n",
            "[Epoch 140/200] [Batch 50/938] loss_G: 3.167147, loss_D: 0.134423\n",
            "[Epoch 140/200] [Batch 60/938] loss_G: 3.013939, loss_D: 0.153943\n",
            "[Epoch 140/200] [Batch 70/938] loss_G: 3.285712, loss_D: 0.261601\n",
            "[Epoch 140/200] [Batch 80/938] loss_G: 3.055397, loss_D: 0.256814\n",
            "[Epoch 140/200] [Batch 90/938] loss_G: 2.980135, loss_D: 0.198052\n",
            "[Epoch 140/200] [Batch 100/938] loss_G: 2.821189, loss_D: 0.293023\n",
            "[Epoch 140/200] [Batch 110/938] loss_G: 3.043906, loss_D: 0.222410\n",
            "[Epoch 140/200] [Batch 120/938] loss_G: 2.879795, loss_D: 0.273588\n",
            "[Epoch 140/200] [Batch 130/938] loss_G: 3.090293, loss_D: 0.250034\n",
            "[Epoch 140/200] [Batch 140/938] loss_G: 2.798227, loss_D: 0.267957\n",
            "[Epoch 140/200] [Batch 150/938] loss_G: 3.202482, loss_D: 0.211772\n",
            "[Epoch 140/200] [Batch 160/938] loss_G: 2.668891, loss_D: 0.305883\n",
            "[Epoch 140/200] [Batch 170/938] loss_G: 3.256895, loss_D: 0.219717\n",
            "[Epoch 140/200] [Batch 180/938] loss_G: 2.904671, loss_D: 0.205425\n",
            "[Epoch 140/200] [Batch 190/938] loss_G: 3.129461, loss_D: 0.153711\n",
            "[Epoch 140/200] [Batch 200/938] loss_G: 3.154605, loss_D: 0.225936\n",
            "[Epoch 140/200] [Batch 210/938] loss_G: 2.907712, loss_D: 0.234936\n",
            "[Epoch 140/200] [Batch 220/938] loss_G: 2.832845, loss_D: 0.233913\n",
            "[Epoch 140/200] [Batch 230/938] loss_G: 2.881705, loss_D: 0.264965\n",
            "[Epoch 140/200] [Batch 240/938] loss_G: 2.467883, loss_D: 0.166250\n",
            "[Epoch 140/200] [Batch 250/938] loss_G: 3.013027, loss_D: 0.171356\n",
            "[Epoch 140/200] [Batch 260/938] loss_G: 3.090552, loss_D: 0.196182\n",
            "[Epoch 140/200] [Batch 270/938] loss_G: 3.246525, loss_D: 0.176793\n",
            "[Epoch 140/200] [Batch 280/938] loss_G: 2.895522, loss_D: 0.227034\n",
            "[Epoch 140/200] [Batch 290/938] loss_G: 2.971738, loss_D: 0.205589\n",
            "[Epoch 140/200] [Batch 300/938] loss_G: 2.912474, loss_D: 0.236173\n",
            "[Epoch 140/200] [Batch 310/938] loss_G: 3.286603, loss_D: 0.177614\n",
            "[Epoch 140/200] [Batch 320/938] loss_G: 2.813426, loss_D: 0.294130\n",
            "[Epoch 140/200] [Batch 330/938] loss_G: 2.826972, loss_D: 0.208828\n",
            "[Epoch 140/200] [Batch 340/938] loss_G: 3.215139, loss_D: 0.176918\n",
            "[Epoch 140/200] [Batch 350/938] loss_G: 3.444704, loss_D: 0.209732\n",
            "[Epoch 140/200] [Batch 360/938] loss_G: 2.964557, loss_D: 0.234001\n",
            "[Epoch 140/200] [Batch 370/938] loss_G: 2.912805, loss_D: 0.219064\n",
            "[Epoch 140/200] [Batch 380/938] loss_G: 3.017492, loss_D: 0.199456\n",
            "[Epoch 140/200] [Batch 390/938] loss_G: 2.663591, loss_D: 0.260883\n",
            "[Epoch 140/200] [Batch 400/938] loss_G: 2.827995, loss_D: 0.183588\n",
            "[Epoch 140/200] [Batch 410/938] loss_G: 3.014372, loss_D: 0.259820\n",
            "[Epoch 140/200] [Batch 420/938] loss_G: 2.910841, loss_D: 0.153086\n",
            "[Epoch 140/200] [Batch 430/938] loss_G: 3.109785, loss_D: 0.258397\n",
            "[Epoch 140/200] [Batch 440/938] loss_G: 3.110894, loss_D: 0.284518\n",
            "[Epoch 140/200] [Batch 450/938] loss_G: 2.788554, loss_D: 0.273002\n",
            "[Epoch 140/200] [Batch 460/938] loss_G: 2.798662, loss_D: 0.278648\n",
            "[Epoch 140/200] [Batch 470/938] loss_G: 3.078822, loss_D: 0.207201\n",
            "[Epoch 140/200] [Batch 480/938] loss_G: 3.137341, loss_D: 0.211385\n",
            "[Epoch 140/200] [Batch 490/938] loss_G: 3.060393, loss_D: 0.160985\n",
            "[Epoch 140/200] [Batch 500/938] loss_G: 3.063295, loss_D: 0.275408\n",
            "[Epoch 140/200] [Batch 510/938] loss_G: 2.858923, loss_D: 0.259169\n",
            "[Epoch 140/200] [Batch 520/938] loss_G: 3.124596, loss_D: 0.257963\n",
            "[Epoch 140/200] [Batch 530/938] loss_G: 2.959461, loss_D: 0.290872\n",
            "[Epoch 140/200] [Batch 540/938] loss_G: 2.744810, loss_D: 0.244629\n",
            "[Epoch 140/200] [Batch 550/938] loss_G: 2.847520, loss_D: 0.154312\n",
            "[Epoch 140/200] [Batch 560/938] loss_G: 3.018291, loss_D: 0.212505\n",
            "[Epoch 140/200] [Batch 570/938] loss_G: 3.173928, loss_D: 0.240501\n",
            "[Epoch 140/200] [Batch 580/938] loss_G: 2.893355, loss_D: 0.268863\n",
            "[Epoch 140/200] [Batch 590/938] loss_G: 2.993804, loss_D: 0.185330\n",
            "[Epoch 140/200] [Batch 600/938] loss_G: 3.082843, loss_D: 0.215510\n",
            "[Epoch 140/200] [Batch 610/938] loss_G: 3.161959, loss_D: 0.176961\n",
            "[Epoch 140/200] [Batch 620/938] loss_G: 3.100160, loss_D: 0.206274\n",
            "[Epoch 140/200] [Batch 630/938] loss_G: 2.741509, loss_D: 0.137598\n",
            "[Epoch 140/200] [Batch 640/938] loss_G: 2.803623, loss_D: 0.213200\n",
            "[Epoch 140/200] [Batch 650/938] loss_G: 3.051603, loss_D: 0.209673\n",
            "[Epoch 140/200] [Batch 660/938] loss_G: 2.805165, loss_D: 0.255886\n",
            "[Epoch 140/200] [Batch 670/938] loss_G: 2.848137, loss_D: 0.171179\n",
            "[Epoch 140/200] [Batch 680/938] loss_G: 3.035469, loss_D: 0.181478\n",
            "[Epoch 140/200] [Batch 690/938] loss_G: 3.041606, loss_D: 0.246535\n",
            "[Epoch 140/200] [Batch 700/938] loss_G: 3.161337, loss_D: 0.251482\n",
            "[Epoch 140/200] [Batch 710/938] loss_G: 3.003874, loss_D: 0.185386\n",
            "[Epoch 140/200] [Batch 720/938] loss_G: 3.014864, loss_D: 0.206431\n",
            "[Epoch 140/200] [Batch 730/938] loss_G: 3.091521, loss_D: 0.224012\n",
            "[Epoch 140/200] [Batch 740/938] loss_G: 2.994087, loss_D: 0.200775\n",
            "[Epoch 140/200] [Batch 750/938] loss_G: 3.074612, loss_D: 0.154776\n",
            "[Epoch 140/200] [Batch 760/938] loss_G: 2.494648, loss_D: 0.237432\n",
            "[Epoch 140/200] [Batch 770/938] loss_G: 3.000818, loss_D: 0.134417\n",
            "[Epoch 140/200] [Batch 780/938] loss_G: 2.734874, loss_D: 0.142837\n",
            "[Epoch 140/200] [Batch 790/938] loss_G: 3.134612, loss_D: 0.243557\n",
            "[Epoch 140/200] [Batch 800/938] loss_G: 2.962605, loss_D: 0.181361\n",
            "[Epoch 140/200] [Batch 810/938] loss_G: 3.068402, loss_D: 0.289238\n",
            "[Epoch 140/200] [Batch 820/938] loss_G: 2.710261, loss_D: 0.349551\n",
            "[Epoch 140/200] [Batch 830/938] loss_G: 3.137717, loss_D: 0.203325\n",
            "[Epoch 140/200] [Batch 840/938] loss_G: 2.815370, loss_D: 0.226652\n",
            "[Epoch 140/200] [Batch 850/938] loss_G: 2.868903, loss_D: 0.217336\n",
            "[Epoch 140/200] [Batch 860/938] loss_G: 2.614269, loss_D: 0.174040\n",
            "[Epoch 140/200] [Batch 870/938] loss_G: 3.213175, loss_D: 0.226643\n",
            "[Epoch 140/200] [Batch 880/938] loss_G: 2.723708, loss_D: 0.228783\n",
            "[Epoch 140/200] [Batch 890/938] loss_G: 3.126627, loss_D: 0.177391\n",
            "[Epoch 140/200] [Batch 900/938] loss_G: 2.788687, loss_D: 0.223703\n",
            "[Epoch 140/200] [Batch 910/938] loss_G: 2.646832, loss_D: 0.278161\n",
            "[Epoch 140/200] [Batch 920/938] loss_G: 2.782763, loss_D: 0.209228\n",
            "[Epoch 140/200] [Batch 930/938] loss_G: 2.584832, loss_D: 0.266865\n",
            "[Epoch 141/200] [Batch 0/938] loss_G: 2.928247, loss_D: 0.232940\n",
            "[Epoch 141/200] [Batch 10/938] loss_G: 3.130675, loss_D: 0.255878\n",
            "[Epoch 141/200] [Batch 20/938] loss_G: 3.169654, loss_D: 0.208056\n",
            "[Epoch 141/200] [Batch 30/938] loss_G: 3.185056, loss_D: 0.219561\n",
            "[Epoch 141/200] [Batch 40/938] loss_G: 3.160871, loss_D: 0.151513\n",
            "[Epoch 141/200] [Batch 50/938] loss_G: 3.502168, loss_D: 0.120467\n",
            "[Epoch 141/200] [Batch 60/938] loss_G: 3.164737, loss_D: 0.250489\n",
            "[Epoch 141/200] [Batch 70/938] loss_G: 3.082090, loss_D: 0.239908\n",
            "[Epoch 141/200] [Batch 80/938] loss_G: 3.344690, loss_D: 0.208967\n",
            "[Epoch 141/200] [Batch 90/938] loss_G: 2.915202, loss_D: 0.161740\n",
            "[Epoch 141/200] [Batch 100/938] loss_G: 2.888550, loss_D: 0.263896\n",
            "[Epoch 141/200] [Batch 110/938] loss_G: 3.073953, loss_D: 0.215584\n",
            "[Epoch 141/200] [Batch 120/938] loss_G: 3.243920, loss_D: 0.239899\n",
            "[Epoch 141/200] [Batch 130/938] loss_G: 2.963365, loss_D: 0.235827\n",
            "[Epoch 141/200] [Batch 140/938] loss_G: 2.856550, loss_D: 0.242543\n",
            "[Epoch 141/200] [Batch 150/938] loss_G: 2.866022, loss_D: 0.149187\n",
            "[Epoch 141/200] [Batch 160/938] loss_G: 3.179673, loss_D: 0.230789\n",
            "[Epoch 141/200] [Batch 170/938] loss_G: 2.994325, loss_D: 0.179685\n",
            "[Epoch 141/200] [Batch 180/938] loss_G: 2.970124, loss_D: 0.217594\n",
            "[Epoch 141/200] [Batch 190/938] loss_G: 2.531758, loss_D: 0.209687\n",
            "[Epoch 141/200] [Batch 200/938] loss_G: 2.706728, loss_D: 0.262461\n",
            "[Epoch 141/200] [Batch 210/938] loss_G: 3.005653, loss_D: 0.226836\n",
            "[Epoch 141/200] [Batch 220/938] loss_G: 2.928197, loss_D: 0.324335\n",
            "[Epoch 141/200] [Batch 230/938] loss_G: 3.041797, loss_D: 0.276809\n",
            "[Epoch 141/200] [Batch 240/938] loss_G: 2.617011, loss_D: 0.206347\n",
            "[Epoch 141/200] [Batch 250/938] loss_G: 2.690882, loss_D: 0.173004\n",
            "[Epoch 141/200] [Batch 260/938] loss_G: 3.016007, loss_D: 0.210381\n",
            "[Epoch 141/200] [Batch 270/938] loss_G: 2.871293, loss_D: 0.217606\n",
            "[Epoch 141/200] [Batch 280/938] loss_G: 2.618045, loss_D: 0.264003\n",
            "[Epoch 141/200] [Batch 290/938] loss_G: 2.747927, loss_D: 0.263861\n",
            "[Epoch 141/200] [Batch 300/938] loss_G: 2.908058, loss_D: 0.176646\n",
            "[Epoch 141/200] [Batch 310/938] loss_G: 2.815662, loss_D: 0.160099\n",
            "[Epoch 141/200] [Batch 320/938] loss_G: 3.055815, loss_D: 0.154577\n",
            "[Epoch 141/200] [Batch 330/938] loss_G: 3.162069, loss_D: 0.240924\n",
            "[Epoch 141/200] [Batch 340/938] loss_G: 2.742554, loss_D: 0.192026\n",
            "[Epoch 141/200] [Batch 350/938] loss_G: 2.881177, loss_D: 0.216331\n",
            "[Epoch 141/200] [Batch 360/938] loss_G: 3.212283, loss_D: 0.204740\n",
            "[Epoch 141/200] [Batch 370/938] loss_G: 2.747429, loss_D: 0.176455\n",
            "[Epoch 141/200] [Batch 380/938] loss_G: 3.028551, loss_D: 0.240081\n",
            "[Epoch 141/200] [Batch 390/938] loss_G: 2.784693, loss_D: 0.233983\n",
            "[Epoch 141/200] [Batch 400/938] loss_G: 3.118732, loss_D: 0.169635\n",
            "[Epoch 141/200] [Batch 410/938] loss_G: 2.886093, loss_D: 0.233941\n",
            "[Epoch 141/200] [Batch 420/938] loss_G: 2.923993, loss_D: 0.201011\n",
            "[Epoch 141/200] [Batch 430/938] loss_G: 2.699794, loss_D: 0.225325\n",
            "[Epoch 141/200] [Batch 440/938] loss_G: 3.151901, loss_D: 0.232628\n",
            "[Epoch 141/200] [Batch 450/938] loss_G: 2.622287, loss_D: 0.215040\n",
            "[Epoch 141/200] [Batch 460/938] loss_G: 2.721132, loss_D: 0.277896\n",
            "[Epoch 141/200] [Batch 470/938] loss_G: 3.093792, loss_D: 0.182666\n",
            "[Epoch 141/200] [Batch 480/938] loss_G: 3.356841, loss_D: 0.168364\n",
            "[Epoch 141/200] [Batch 490/938] loss_G: 3.199957, loss_D: 0.119137\n",
            "[Epoch 141/200] [Batch 500/938] loss_G: 2.764540, loss_D: 0.178567\n",
            "[Epoch 141/200] [Batch 510/938] loss_G: 2.945201, loss_D: 0.133690\n",
            "[Epoch 141/200] [Batch 520/938] loss_G: 2.732360, loss_D: 0.220124\n",
            "[Epoch 141/200] [Batch 530/938] loss_G: 2.765092, loss_D: 0.193880\n",
            "[Epoch 141/200] [Batch 540/938] loss_G: 3.198225, loss_D: 0.136630\n",
            "[Epoch 141/200] [Batch 550/938] loss_G: 2.673140, loss_D: 0.229360\n",
            "[Epoch 141/200] [Batch 560/938] loss_G: 3.157747, loss_D: 0.194838\n",
            "[Epoch 141/200] [Batch 570/938] loss_G: 3.123853, loss_D: 0.176047\n",
            "[Epoch 141/200] [Batch 580/938] loss_G: 3.028626, loss_D: 0.215757\n",
            "[Epoch 141/200] [Batch 590/938] loss_G: 3.035728, loss_D: 0.218934\n",
            "[Epoch 141/200] [Batch 600/938] loss_G: 2.861444, loss_D: 0.322779\n",
            "[Epoch 141/200] [Batch 610/938] loss_G: 2.993967, loss_D: 0.142603\n",
            "[Epoch 141/200] [Batch 620/938] loss_G: 2.741896, loss_D: 0.242955\n",
            "[Epoch 141/200] [Batch 630/938] loss_G: 2.556092, loss_D: 0.267004\n",
            "[Epoch 141/200] [Batch 640/938] loss_G: 3.403689, loss_D: 0.180062\n",
            "[Epoch 141/200] [Batch 650/938] loss_G: 2.879296, loss_D: 0.144065\n",
            "[Epoch 141/200] [Batch 660/938] loss_G: 2.760566, loss_D: 0.186750\n",
            "[Epoch 141/200] [Batch 670/938] loss_G: 3.074569, loss_D: 0.211849\n",
            "[Epoch 141/200] [Batch 680/938] loss_G: 2.635519, loss_D: 0.327265\n",
            "[Epoch 141/200] [Batch 690/938] loss_G: 2.951706, loss_D: 0.167519\n",
            "[Epoch 141/200] [Batch 700/938] loss_G: 3.023943, loss_D: 0.228043\n",
            "[Epoch 141/200] [Batch 710/938] loss_G: 2.968808, loss_D: 0.210075\n",
            "[Epoch 141/200] [Batch 720/938] loss_G: 2.858111, loss_D: 0.269323\n",
            "[Epoch 141/200] [Batch 730/938] loss_G: 3.109400, loss_D: 0.147677\n",
            "[Epoch 141/200] [Batch 740/938] loss_G: 2.745407, loss_D: 0.207546\n",
            "[Epoch 141/200] [Batch 750/938] loss_G: 2.980700, loss_D: 0.218681\n",
            "[Epoch 141/200] [Batch 760/938] loss_G: 2.968894, loss_D: 0.355281\n",
            "[Epoch 141/200] [Batch 770/938] loss_G: 2.961031, loss_D: 0.229501\n",
            "[Epoch 141/200] [Batch 780/938] loss_G: 3.210098, loss_D: 0.116810\n",
            "[Epoch 141/200] [Batch 790/938] loss_G: 2.807557, loss_D: 0.246787\n",
            "[Epoch 141/200] [Batch 800/938] loss_G: 3.297127, loss_D: 0.101526\n",
            "[Epoch 141/200] [Batch 810/938] loss_G: 3.116361, loss_D: 0.202846\n",
            "[Epoch 141/200] [Batch 820/938] loss_G: 2.679291, loss_D: 0.269228\n",
            "[Epoch 141/200] [Batch 830/938] loss_G: 2.824801, loss_D: 0.247490\n",
            "[Epoch 141/200] [Batch 840/938] loss_G: 2.980546, loss_D: 0.197724\n",
            "[Epoch 141/200] [Batch 850/938] loss_G: 2.983684, loss_D: 0.197497\n",
            "[Epoch 141/200] [Batch 860/938] loss_G: 3.190450, loss_D: 0.245786\n",
            "[Epoch 141/200] [Batch 870/938] loss_G: 2.731663, loss_D: 0.262076\n",
            "[Epoch 141/200] [Batch 880/938] loss_G: 3.363309, loss_D: 0.166871\n",
            "[Epoch 141/200] [Batch 890/938] loss_G: 2.725020, loss_D: 0.197776\n",
            "[Epoch 141/200] [Batch 900/938] loss_G: 2.814003, loss_D: 0.193385\n",
            "[Epoch 141/200] [Batch 910/938] loss_G: 2.922976, loss_D: 0.127251\n",
            "[Epoch 141/200] [Batch 920/938] loss_G: 3.075697, loss_D: 0.171440\n",
            "[Epoch 141/200] [Batch 930/938] loss_G: 3.132311, loss_D: 0.375140\n",
            "[Epoch 142/200] [Batch 0/938] loss_G: 2.899187, loss_D: 0.201964\n",
            "[Epoch 142/200] [Batch 10/938] loss_G: 3.077111, loss_D: 0.201349\n",
            "[Epoch 142/200] [Batch 20/938] loss_G: 3.034647, loss_D: 0.134283\n",
            "[Epoch 142/200] [Batch 30/938] loss_G: 2.963143, loss_D: 0.186874\n",
            "[Epoch 142/200] [Batch 40/938] loss_G: 2.956257, loss_D: 0.199099\n",
            "[Epoch 142/200] [Batch 50/938] loss_G: 2.915674, loss_D: 0.180734\n",
            "[Epoch 142/200] [Batch 60/938] loss_G: 2.874143, loss_D: 0.117987\n",
            "[Epoch 142/200] [Batch 70/938] loss_G: 2.960351, loss_D: 0.214949\n",
            "[Epoch 142/200] [Batch 80/938] loss_G: 3.111245, loss_D: 0.172498\n",
            "[Epoch 142/200] [Batch 90/938] loss_G: 2.947271, loss_D: 0.234740\n",
            "[Epoch 142/200] [Batch 100/938] loss_G: 2.901295, loss_D: 0.137671\n",
            "[Epoch 142/200] [Batch 110/938] loss_G: 2.844788, loss_D: 0.185407\n",
            "[Epoch 142/200] [Batch 120/938] loss_G: 3.226378, loss_D: 0.137537\n",
            "[Epoch 142/200] [Batch 130/938] loss_G: 3.010995, loss_D: 0.220939\n",
            "[Epoch 142/200] [Batch 140/938] loss_G: 3.334852, loss_D: 0.204815\n",
            "[Epoch 142/200] [Batch 150/938] loss_G: 3.016820, loss_D: 0.201895\n",
            "[Epoch 142/200] [Batch 160/938] loss_G: 3.192692, loss_D: 0.165996\n",
            "[Epoch 142/200] [Batch 170/938] loss_G: 3.259729, loss_D: 0.258120\n",
            "[Epoch 142/200] [Batch 180/938] loss_G: 3.127149, loss_D: 0.135020\n",
            "[Epoch 142/200] [Batch 190/938] loss_G: 3.060773, loss_D: 0.220302\n",
            "[Epoch 142/200] [Batch 200/938] loss_G: 2.743318, loss_D: 0.220780\n",
            "[Epoch 142/200] [Batch 210/938] loss_G: 3.060189, loss_D: 0.263208\n",
            "[Epoch 142/200] [Batch 220/938] loss_G: 2.954181, loss_D: 0.168236\n",
            "[Epoch 142/200] [Batch 230/938] loss_G: 3.080831, loss_D: 0.252196\n",
            "[Epoch 142/200] [Batch 240/938] loss_G: 3.427131, loss_D: 0.170285\n",
            "[Epoch 142/200] [Batch 250/938] loss_G: 3.220295, loss_D: 0.252461\n",
            "[Epoch 142/200] [Batch 260/938] loss_G: 2.945876, loss_D: 0.204302\n",
            "[Epoch 142/200] [Batch 270/938] loss_G: 2.985450, loss_D: 0.113501\n",
            "[Epoch 142/200] [Batch 280/938] loss_G: 3.300779, loss_D: 0.195268\n",
            "[Epoch 142/200] [Batch 290/938] loss_G: 2.610723, loss_D: 0.179390\n",
            "[Epoch 142/200] [Batch 300/938] loss_G: 3.234419, loss_D: 0.197398\n",
            "[Epoch 142/200] [Batch 310/938] loss_G: 3.071032, loss_D: 0.211742\n",
            "[Epoch 142/200] [Batch 320/938] loss_G: 3.118736, loss_D: 0.219132\n",
            "[Epoch 142/200] [Batch 330/938] loss_G: 2.926136, loss_D: 0.223094\n",
            "[Epoch 142/200] [Batch 340/938] loss_G: 3.396926, loss_D: 0.236773\n",
            "[Epoch 142/200] [Batch 350/938] loss_G: 2.740687, loss_D: 0.233555\n",
            "[Epoch 142/200] [Batch 360/938] loss_G: 2.838126, loss_D: 0.227982\n",
            "[Epoch 142/200] [Batch 370/938] loss_G: 3.204951, loss_D: 0.214199\n",
            "[Epoch 142/200] [Batch 380/938] loss_G: 3.090385, loss_D: 0.182887\n",
            "[Epoch 142/200] [Batch 390/938] loss_G: 3.345942, loss_D: 0.284833\n",
            "[Epoch 142/200] [Batch 400/938] loss_G: 3.012210, loss_D: 0.235521\n",
            "[Epoch 142/200] [Batch 410/938] loss_G: 3.240073, loss_D: 0.196680\n",
            "[Epoch 142/200] [Batch 420/938] loss_G: 3.199238, loss_D: 0.134127\n",
            "[Epoch 142/200] [Batch 430/938] loss_G: 2.845861, loss_D: 0.221833\n",
            "[Epoch 142/200] [Batch 440/938] loss_G: 3.223012, loss_D: 0.204200\n",
            "[Epoch 142/200] [Batch 450/938] loss_G: 3.624754, loss_D: 0.177640\n",
            "[Epoch 142/200] [Batch 460/938] loss_G: 2.905275, loss_D: 0.244519\n",
            "[Epoch 142/200] [Batch 470/938] loss_G: 3.120448, loss_D: 0.221160\n",
            "[Epoch 142/200] [Batch 480/938] loss_G: 3.079477, loss_D: 0.216949\n",
            "[Epoch 142/200] [Batch 490/938] loss_G: 2.598436, loss_D: 0.184928\n",
            "[Epoch 142/200] [Batch 500/938] loss_G: 3.242079, loss_D: 0.190173\n",
            "[Epoch 142/200] [Batch 510/938] loss_G: 3.130883, loss_D: 0.153584\n",
            "[Epoch 142/200] [Batch 520/938] loss_G: 3.171325, loss_D: 0.262354\n",
            "[Epoch 142/200] [Batch 530/938] loss_G: 2.853609, loss_D: 0.282414\n",
            "[Epoch 142/200] [Batch 540/938] loss_G: 2.878986, loss_D: 0.239241\n",
            "[Epoch 142/200] [Batch 550/938] loss_G: 2.930855, loss_D: 0.181724\n",
            "[Epoch 142/200] [Batch 560/938] loss_G: 3.177014, loss_D: 0.208843\n",
            "[Epoch 142/200] [Batch 570/938] loss_G: 3.028777, loss_D: 0.197277\n",
            "[Epoch 142/200] [Batch 580/938] loss_G: 2.811953, loss_D: 0.192961\n",
            "[Epoch 142/200] [Batch 590/938] loss_G: 3.056108, loss_D: 0.221117\n",
            "[Epoch 142/200] [Batch 600/938] loss_G: 3.132628, loss_D: 0.188633\n",
            "[Epoch 142/200] [Batch 610/938] loss_G: 3.013515, loss_D: 0.235192\n",
            "[Epoch 142/200] [Batch 620/938] loss_G: 3.315620, loss_D: 0.169337\n",
            "[Epoch 142/200] [Batch 630/938] loss_G: 2.779505, loss_D: 0.258921\n",
            "[Epoch 142/200] [Batch 640/938] loss_G: 2.902074, loss_D: 0.289453\n",
            "[Epoch 142/200] [Batch 650/938] loss_G: 2.929713, loss_D: 0.221973\n",
            "[Epoch 142/200] [Batch 660/938] loss_G: 2.940925, loss_D: 0.203236\n",
            "[Epoch 142/200] [Batch 670/938] loss_G: 3.484123, loss_D: 0.210308\n",
            "[Epoch 142/200] [Batch 680/938] loss_G: 2.857985, loss_D: 0.217514\n",
            "[Epoch 142/200] [Batch 690/938] loss_G: 2.996201, loss_D: 0.264339\n",
            "[Epoch 142/200] [Batch 700/938] loss_G: 2.899088, loss_D: 0.211767\n",
            "[Epoch 142/200] [Batch 710/938] loss_G: 2.880169, loss_D: 0.172922\n",
            "[Epoch 142/200] [Batch 720/938] loss_G: 3.388079, loss_D: 0.287838\n",
            "[Epoch 142/200] [Batch 730/938] loss_G: 2.587510, loss_D: 0.249463\n",
            "[Epoch 142/200] [Batch 740/938] loss_G: 2.960001, loss_D: 0.200874\n",
            "[Epoch 142/200] [Batch 750/938] loss_G: 2.887840, loss_D: 0.217602\n",
            "[Epoch 142/200] [Batch 760/938] loss_G: 3.158836, loss_D: 0.131152\n",
            "[Epoch 142/200] [Batch 770/938] loss_G: 3.045761, loss_D: 0.216788\n",
            "[Epoch 142/200] [Batch 780/938] loss_G: 3.250700, loss_D: 0.223343\n",
            "[Epoch 142/200] [Batch 790/938] loss_G: 2.880650, loss_D: 0.210215\n",
            "[Epoch 142/200] [Batch 800/938] loss_G: 2.984880, loss_D: 0.252994\n",
            "[Epoch 142/200] [Batch 810/938] loss_G: 3.104701, loss_D: 0.299631\n",
            "[Epoch 142/200] [Batch 820/938] loss_G: 2.951068, loss_D: 0.216391\n",
            "[Epoch 142/200] [Batch 830/938] loss_G: 3.007132, loss_D: 0.215696\n",
            "[Epoch 142/200] [Batch 840/938] loss_G: 3.258689, loss_D: 0.253705\n",
            "[Epoch 142/200] [Batch 850/938] loss_G: 3.011210, loss_D: 0.188870\n",
            "[Epoch 142/200] [Batch 860/938] loss_G: 3.109919, loss_D: 0.175327\n",
            "[Epoch 142/200] [Batch 870/938] loss_G: 2.669091, loss_D: 0.172170\n",
            "[Epoch 142/200] [Batch 880/938] loss_G: 3.060093, loss_D: 0.201030\n",
            "[Epoch 142/200] [Batch 890/938] loss_G: 2.778752, loss_D: 0.211815\n",
            "[Epoch 142/200] [Batch 900/938] loss_G: 2.953929, loss_D: 0.182344\n",
            "[Epoch 142/200] [Batch 910/938] loss_G: 2.753829, loss_D: 0.279336\n",
            "[Epoch 142/200] [Batch 920/938] loss_G: 2.693187, loss_D: 0.346454\n",
            "[Epoch 142/200] [Batch 930/938] loss_G: 2.805697, loss_D: 0.289571\n",
            "[Epoch 143/200] [Batch 0/938] loss_G: 2.629231, loss_D: 0.282621\n",
            "[Epoch 143/200] [Batch 10/938] loss_G: 3.252975, loss_D: 0.219706\n",
            "[Epoch 143/200] [Batch 20/938] loss_G: 3.175142, loss_D: 0.265799\n",
            "[Epoch 143/200] [Batch 30/938] loss_G: 3.230641, loss_D: 0.232543\n",
            "[Epoch 143/200] [Batch 40/938] loss_G: 2.975762, loss_D: 0.119008\n",
            "[Epoch 143/200] [Batch 50/938] loss_G: 2.805888, loss_D: 0.179847\n",
            "[Epoch 143/200] [Batch 60/938] loss_G: 3.227953, loss_D: 0.222194\n",
            "[Epoch 143/200] [Batch 70/938] loss_G: 2.992388, loss_D: 0.125422\n",
            "[Epoch 143/200] [Batch 80/938] loss_G: 3.179554, loss_D: 0.255325\n",
            "[Epoch 143/200] [Batch 90/938] loss_G: 2.873811, loss_D: 0.246246\n",
            "[Epoch 143/200] [Batch 100/938] loss_G: 2.864034, loss_D: 0.221811\n",
            "[Epoch 143/200] [Batch 110/938] loss_G: 3.012820, loss_D: 0.252800\n",
            "[Epoch 143/200] [Batch 120/938] loss_G: 3.315073, loss_D: 0.247988\n",
            "[Epoch 143/200] [Batch 130/938] loss_G: 2.832673, loss_D: 0.256268\n",
            "[Epoch 143/200] [Batch 140/938] loss_G: 3.104290, loss_D: 0.171661\n",
            "[Epoch 143/200] [Batch 150/938] loss_G: 3.101566, loss_D: 0.165388\n",
            "[Epoch 143/200] [Batch 160/938] loss_G: 2.867831, loss_D: 0.211023\n",
            "[Epoch 143/200] [Batch 170/938] loss_G: 2.570971, loss_D: 0.208969\n",
            "[Epoch 143/200] [Batch 180/938] loss_G: 3.148424, loss_D: 0.233582\n",
            "[Epoch 143/200] [Batch 190/938] loss_G: 3.437822, loss_D: 0.247114\n",
            "[Epoch 143/200] [Batch 200/938] loss_G: 2.838028, loss_D: 0.169258\n",
            "[Epoch 143/200] [Batch 210/938] loss_G: 3.343727, loss_D: 0.218058\n",
            "[Epoch 143/200] [Batch 220/938] loss_G: 2.788243, loss_D: 0.171868\n",
            "[Epoch 143/200] [Batch 230/938] loss_G: 2.951362, loss_D: 0.151342\n",
            "[Epoch 143/200] [Batch 240/938] loss_G: 3.031802, loss_D: 0.210813\n",
            "[Epoch 143/200] [Batch 250/938] loss_G: 3.287935, loss_D: 0.225651\n",
            "[Epoch 143/200] [Batch 260/938] loss_G: 3.252504, loss_D: 0.185745\n",
            "[Epoch 143/200] [Batch 270/938] loss_G: 3.458683, loss_D: 0.113968\n",
            "[Epoch 143/200] [Batch 280/938] loss_G: 2.835687, loss_D: 0.213413\n",
            "[Epoch 143/200] [Batch 290/938] loss_G: 2.911954, loss_D: 0.239775\n",
            "[Epoch 143/200] [Batch 300/938] loss_G: 3.018384, loss_D: 0.169057\n",
            "[Epoch 143/200] [Batch 310/938] loss_G: 2.974715, loss_D: 0.173862\n",
            "[Epoch 143/200] [Batch 320/938] loss_G: 2.904323, loss_D: 0.167237\n",
            "[Epoch 143/200] [Batch 330/938] loss_G: 3.270385, loss_D: 0.184087\n",
            "[Epoch 143/200] [Batch 340/938] loss_G: 2.890181, loss_D: 0.153183\n",
            "[Epoch 143/200] [Batch 350/938] loss_G: 2.797554, loss_D: 0.242260\n",
            "[Epoch 143/200] [Batch 360/938] loss_G: 2.959151, loss_D: 0.222705\n",
            "[Epoch 143/200] [Batch 370/938] loss_G: 3.049297, loss_D: 0.215806\n",
            "[Epoch 143/200] [Batch 380/938] loss_G: 3.091357, loss_D: 0.181829\n",
            "[Epoch 143/200] [Batch 390/938] loss_G: 3.025623, loss_D: 0.225822\n",
            "[Epoch 143/200] [Batch 400/938] loss_G: 3.443812, loss_D: 0.169975\n",
            "[Epoch 143/200] [Batch 410/938] loss_G: 2.806942, loss_D: 0.176712\n",
            "[Epoch 143/200] [Batch 420/938] loss_G: 2.922576, loss_D: 0.256060\n",
            "[Epoch 143/200] [Batch 430/938] loss_G: 3.015275, loss_D: 0.185040\n",
            "[Epoch 143/200] [Batch 440/938] loss_G: 3.004280, loss_D: 0.112121\n",
            "[Epoch 143/200] [Batch 450/938] loss_G: 2.411666, loss_D: 0.249219\n",
            "[Epoch 143/200] [Batch 460/938] loss_G: 3.187162, loss_D: 0.182931\n",
            "[Epoch 143/200] [Batch 470/938] loss_G: 3.012103, loss_D: 0.136157\n",
            "[Epoch 143/200] [Batch 480/938] loss_G: 3.052042, loss_D: 0.258005\n",
            "[Epoch 143/200] [Batch 490/938] loss_G: 2.740443, loss_D: 0.249432\n",
            "[Epoch 143/200] [Batch 500/938] loss_G: 2.803502, loss_D: 0.204475\n",
            "[Epoch 143/200] [Batch 510/938] loss_G: 2.743599, loss_D: 0.238679\n",
            "[Epoch 143/200] [Batch 520/938] loss_G: 3.211622, loss_D: 0.181142\n",
            "[Epoch 143/200] [Batch 530/938] loss_G: 3.122300, loss_D: 0.188246\n",
            "[Epoch 143/200] [Batch 540/938] loss_G: 2.911415, loss_D: 0.213952\n",
            "[Epoch 143/200] [Batch 550/938] loss_G: 3.021428, loss_D: 0.161031\n",
            "[Epoch 143/200] [Batch 560/938] loss_G: 3.106546, loss_D: 0.193828\n",
            "[Epoch 143/200] [Batch 570/938] loss_G: 3.061871, loss_D: 0.272654\n",
            "[Epoch 143/200] [Batch 580/938] loss_G: 3.155404, loss_D: 0.259882\n",
            "[Epoch 143/200] [Batch 590/938] loss_G: 2.996301, loss_D: 0.140768\n",
            "[Epoch 143/200] [Batch 600/938] loss_G: 3.270696, loss_D: 0.176172\n",
            "[Epoch 143/200] [Batch 610/938] loss_G: 2.860459, loss_D: 0.212952\n",
            "[Epoch 143/200] [Batch 620/938] loss_G: 3.361777, loss_D: 0.201613\n",
            "[Epoch 143/200] [Batch 630/938] loss_G: 2.767597, loss_D: 0.222454\n",
            "[Epoch 143/200] [Batch 640/938] loss_G: 3.433704, loss_D: 0.245809\n",
            "[Epoch 143/200] [Batch 650/938] loss_G: 3.026104, loss_D: 0.208025\n",
            "[Epoch 143/200] [Batch 660/938] loss_G: 3.223270, loss_D: 0.199483\n",
            "[Epoch 143/200] [Batch 670/938] loss_G: 3.371232, loss_D: 0.153744\n",
            "[Epoch 143/200] [Batch 680/938] loss_G: 3.227742, loss_D: 0.166210\n",
            "[Epoch 143/200] [Batch 690/938] loss_G: 3.516956, loss_D: 0.184690\n",
            "[Epoch 143/200] [Batch 700/938] loss_G: 2.809141, loss_D: 0.227732\n",
            "[Epoch 143/200] [Batch 710/938] loss_G: 3.039147, loss_D: 0.250220\n",
            "[Epoch 143/200] [Batch 720/938] loss_G: 2.853869, loss_D: 0.236556\n",
            "[Epoch 143/200] [Batch 730/938] loss_G: 3.179617, loss_D: 0.190513\n",
            "[Epoch 143/200] [Batch 740/938] loss_G: 2.806728, loss_D: 0.355449\n",
            "[Epoch 143/200] [Batch 750/938] loss_G: 3.094210, loss_D: 0.232473\n",
            "[Epoch 143/200] [Batch 760/938] loss_G: 3.217679, loss_D: 0.220259\n",
            "[Epoch 143/200] [Batch 770/938] loss_G: 3.214109, loss_D: 0.201909\n",
            "[Epoch 143/200] [Batch 780/938] loss_G: 2.931973, loss_D: 0.232356\n",
            "[Epoch 143/200] [Batch 790/938] loss_G: 2.830980, loss_D: 0.160277\n",
            "[Epoch 143/200] [Batch 800/938] loss_G: 2.736047, loss_D: 0.170764\n",
            "[Epoch 143/200] [Batch 810/938] loss_G: 3.261960, loss_D: 0.225454\n",
            "[Epoch 143/200] [Batch 820/938] loss_G: 3.001272, loss_D: 0.256203\n",
            "[Epoch 143/200] [Batch 830/938] loss_G: 2.706919, loss_D: 0.230741\n",
            "[Epoch 143/200] [Batch 840/938] loss_G: 3.335961, loss_D: 0.179412\n",
            "[Epoch 143/200] [Batch 850/938] loss_G: 3.172059, loss_D: 0.205483\n",
            "[Epoch 143/200] [Batch 860/938] loss_G: 2.712137, loss_D: 0.270004\n",
            "[Epoch 143/200] [Batch 870/938] loss_G: 3.029886, loss_D: 0.241062\n",
            "[Epoch 143/200] [Batch 880/938] loss_G: 2.973021, loss_D: 0.182061\n",
            "[Epoch 143/200] [Batch 890/938] loss_G: 2.533697, loss_D: 0.258157\n",
            "[Epoch 143/200] [Batch 900/938] loss_G: 2.925946, loss_D: 0.294077\n",
            "[Epoch 143/200] [Batch 910/938] loss_G: 3.169880, loss_D: 0.196150\n",
            "[Epoch 143/200] [Batch 920/938] loss_G: 2.888344, loss_D: 0.216489\n",
            "[Epoch 143/200] [Batch 930/938] loss_G: 3.325041, loss_D: 0.214350\n",
            "[Epoch 144/200] [Batch 0/938] loss_G: 2.977714, loss_D: 0.198741\n",
            "[Epoch 144/200] [Batch 10/938] loss_G: 3.074828, loss_D: 0.244719\n",
            "[Epoch 144/200] [Batch 20/938] loss_G: 3.029641, loss_D: 0.204895\n",
            "[Epoch 144/200] [Batch 30/938] loss_G: 3.089630, loss_D: 0.209292\n",
            "[Epoch 144/200] [Batch 40/938] loss_G: 2.818650, loss_D: 0.199497\n",
            "[Epoch 144/200] [Batch 50/938] loss_G: 3.009233, loss_D: 0.245558\n",
            "[Epoch 144/200] [Batch 60/938] loss_G: 2.978465, loss_D: 0.219230\n",
            "[Epoch 144/200] [Batch 70/938] loss_G: 3.126147, loss_D: 0.208366\n",
            "[Epoch 144/200] [Batch 80/938] loss_G: 2.959536, loss_D: 0.290736\n",
            "[Epoch 144/200] [Batch 90/938] loss_G: 2.958062, loss_D: 0.181008\n",
            "[Epoch 144/200] [Batch 100/938] loss_G: 2.885333, loss_D: 0.250587\n",
            "[Epoch 144/200] [Batch 110/938] loss_G: 2.845450, loss_D: 0.219137\n",
            "[Epoch 144/200] [Batch 120/938] loss_G: 3.335421, loss_D: 0.174584\n",
            "[Epoch 144/200] [Batch 130/938] loss_G: 2.614650, loss_D: 0.277627\n",
            "[Epoch 144/200] [Batch 140/938] loss_G: 2.686404, loss_D: 0.216369\n",
            "[Epoch 144/200] [Batch 150/938] loss_G: 3.098431, loss_D: 0.168935\n",
            "[Epoch 144/200] [Batch 160/938] loss_G: 2.854540, loss_D: 0.145809\n",
            "[Epoch 144/200] [Batch 170/938] loss_G: 2.732991, loss_D: 0.169831\n",
            "[Epoch 144/200] [Batch 180/938] loss_G: 3.174302, loss_D: 0.192824\n",
            "[Epoch 144/200] [Batch 190/938] loss_G: 3.175187, loss_D: 0.230203\n",
            "[Epoch 144/200] [Batch 200/938] loss_G: 2.915523, loss_D: 0.189684\n",
            "[Epoch 144/200] [Batch 210/938] loss_G: 2.775662, loss_D: 0.140382\n",
            "[Epoch 144/200] [Batch 220/938] loss_G: 3.160401, loss_D: 0.182602\n",
            "[Epoch 144/200] [Batch 230/938] loss_G: 3.105483, loss_D: 0.188549\n",
            "[Epoch 144/200] [Batch 240/938] loss_G: 3.167338, loss_D: 0.182728\n",
            "[Epoch 144/200] [Batch 250/938] loss_G: 3.180695, loss_D: 0.156179\n",
            "[Epoch 144/200] [Batch 260/938] loss_G: 3.246537, loss_D: 0.259435\n",
            "[Epoch 144/200] [Batch 270/938] loss_G: 3.205036, loss_D: 0.171967\n",
            "[Epoch 144/200] [Batch 280/938] loss_G: 3.060469, loss_D: 0.141400\n",
            "[Epoch 144/200] [Batch 290/938] loss_G: 3.604196, loss_D: 0.220688\n",
            "[Epoch 144/200] [Batch 300/938] loss_G: 3.217319, loss_D: 0.165347\n",
            "[Epoch 144/200] [Batch 310/938] loss_G: 2.903533, loss_D: 0.185593\n",
            "[Epoch 144/200] [Batch 320/938] loss_G: 3.045594, loss_D: 0.196025\n",
            "[Epoch 144/200] [Batch 330/938] loss_G: 2.803612, loss_D: 0.237762\n",
            "[Epoch 144/200] [Batch 340/938] loss_G: 3.112631, loss_D: 0.250687\n",
            "[Epoch 144/200] [Batch 350/938] loss_G: 3.199037, loss_D: 0.208835\n",
            "[Epoch 144/200] [Batch 360/938] loss_G: 3.175461, loss_D: 0.223760\n",
            "[Epoch 144/200] [Batch 370/938] loss_G: 3.045721, loss_D: 0.168505\n",
            "[Epoch 144/200] [Batch 380/938] loss_G: 2.982741, loss_D: 0.212506\n",
            "[Epoch 144/200] [Batch 390/938] loss_G: 3.159766, loss_D: 0.176661\n",
            "[Epoch 144/200] [Batch 400/938] loss_G: 3.132206, loss_D: 0.210447\n",
            "[Epoch 144/200] [Batch 410/938] loss_G: 3.427255, loss_D: 0.216163\n",
            "[Epoch 144/200] [Batch 420/938] loss_G: 2.522262, loss_D: 0.212473\n",
            "[Epoch 144/200] [Batch 430/938] loss_G: 2.875260, loss_D: 0.161475\n",
            "[Epoch 144/200] [Batch 440/938] loss_G: 2.824424, loss_D: 0.231944\n",
            "[Epoch 144/200] [Batch 450/938] loss_G: 3.149452, loss_D: 0.225095\n",
            "[Epoch 144/200] [Batch 460/938] loss_G: 3.158581, loss_D: 0.228486\n",
            "[Epoch 144/200] [Batch 470/938] loss_G: 3.090261, loss_D: 0.176564\n",
            "[Epoch 144/200] [Batch 480/938] loss_G: 3.043777, loss_D: 0.172202\n",
            "[Epoch 144/200] [Batch 490/938] loss_G: 2.895164, loss_D: 0.259740\n",
            "[Epoch 144/200] [Batch 500/938] loss_G: 3.211767, loss_D: 0.154139\n",
            "[Epoch 144/200] [Batch 510/938] loss_G: 3.258111, loss_D: 0.287865\n",
            "[Epoch 144/200] [Batch 520/938] loss_G: 3.409016, loss_D: 0.141846\n",
            "[Epoch 144/200] [Batch 530/938] loss_G: 2.983771, loss_D: 0.329705\n",
            "[Epoch 144/200] [Batch 540/938] loss_G: 3.117665, loss_D: 0.327260\n",
            "[Epoch 144/200] [Batch 550/938] loss_G: 3.054472, loss_D: 0.188726\n",
            "[Epoch 144/200] [Batch 560/938] loss_G: 3.182208, loss_D: 0.168645\n",
            "[Epoch 144/200] [Batch 570/938] loss_G: 2.923080, loss_D: 0.301494\n",
            "[Epoch 144/200] [Batch 580/938] loss_G: 2.830966, loss_D: 0.209670\n",
            "[Epoch 144/200] [Batch 590/938] loss_G: 3.178102, loss_D: 0.166085\n",
            "[Epoch 144/200] [Batch 600/938] loss_G: 2.766219, loss_D: 0.150333\n",
            "[Epoch 144/200] [Batch 610/938] loss_G: 3.048562, loss_D: 0.192967\n",
            "[Epoch 144/200] [Batch 620/938] loss_G: 3.180351, loss_D: 0.225531\n",
            "[Epoch 144/200] [Batch 630/938] loss_G: 3.040417, loss_D: 0.275218\n",
            "[Epoch 144/200] [Batch 640/938] loss_G: 3.057742, loss_D: 0.264416\n",
            "[Epoch 144/200] [Batch 650/938] loss_G: 3.151684, loss_D: 0.185725\n",
            "[Epoch 144/200] [Batch 660/938] loss_G: 2.796843, loss_D: 0.199371\n",
            "[Epoch 144/200] [Batch 670/938] loss_G: 3.328256, loss_D: 0.204718\n",
            "[Epoch 144/200] [Batch 680/938] loss_G: 3.118275, loss_D: 0.186560\n",
            "[Epoch 144/200] [Batch 690/938] loss_G: 3.257167, loss_D: 0.121620\n",
            "[Epoch 144/200] [Batch 700/938] loss_G: 2.806904, loss_D: 0.194953\n",
            "[Epoch 144/200] [Batch 710/938] loss_G: 3.074080, loss_D: 0.257022\n",
            "[Epoch 144/200] [Batch 720/938] loss_G: 3.056348, loss_D: 0.190979\n",
            "[Epoch 144/200] [Batch 730/938] loss_G: 3.311044, loss_D: 0.225341\n",
            "[Epoch 144/200] [Batch 740/938] loss_G: 3.256273, loss_D: 0.185450\n",
            "[Epoch 144/200] [Batch 750/938] loss_G: 3.511349, loss_D: 0.189793\n",
            "[Epoch 144/200] [Batch 760/938] loss_G: 3.053893, loss_D: 0.137631\n",
            "[Epoch 144/200] [Batch 770/938] loss_G: 3.040517, loss_D: 0.183242\n",
            "[Epoch 144/200] [Batch 780/938] loss_G: 2.780931, loss_D: 0.235575\n",
            "[Epoch 144/200] [Batch 790/938] loss_G: 2.935176, loss_D: 0.388199\n",
            "[Epoch 144/200] [Batch 800/938] loss_G: 3.284483, loss_D: 0.169012\n",
            "[Epoch 144/200] [Batch 810/938] loss_G: 3.327286, loss_D: 0.262381\n",
            "[Epoch 144/200] [Batch 820/938] loss_G: 3.039787, loss_D: 0.144951\n",
            "[Epoch 144/200] [Batch 830/938] loss_G: 3.250125, loss_D: 0.176094\n",
            "[Epoch 144/200] [Batch 840/938] loss_G: 3.166481, loss_D: 0.195042\n",
            "[Epoch 144/200] [Batch 850/938] loss_G: 2.930921, loss_D: 0.214976\n",
            "[Epoch 144/200] [Batch 860/938] loss_G: 2.964149, loss_D: 0.189007\n",
            "[Epoch 144/200] [Batch 870/938] loss_G: 3.177982, loss_D: 0.172676\n",
            "[Epoch 144/200] [Batch 880/938] loss_G: 3.047907, loss_D: 0.234690\n",
            "[Epoch 144/200] [Batch 890/938] loss_G: 3.338500, loss_D: 0.237023\n",
            "[Epoch 144/200] [Batch 900/938] loss_G: 2.924505, loss_D: 0.289740\n",
            "[Epoch 144/200] [Batch 910/938] loss_G: 3.092572, loss_D: 0.170888\n",
            "[Epoch 144/200] [Batch 920/938] loss_G: 2.965128, loss_D: 0.235438\n",
            "[Epoch 144/200] [Batch 930/938] loss_G: 2.877366, loss_D: 0.260834\n",
            "[Epoch 145/200] [Batch 0/938] loss_G: 3.330356, loss_D: 0.219847\n",
            "[Epoch 145/200] [Batch 10/938] loss_G: 2.929941, loss_D: 0.165162\n",
            "[Epoch 145/200] [Batch 20/938] loss_G: 2.984322, loss_D: 0.200793\n",
            "[Epoch 145/200] [Batch 30/938] loss_G: 3.110377, loss_D: 0.157671\n",
            "[Epoch 145/200] [Batch 40/938] loss_G: 2.950104, loss_D: 0.234770\n",
            "[Epoch 145/200] [Batch 50/938] loss_G: 3.234896, loss_D: 0.187934\n",
            "[Epoch 145/200] [Batch 60/938] loss_G: 3.038905, loss_D: 0.173387\n",
            "[Epoch 145/200] [Batch 70/938] loss_G: 2.856816, loss_D: 0.331120\n",
            "[Epoch 145/200] [Batch 80/938] loss_G: 2.886606, loss_D: 0.164352\n",
            "[Epoch 145/200] [Batch 90/938] loss_G: 2.942661, loss_D: 0.225776\n",
            "[Epoch 145/200] [Batch 100/938] loss_G: 3.159086, loss_D: 0.251843\n",
            "[Epoch 145/200] [Batch 110/938] loss_G: 3.543588, loss_D: 0.165647\n",
            "[Epoch 145/200] [Batch 120/938] loss_G: 2.565054, loss_D: 0.270133\n",
            "[Epoch 145/200] [Batch 130/938] loss_G: 3.302432, loss_D: 0.167811\n",
            "[Epoch 145/200] [Batch 140/938] loss_G: 3.297864, loss_D: 0.168074\n",
            "[Epoch 145/200] [Batch 150/938] loss_G: 3.076467, loss_D: 0.123070\n",
            "[Epoch 145/200] [Batch 160/938] loss_G: 3.166014, loss_D: 0.260308\n",
            "[Epoch 145/200] [Batch 170/938] loss_G: 3.793691, loss_D: 0.209389\n",
            "[Epoch 145/200] [Batch 180/938] loss_G: 3.424147, loss_D: 0.225930\n",
            "[Epoch 145/200] [Batch 190/938] loss_G: 3.027532, loss_D: 0.224234\n",
            "[Epoch 145/200] [Batch 200/938] loss_G: 3.085604, loss_D: 0.260532\n",
            "[Epoch 145/200] [Batch 210/938] loss_G: 3.429206, loss_D: 0.265627\n",
            "[Epoch 145/200] [Batch 220/938] loss_G: 3.233740, loss_D: 0.250171\n",
            "[Epoch 145/200] [Batch 230/938] loss_G: 3.175757, loss_D: 0.212873\n",
            "[Epoch 145/200] [Batch 240/938] loss_G: 2.979421, loss_D: 0.234148\n",
            "[Epoch 145/200] [Batch 250/938] loss_G: 2.910537, loss_D: 0.220667\n",
            "[Epoch 145/200] [Batch 260/938] loss_G: 3.093491, loss_D: 0.180478\n",
            "[Epoch 145/200] [Batch 270/938] loss_G: 3.027862, loss_D: 0.259681\n",
            "[Epoch 145/200] [Batch 280/938] loss_G: 3.117169, loss_D: 0.201260\n",
            "[Epoch 145/200] [Batch 290/938] loss_G: 2.837606, loss_D: 0.189660\n",
            "[Epoch 145/200] [Batch 300/938] loss_G: 3.216678, loss_D: 0.245995\n",
            "[Epoch 145/200] [Batch 310/938] loss_G: 3.165524, loss_D: 0.153120\n",
            "[Epoch 145/200] [Batch 320/938] loss_G: 2.827711, loss_D: 0.170210\n",
            "[Epoch 145/200] [Batch 330/938] loss_G: 2.880637, loss_D: 0.230128\n",
            "[Epoch 145/200] [Batch 340/938] loss_G: 3.339550, loss_D: 0.170751\n",
            "[Epoch 145/200] [Batch 350/938] loss_G: 2.889062, loss_D: 0.212697\n",
            "[Epoch 145/200] [Batch 360/938] loss_G: 3.253411, loss_D: 0.279883\n",
            "[Epoch 145/200] [Batch 370/938] loss_G: 3.043681, loss_D: 0.236300\n",
            "[Epoch 145/200] [Batch 380/938] loss_G: 3.160819, loss_D: 0.173179\n",
            "[Epoch 145/200] [Batch 390/938] loss_G: 2.987395, loss_D: 0.204248\n",
            "[Epoch 145/200] [Batch 400/938] loss_G: 3.132955, loss_D: 0.244715\n",
            "[Epoch 145/200] [Batch 410/938] loss_G: 2.608707, loss_D: 0.187902\n",
            "[Epoch 145/200] [Batch 420/938] loss_G: 2.693484, loss_D: 0.236340\n",
            "[Epoch 145/200] [Batch 430/938] loss_G: 3.411673, loss_D: 0.171575\n",
            "[Epoch 145/200] [Batch 440/938] loss_G: 2.659972, loss_D: 0.175826\n",
            "[Epoch 145/200] [Batch 450/938] loss_G: 3.037385, loss_D: 0.160819\n",
            "[Epoch 145/200] [Batch 460/938] loss_G: 2.595591, loss_D: 0.253985\n",
            "[Epoch 145/200] [Batch 470/938] loss_G: 2.984563, loss_D: 0.303303\n",
            "[Epoch 145/200] [Batch 480/938] loss_G: 3.342145, loss_D: 0.151137\n",
            "[Epoch 145/200] [Batch 490/938] loss_G: 3.192363, loss_D: 0.224274\n",
            "[Epoch 145/200] [Batch 500/938] loss_G: 2.982284, loss_D: 0.188509\n",
            "[Epoch 145/200] [Batch 510/938] loss_G: 3.318188, loss_D: 0.124623\n",
            "[Epoch 145/200] [Batch 520/938] loss_G: 3.409193, loss_D: 0.185062\n",
            "[Epoch 145/200] [Batch 530/938] loss_G: 2.986088, loss_D: 0.181267\n",
            "[Epoch 145/200] [Batch 540/938] loss_G: 3.456313, loss_D: 0.169239\n",
            "[Epoch 145/200] [Batch 550/938] loss_G: 3.140563, loss_D: 0.229194\n",
            "[Epoch 145/200] [Batch 560/938] loss_G: 3.128834, loss_D: 0.158320\n",
            "[Epoch 145/200] [Batch 570/938] loss_G: 3.147343, loss_D: 0.205412\n",
            "[Epoch 145/200] [Batch 580/938] loss_G: 3.267227, loss_D: 0.203520\n",
            "[Epoch 145/200] [Batch 590/938] loss_G: 3.269809, loss_D: 0.134452\n",
            "[Epoch 145/200] [Batch 600/938] loss_G: 2.545588, loss_D: 0.248164\n",
            "[Epoch 145/200] [Batch 610/938] loss_G: 3.035576, loss_D: 0.160021\n",
            "[Epoch 145/200] [Batch 620/938] loss_G: 3.391981, loss_D: 0.183172\n",
            "[Epoch 145/200] [Batch 630/938] loss_G: 3.259444, loss_D: 0.219474\n",
            "[Epoch 145/200] [Batch 640/938] loss_G: 3.235204, loss_D: 0.144364\n",
            "[Epoch 145/200] [Batch 650/938] loss_G: 3.184014, loss_D: 0.212568\n",
            "[Epoch 145/200] [Batch 660/938] loss_G: 3.209929, loss_D: 0.191998\n",
            "[Epoch 145/200] [Batch 670/938] loss_G: 3.095222, loss_D: 0.125788\n",
            "[Epoch 145/200] [Batch 680/938] loss_G: 3.076364, loss_D: 0.246299\n",
            "[Epoch 145/200] [Batch 690/938] loss_G: 2.768695, loss_D: 0.173665\n",
            "[Epoch 145/200] [Batch 700/938] loss_G: 2.985689, loss_D: 0.246635\n",
            "[Epoch 145/200] [Batch 710/938] loss_G: 2.962752, loss_D: 0.190889\n",
            "[Epoch 145/200] [Batch 720/938] loss_G: 3.141044, loss_D: 0.213071\n",
            "[Epoch 145/200] [Batch 730/938] loss_G: 3.465696, loss_D: 0.176806\n",
            "[Epoch 145/200] [Batch 740/938] loss_G: 2.858736, loss_D: 0.237574\n",
            "[Epoch 145/200] [Batch 750/938] loss_G: 2.556468, loss_D: 0.174892\n",
            "[Epoch 145/200] [Batch 760/938] loss_G: 3.234249, loss_D: 0.188749\n",
            "[Epoch 145/200] [Batch 770/938] loss_G: 3.342499, loss_D: 0.194034\n",
            "[Epoch 145/200] [Batch 780/938] loss_G: 2.988815, loss_D: 0.185930\n",
            "[Epoch 145/200] [Batch 790/938] loss_G: 3.361541, loss_D: 0.209404\n",
            "[Epoch 145/200] [Batch 800/938] loss_G: 3.052682, loss_D: 0.290799\n",
            "[Epoch 145/200] [Batch 810/938] loss_G: 2.812990, loss_D: 0.166133\n",
            "[Epoch 145/200] [Batch 820/938] loss_G: 3.405019, loss_D: 0.135088\n",
            "[Epoch 145/200] [Batch 830/938] loss_G: 2.956517, loss_D: 0.335376\n",
            "[Epoch 145/200] [Batch 840/938] loss_G: 3.037878, loss_D: 0.190147\n",
            "[Epoch 145/200] [Batch 850/938] loss_G: 3.395900, loss_D: 0.356993\n",
            "[Epoch 145/200] [Batch 860/938] loss_G: 2.617220, loss_D: 0.217003\n",
            "[Epoch 145/200] [Batch 870/938] loss_G: 2.916853, loss_D: 0.265436\n",
            "[Epoch 145/200] [Batch 880/938] loss_G: 3.153127, loss_D: 0.276964\n",
            "[Epoch 145/200] [Batch 890/938] loss_G: 2.866265, loss_D: 0.208951\n",
            "[Epoch 145/200] [Batch 900/938] loss_G: 3.116201, loss_D: 0.210041\n",
            "[Epoch 145/200] [Batch 910/938] loss_G: 3.220360, loss_D: 0.178442\n",
            "[Epoch 145/200] [Batch 920/938] loss_G: 3.499049, loss_D: 0.244338\n",
            "[Epoch 145/200] [Batch 930/938] loss_G: 3.110510, loss_D: 0.202116\n",
            "[Epoch 146/200] [Batch 0/938] loss_G: 3.154779, loss_D: 0.247980\n",
            "[Epoch 146/200] [Batch 10/938] loss_G: 3.285710, loss_D: 0.207257\n",
            "[Epoch 146/200] [Batch 20/938] loss_G: 3.116651, loss_D: 0.183976\n",
            "[Epoch 146/200] [Batch 30/938] loss_G: 3.412784, loss_D: 0.188901\n",
            "[Epoch 146/200] [Batch 40/938] loss_G: 3.286230, loss_D: 0.149934\n",
            "[Epoch 146/200] [Batch 50/938] loss_G: 3.533403, loss_D: 0.217952\n",
            "[Epoch 146/200] [Batch 60/938] loss_G: 2.587060, loss_D: 0.274262\n",
            "[Epoch 146/200] [Batch 70/938] loss_G: 3.068667, loss_D: 0.139474\n",
            "[Epoch 146/200] [Batch 80/938] loss_G: 3.194690, loss_D: 0.262014\n",
            "[Epoch 146/200] [Batch 90/938] loss_G: 3.220536, loss_D: 0.188409\n",
            "[Epoch 146/200] [Batch 100/938] loss_G: 3.236023, loss_D: 0.173310\n",
            "[Epoch 146/200] [Batch 110/938] loss_G: 2.879049, loss_D: 0.193597\n",
            "[Epoch 146/200] [Batch 120/938] loss_G: 3.138156, loss_D: 0.144741\n",
            "[Epoch 146/200] [Batch 130/938] loss_G: 3.505810, loss_D: 0.127655\n",
            "[Epoch 146/200] [Batch 140/938] loss_G: 2.850545, loss_D: 0.182800\n",
            "[Epoch 146/200] [Batch 150/938] loss_G: 3.149563, loss_D: 0.172118\n",
            "[Epoch 146/200] [Batch 160/938] loss_G: 3.248547, loss_D: 0.228129\n",
            "[Epoch 146/200] [Batch 170/938] loss_G: 2.988038, loss_D: 0.218200\n",
            "[Epoch 146/200] [Batch 180/938] loss_G: 3.558372, loss_D: 0.304466\n",
            "[Epoch 146/200] [Batch 190/938] loss_G: 2.936304, loss_D: 0.220574\n",
            "[Epoch 146/200] [Batch 200/938] loss_G: 3.332432, loss_D: 0.204919\n",
            "[Epoch 146/200] [Batch 210/938] loss_G: 2.974509, loss_D: 0.186975\n",
            "[Epoch 146/200] [Batch 220/938] loss_G: 3.019440, loss_D: 0.190429\n",
            "[Epoch 146/200] [Batch 230/938] loss_G: 2.821453, loss_D: 0.227564\n",
            "[Epoch 146/200] [Batch 240/938] loss_G: 2.879244, loss_D: 0.219222\n",
            "[Epoch 146/200] [Batch 250/938] loss_G: 3.175786, loss_D: 0.157294\n",
            "[Epoch 146/200] [Batch 260/938] loss_G: 2.811637, loss_D: 0.207864\n",
            "[Epoch 146/200] [Batch 270/938] loss_G: 3.424196, loss_D: 0.231315\n",
            "[Epoch 146/200] [Batch 280/938] loss_G: 2.638125, loss_D: 0.194147\n",
            "[Epoch 146/200] [Batch 290/938] loss_G: 3.071988, loss_D: 0.213380\n",
            "[Epoch 146/200] [Batch 300/938] loss_G: 2.918623, loss_D: 0.217370\n",
            "[Epoch 146/200] [Batch 310/938] loss_G: 3.423117, loss_D: 0.183369\n",
            "[Epoch 146/200] [Batch 320/938] loss_G: 3.155188, loss_D: 0.248117\n",
            "[Epoch 146/200] [Batch 330/938] loss_G: 3.206550, loss_D: 0.242749\n",
            "[Epoch 146/200] [Batch 340/938] loss_G: 3.017638, loss_D: 0.238761\n",
            "[Epoch 146/200] [Batch 350/938] loss_G: 2.995017, loss_D: 0.220460\n",
            "[Epoch 146/200] [Batch 360/938] loss_G: 3.039266, loss_D: 0.195349\n",
            "[Epoch 146/200] [Batch 370/938] loss_G: 3.126643, loss_D: 0.148140\n",
            "[Epoch 146/200] [Batch 380/938] loss_G: 2.859855, loss_D: 0.173190\n",
            "[Epoch 146/200] [Batch 390/938] loss_G: 3.109430, loss_D: 0.194300\n",
            "[Epoch 146/200] [Batch 400/938] loss_G: 2.520575, loss_D: 0.229862\n",
            "[Epoch 146/200] [Batch 410/938] loss_G: 3.272315, loss_D: 0.172464\n",
            "[Epoch 146/200] [Batch 420/938] loss_G: 2.895818, loss_D: 0.272037\n",
            "[Epoch 146/200] [Batch 430/938] loss_G: 2.834337, loss_D: 0.214430\n",
            "[Epoch 146/200] [Batch 440/938] loss_G: 2.964605, loss_D: 0.260618\n",
            "[Epoch 146/200] [Batch 450/938] loss_G: 3.066614, loss_D: 0.240599\n",
            "[Epoch 146/200] [Batch 460/938] loss_G: 2.909235, loss_D: 0.249910\n",
            "[Epoch 146/200] [Batch 470/938] loss_G: 2.811718, loss_D: 0.236701\n",
            "[Epoch 146/200] [Batch 480/938] loss_G: 2.671154, loss_D: 0.194748\n",
            "[Epoch 146/200] [Batch 490/938] loss_G: 2.870265, loss_D: 0.201062\n",
            "[Epoch 146/200] [Batch 500/938] loss_G: 2.886953, loss_D: 0.222417\n",
            "[Epoch 146/200] [Batch 510/938] loss_G: 2.935390, loss_D: 0.171214\n",
            "[Epoch 146/200] [Batch 520/938] loss_G: 2.634804, loss_D: 0.261993\n",
            "[Epoch 146/200] [Batch 530/938] loss_G: 3.460159, loss_D: 0.171776\n",
            "[Epoch 146/200] [Batch 540/938] loss_G: 3.172741, loss_D: 0.248657\n",
            "[Epoch 146/200] [Batch 550/938] loss_G: 2.944158, loss_D: 0.163716\n",
            "[Epoch 146/200] [Batch 560/938] loss_G: 3.336809, loss_D: 0.193834\n",
            "[Epoch 146/200] [Batch 570/938] loss_G: 3.277848, loss_D: 0.206288\n",
            "[Epoch 146/200] [Batch 580/938] loss_G: 3.078806, loss_D: 0.227783\n",
            "[Epoch 146/200] [Batch 590/938] loss_G: 3.175660, loss_D: 0.135575\n",
            "[Epoch 146/200] [Batch 600/938] loss_G: 3.085712, loss_D: 0.138844\n",
            "[Epoch 146/200] [Batch 610/938] loss_G: 3.252663, loss_D: 0.221249\n",
            "[Epoch 146/200] [Batch 620/938] loss_G: 3.133951, loss_D: 0.278204\n",
            "[Epoch 146/200] [Batch 630/938] loss_G: 2.764576, loss_D: 0.190823\n",
            "[Epoch 146/200] [Batch 640/938] loss_G: 2.979464, loss_D: 0.196467\n",
            "[Epoch 146/200] [Batch 650/938] loss_G: 3.141302, loss_D: 0.271968\n",
            "[Epoch 146/200] [Batch 660/938] loss_G: 3.162914, loss_D: 0.140096\n",
            "[Epoch 146/200] [Batch 670/938] loss_G: 2.913116, loss_D: 0.205314\n",
            "[Epoch 146/200] [Batch 680/938] loss_G: 2.699517, loss_D: 0.199063\n",
            "[Epoch 146/200] [Batch 690/938] loss_G: 3.256290, loss_D: 0.177669\n",
            "[Epoch 146/200] [Batch 700/938] loss_G: 2.887647, loss_D: 0.222236\n",
            "[Epoch 146/200] [Batch 710/938] loss_G: 2.501284, loss_D: 0.198709\n",
            "[Epoch 146/200] [Batch 720/938] loss_G: 3.008311, loss_D: 0.150291\n",
            "[Epoch 146/200] [Batch 730/938] loss_G: 2.765772, loss_D: 0.297610\n",
            "[Epoch 146/200] [Batch 740/938] loss_G: 3.419122, loss_D: 0.221183\n",
            "[Epoch 146/200] [Batch 750/938] loss_G: 2.900801, loss_D: 0.266848\n",
            "[Epoch 146/200] [Batch 760/938] loss_G: 2.945443, loss_D: 0.191349\n",
            "[Epoch 146/200] [Batch 770/938] loss_G: 3.714039, loss_D: 0.204511\n",
            "[Epoch 146/200] [Batch 780/938] loss_G: 3.019045, loss_D: 0.218788\n",
            "[Epoch 146/200] [Batch 790/938] loss_G: 3.053525, loss_D: 0.226837\n",
            "[Epoch 146/200] [Batch 800/938] loss_G: 2.945323, loss_D: 0.259254\n",
            "[Epoch 146/200] [Batch 810/938] loss_G: 2.908905, loss_D: 0.167664\n",
            "[Epoch 146/200] [Batch 820/938] loss_G: 2.971966, loss_D: 0.251947\n",
            "[Epoch 146/200] [Batch 830/938] loss_G: 3.052889, loss_D: 0.219426\n",
            "[Epoch 146/200] [Batch 840/938] loss_G: 2.972152, loss_D: 0.299748\n",
            "[Epoch 146/200] [Batch 850/938] loss_G: 2.825532, loss_D: 0.209272\n",
            "[Epoch 146/200] [Batch 860/938] loss_G: 3.112862, loss_D: 0.266609\n",
            "[Epoch 146/200] [Batch 870/938] loss_G: 3.623491, loss_D: 0.173291\n",
            "[Epoch 146/200] [Batch 880/938] loss_G: 3.041048, loss_D: 0.185046\n",
            "[Epoch 146/200] [Batch 890/938] loss_G: 3.212276, loss_D: 0.187852\n",
            "[Epoch 146/200] [Batch 900/938] loss_G: 3.318136, loss_D: 0.244107\n",
            "[Epoch 146/200] [Batch 910/938] loss_G: 2.968131, loss_D: 0.147432\n",
            "[Epoch 146/200] [Batch 920/938] loss_G: 3.123236, loss_D: 0.151460\n",
            "[Epoch 146/200] [Batch 930/938] loss_G: 3.203556, loss_D: 0.183431\n",
            "[Epoch 147/200] [Batch 0/938] loss_G: 3.217733, loss_D: 0.202985\n",
            "[Epoch 147/200] [Batch 10/938] loss_G: 3.291967, loss_D: 0.173859\n",
            "[Epoch 147/200] [Batch 20/938] loss_G: 2.776181, loss_D: 0.124797\n",
            "[Epoch 147/200] [Batch 30/938] loss_G: 3.350579, loss_D: 0.198668\n",
            "[Epoch 147/200] [Batch 40/938] loss_G: 3.577234, loss_D: 0.217936\n",
            "[Epoch 147/200] [Batch 50/938] loss_G: 3.051218, loss_D: 0.163087\n",
            "[Epoch 147/200] [Batch 60/938] loss_G: 3.269897, loss_D: 0.191380\n",
            "[Epoch 147/200] [Batch 70/938] loss_G: 2.907294, loss_D: 0.175687\n",
            "[Epoch 147/200] [Batch 80/938] loss_G: 3.066776, loss_D: 0.240993\n",
            "[Epoch 147/200] [Batch 90/938] loss_G: 3.011980, loss_D: 0.255572\n",
            "[Epoch 147/200] [Batch 100/938] loss_G: 2.968735, loss_D: 0.149013\n",
            "[Epoch 147/200] [Batch 110/938] loss_G: 3.140513, loss_D: 0.165502\n",
            "[Epoch 147/200] [Batch 120/938] loss_G: 2.763747, loss_D: 0.260270\n",
            "[Epoch 147/200] [Batch 130/938] loss_G: 3.115383, loss_D: 0.150036\n",
            "[Epoch 147/200] [Batch 140/938] loss_G: 3.011535, loss_D: 0.194896\n",
            "[Epoch 147/200] [Batch 150/938] loss_G: 2.857856, loss_D: 0.217661\n",
            "[Epoch 147/200] [Batch 160/938] loss_G: 3.174146, loss_D: 0.237051\n",
            "[Epoch 147/200] [Batch 170/938] loss_G: 2.847531, loss_D: 0.169676\n",
            "[Epoch 147/200] [Batch 180/938] loss_G: 3.173984, loss_D: 0.182313\n",
            "[Epoch 147/200] [Batch 190/938] loss_G: 3.330741, loss_D: 0.254362\n",
            "[Epoch 147/200] [Batch 200/938] loss_G: 2.945994, loss_D: 0.206148\n",
            "[Epoch 147/200] [Batch 210/938] loss_G: 3.314308, loss_D: 0.222066\n",
            "[Epoch 147/200] [Batch 220/938] loss_G: 2.849926, loss_D: 0.242014\n",
            "[Epoch 147/200] [Batch 230/938] loss_G: 2.939542, loss_D: 0.198622\n",
            "[Epoch 147/200] [Batch 240/938] loss_G: 2.735935, loss_D: 0.140691\n",
            "[Epoch 147/200] [Batch 250/938] loss_G: 3.126506, loss_D: 0.234364\n",
            "[Epoch 147/200] [Batch 260/938] loss_G: 3.259637, loss_D: 0.260668\n",
            "[Epoch 147/200] [Batch 270/938] loss_G: 2.689138, loss_D: 0.238433\n",
            "[Epoch 147/200] [Batch 280/938] loss_G: 2.824219, loss_D: 0.275070\n",
            "[Epoch 147/200] [Batch 290/938] loss_G: 2.732706, loss_D: 0.252886\n",
            "[Epoch 147/200] [Batch 300/938] loss_G: 3.147002, loss_D: 0.204248\n",
            "[Epoch 147/200] [Batch 310/938] loss_G: 2.559989, loss_D: 0.229821\n",
            "[Epoch 147/200] [Batch 320/938] loss_G: 3.136823, loss_D: 0.188489\n",
            "[Epoch 147/200] [Batch 330/938] loss_G: 3.210226, loss_D: 0.217121\n",
            "[Epoch 147/200] [Batch 340/938] loss_G: 3.190064, loss_D: 0.168999\n",
            "[Epoch 147/200] [Batch 350/938] loss_G: 3.446833, loss_D: 0.249022\n",
            "[Epoch 147/200] [Batch 360/938] loss_G: 2.796787, loss_D: 0.277396\n",
            "[Epoch 147/200] [Batch 370/938] loss_G: 2.912784, loss_D: 0.209879\n",
            "[Epoch 147/200] [Batch 380/938] loss_G: 3.356367, loss_D: 0.191426\n",
            "[Epoch 147/200] [Batch 390/938] loss_G: 3.280724, loss_D: 0.142143\n",
            "[Epoch 147/200] [Batch 400/938] loss_G: 2.670013, loss_D: 0.209048\n",
            "[Epoch 147/200] [Batch 410/938] loss_G: 3.057266, loss_D: 0.211663\n",
            "[Epoch 147/200] [Batch 420/938] loss_G: 2.782904, loss_D: 0.319967\n",
            "[Epoch 147/200] [Batch 430/938] loss_G: 3.240486, loss_D: 0.185051\n",
            "[Epoch 147/200] [Batch 440/938] loss_G: 2.908672, loss_D: 0.192781\n",
            "[Epoch 147/200] [Batch 450/938] loss_G: 3.094170, loss_D: 0.253937\n",
            "[Epoch 147/200] [Batch 460/938] loss_G: 3.038631, loss_D: 0.182495\n",
            "[Epoch 147/200] [Batch 470/938] loss_G: 3.133564, loss_D: 0.196506\n",
            "[Epoch 147/200] [Batch 480/938] loss_G: 3.292691, loss_D: 0.128313\n",
            "[Epoch 147/200] [Batch 490/938] loss_G: 3.365713, loss_D: 0.219087\n",
            "[Epoch 147/200] [Batch 500/938] loss_G: 3.151710, loss_D: 0.232750\n",
            "[Epoch 147/200] [Batch 510/938] loss_G: 2.969011, loss_D: 0.137584\n",
            "[Epoch 147/200] [Batch 520/938] loss_G: 2.769802, loss_D: 0.261621\n",
            "[Epoch 147/200] [Batch 530/938] loss_G: 3.165672, loss_D: 0.206607\n",
            "[Epoch 147/200] [Batch 540/938] loss_G: 3.373263, loss_D: 0.170979\n",
            "[Epoch 147/200] [Batch 550/938] loss_G: 3.110720, loss_D: 0.186192\n",
            "[Epoch 147/200] [Batch 560/938] loss_G: 2.861652, loss_D: 0.226827\n",
            "[Epoch 147/200] [Batch 570/938] loss_G: 3.224318, loss_D: 0.189606\n",
            "[Epoch 147/200] [Batch 580/938] loss_G: 3.326888, loss_D: 0.313764\n",
            "[Epoch 147/200] [Batch 590/938] loss_G: 2.992709, loss_D: 0.253574\n",
            "[Epoch 147/200] [Batch 600/938] loss_G: 3.264831, loss_D: 0.240542\n",
            "[Epoch 147/200] [Batch 610/938] loss_G: 2.937274, loss_D: 0.260820\n",
            "[Epoch 147/200] [Batch 620/938] loss_G: 2.547795, loss_D: 0.277699\n",
            "[Epoch 147/200] [Batch 630/938] loss_G: 2.770305, loss_D: 0.235849\n",
            "[Epoch 147/200] [Batch 640/938] loss_G: 2.712928, loss_D: 0.229900\n",
            "[Epoch 147/200] [Batch 650/938] loss_G: 3.467988, loss_D: 0.178919\n",
            "[Epoch 147/200] [Batch 660/938] loss_G: 2.963597, loss_D: 0.313788\n",
            "[Epoch 147/200] [Batch 670/938] loss_G: 3.313482, loss_D: 0.206599\n",
            "[Epoch 147/200] [Batch 680/938] loss_G: 3.161996, loss_D: 0.248885\n",
            "[Epoch 147/200] [Batch 690/938] loss_G: 3.085446, loss_D: 0.232951\n",
            "[Epoch 147/200] [Batch 700/938] loss_G: 2.724468, loss_D: 0.214398\n",
            "[Epoch 147/200] [Batch 710/938] loss_G: 3.198120, loss_D: 0.137792\n",
            "[Epoch 147/200] [Batch 720/938] loss_G: 3.044219, loss_D: 0.161619\n",
            "[Epoch 147/200] [Batch 730/938] loss_G: 2.724653, loss_D: 0.144351\n",
            "[Epoch 147/200] [Batch 740/938] loss_G: 3.342568, loss_D: 0.207069\n",
            "[Epoch 147/200] [Batch 750/938] loss_G: 2.868011, loss_D: 0.264115\n",
            "[Epoch 147/200] [Batch 760/938] loss_G: 3.059930, loss_D: 0.169989\n",
            "[Epoch 147/200] [Batch 770/938] loss_G: 3.403777, loss_D: 0.176194\n",
            "[Epoch 147/200] [Batch 780/938] loss_G: 2.897904, loss_D: 0.182360\n",
            "[Epoch 147/200] [Batch 790/938] loss_G: 3.233695, loss_D: 0.239022\n",
            "[Epoch 147/200] [Batch 800/938] loss_G: 3.136797, loss_D: 0.216653\n",
            "[Epoch 147/200] [Batch 810/938] loss_G: 3.400879, loss_D: 0.184942\n",
            "[Epoch 147/200] [Batch 820/938] loss_G: 3.245156, loss_D: 0.190915\n",
            "[Epoch 147/200] [Batch 830/938] loss_G: 2.837260, loss_D: 0.206233\n",
            "[Epoch 147/200] [Batch 840/938] loss_G: 3.145233, loss_D: 0.188475\n",
            "[Epoch 147/200] [Batch 850/938] loss_G: 2.826332, loss_D: 0.222966\n",
            "[Epoch 147/200] [Batch 860/938] loss_G: 2.827362, loss_D: 0.210482\n",
            "[Epoch 147/200] [Batch 870/938] loss_G: 3.088501, loss_D: 0.143154\n",
            "[Epoch 147/200] [Batch 880/938] loss_G: 2.832348, loss_D: 0.257044\n",
            "[Epoch 147/200] [Batch 890/938] loss_G: 3.217543, loss_D: 0.196094\n",
            "[Epoch 147/200] [Batch 900/938] loss_G: 3.460592, loss_D: 0.216662\n",
            "[Epoch 147/200] [Batch 910/938] loss_G: 2.893806, loss_D: 0.233691\n",
            "[Epoch 147/200] [Batch 920/938] loss_G: 3.420270, loss_D: 0.223644\n",
            "[Epoch 147/200] [Batch 930/938] loss_G: 3.226298, loss_D: 0.165493\n",
            "[Epoch 148/200] [Batch 0/938] loss_G: 2.861303, loss_D: 0.180699\n",
            "[Epoch 148/200] [Batch 10/938] loss_G: 3.159782, loss_D: 0.207890\n",
            "[Epoch 148/200] [Batch 20/938] loss_G: 3.366178, loss_D: 0.210386\n",
            "[Epoch 148/200] [Batch 30/938] loss_G: 2.663907, loss_D: 0.304120\n",
            "[Epoch 148/200] [Batch 40/938] loss_G: 2.907798, loss_D: 0.260331\n",
            "[Epoch 148/200] [Batch 50/938] loss_G: 3.434083, loss_D: 0.220281\n",
            "[Epoch 148/200] [Batch 60/938] loss_G: 3.396164, loss_D: 0.209180\n",
            "[Epoch 148/200] [Batch 70/938] loss_G: 3.099404, loss_D: 0.239742\n",
            "[Epoch 148/200] [Batch 80/938] loss_G: 3.223431, loss_D: 0.137018\n",
            "[Epoch 148/200] [Batch 90/938] loss_G: 3.236344, loss_D: 0.146795\n",
            "[Epoch 148/200] [Batch 100/938] loss_G: 3.488392, loss_D: 0.214975\n",
            "[Epoch 148/200] [Batch 110/938] loss_G: 3.159048, loss_D: 0.214149\n",
            "[Epoch 148/200] [Batch 120/938] loss_G: 3.118544, loss_D: 0.247010\n",
            "[Epoch 148/200] [Batch 130/938] loss_G: 3.085406, loss_D: 0.224542\n",
            "[Epoch 148/200] [Batch 140/938] loss_G: 3.395643, loss_D: 0.184974\n",
            "[Epoch 148/200] [Batch 150/938] loss_G: 3.289480, loss_D: 0.129520\n",
            "[Epoch 148/200] [Batch 160/938] loss_G: 2.603454, loss_D: 0.291737\n",
            "[Epoch 148/200] [Batch 170/938] loss_G: 2.969699, loss_D: 0.252597\n",
            "[Epoch 148/200] [Batch 180/938] loss_G: 3.336221, loss_D: 0.274216\n",
            "[Epoch 148/200] [Batch 190/938] loss_G: 3.413007, loss_D: 0.198014\n",
            "[Epoch 148/200] [Batch 200/938] loss_G: 2.516290, loss_D: 0.316086\n",
            "[Epoch 148/200] [Batch 210/938] loss_G: 3.033578, loss_D: 0.224438\n",
            "[Epoch 148/200] [Batch 220/938] loss_G: 2.711547, loss_D: 0.263577\n",
            "[Epoch 148/200] [Batch 230/938] loss_G: 3.199496, loss_D: 0.176740\n",
            "[Epoch 148/200] [Batch 240/938] loss_G: 3.229893, loss_D: 0.154447\n",
            "[Epoch 148/200] [Batch 250/938] loss_G: 2.874668, loss_D: 0.204788\n",
            "[Epoch 148/200] [Batch 260/938] loss_G: 3.093986, loss_D: 0.217686\n",
            "[Epoch 148/200] [Batch 270/938] loss_G: 2.937488, loss_D: 0.203245\n",
            "[Epoch 148/200] [Batch 280/938] loss_G: 2.944856, loss_D: 0.137179\n",
            "[Epoch 148/200] [Batch 290/938] loss_G: 2.924245, loss_D: 0.190731\n",
            "[Epoch 148/200] [Batch 300/938] loss_G: 3.000115, loss_D: 0.291814\n",
            "[Epoch 148/200] [Batch 310/938] loss_G: 2.818025, loss_D: 0.279670\n",
            "[Epoch 148/200] [Batch 320/938] loss_G: 3.357506, loss_D: 0.227631\n",
            "[Epoch 148/200] [Batch 330/938] loss_G: 3.305179, loss_D: 0.246955\n",
            "[Epoch 148/200] [Batch 340/938] loss_G: 3.151242, loss_D: 0.231608\n",
            "[Epoch 148/200] [Batch 350/938] loss_G: 3.378616, loss_D: 0.225803\n",
            "[Epoch 148/200] [Batch 360/938] loss_G: 3.367760, loss_D: 0.214639\n",
            "[Epoch 148/200] [Batch 370/938] loss_G: 3.110377, loss_D: 0.231686\n",
            "[Epoch 148/200] [Batch 380/938] loss_G: 3.282665, loss_D: 0.123008\n",
            "[Epoch 148/200] [Batch 390/938] loss_G: 3.055279, loss_D: 0.203958\n",
            "[Epoch 148/200] [Batch 400/938] loss_G: 3.079790, loss_D: 0.179862\n",
            "[Epoch 148/200] [Batch 410/938] loss_G: 3.180910, loss_D: 0.201778\n",
            "[Epoch 148/200] [Batch 420/938] loss_G: 2.839231, loss_D: 0.234787\n",
            "[Epoch 148/200] [Batch 430/938] loss_G: 3.364591, loss_D: 0.314958\n",
            "[Epoch 148/200] [Batch 440/938] loss_G: 2.576964, loss_D: 0.248771\n",
            "[Epoch 148/200] [Batch 450/938] loss_G: 2.795205, loss_D: 0.227465\n",
            "[Epoch 148/200] [Batch 460/938] loss_G: 3.284158, loss_D: 0.254979\n",
            "[Epoch 148/200] [Batch 470/938] loss_G: 3.297992, loss_D: 0.160116\n",
            "[Epoch 148/200] [Batch 480/938] loss_G: 3.324127, loss_D: 0.161508\n",
            "[Epoch 148/200] [Batch 490/938] loss_G: 2.989057, loss_D: 0.243272\n",
            "[Epoch 148/200] [Batch 500/938] loss_G: 3.049328, loss_D: 0.349253\n",
            "[Epoch 148/200] [Batch 510/938] loss_G: 2.885418, loss_D: 0.286247\n",
            "[Epoch 148/200] [Batch 520/938] loss_G: 3.053958, loss_D: 0.264652\n",
            "[Epoch 148/200] [Batch 530/938] loss_G: 3.064816, loss_D: 0.215015\n",
            "[Epoch 148/200] [Batch 540/938] loss_G: 3.487335, loss_D: 0.201474\n",
            "[Epoch 148/200] [Batch 550/938] loss_G: 3.023937, loss_D: 0.199480\n",
            "[Epoch 148/200] [Batch 560/938] loss_G: 3.406220, loss_D: 0.303958\n",
            "[Epoch 148/200] [Batch 570/938] loss_G: 2.513732, loss_D: 0.239446\n",
            "[Epoch 148/200] [Batch 580/938] loss_G: 2.941614, loss_D: 0.269261\n",
            "[Epoch 148/200] [Batch 590/938] loss_G: 2.929873, loss_D: 0.214443\n",
            "[Epoch 148/200] [Batch 600/938] loss_G: 3.020452, loss_D: 0.152952\n",
            "[Epoch 148/200] [Batch 610/938] loss_G: 2.815518, loss_D: 0.216010\n",
            "[Epoch 148/200] [Batch 620/938] loss_G: 3.168385, loss_D: 0.177240\n",
            "[Epoch 148/200] [Batch 630/938] loss_G: 2.851247, loss_D: 0.247515\n",
            "[Epoch 148/200] [Batch 640/938] loss_G: 2.933286, loss_D: 0.188256\n",
            "[Epoch 148/200] [Batch 650/938] loss_G: 2.883193, loss_D: 0.183374\n",
            "[Epoch 148/200] [Batch 660/938] loss_G: 3.119953, loss_D: 0.161812\n",
            "[Epoch 148/200] [Batch 670/938] loss_G: 2.621946, loss_D: 0.202905\n",
            "[Epoch 148/200] [Batch 680/938] loss_G: 3.227249, loss_D: 0.225554\n",
            "[Epoch 148/200] [Batch 690/938] loss_G: 3.363615, loss_D: 0.191618\n",
            "[Epoch 148/200] [Batch 700/938] loss_G: 2.681093, loss_D: 0.276397\n",
            "[Epoch 148/200] [Batch 710/938] loss_G: 2.843619, loss_D: 0.175355\n",
            "[Epoch 148/200] [Batch 720/938] loss_G: 3.146213, loss_D: 0.228871\n",
            "[Epoch 148/200] [Batch 730/938] loss_G: 3.073134, loss_D: 0.286094\n",
            "[Epoch 148/200] [Batch 740/938] loss_G: 2.880876, loss_D: 0.292234\n",
            "[Epoch 148/200] [Batch 750/938] loss_G: 3.096879, loss_D: 0.198558\n",
            "[Epoch 148/200] [Batch 760/938] loss_G: 3.060685, loss_D: 0.129855\n",
            "[Epoch 148/200] [Batch 770/938] loss_G: 2.856500, loss_D: 0.207827\n",
            "[Epoch 148/200] [Batch 780/938] loss_G: 3.157298, loss_D: 0.193459\n",
            "[Epoch 148/200] [Batch 790/938] loss_G: 3.347851, loss_D: 0.123480\n",
            "[Epoch 148/200] [Batch 800/938] loss_G: 2.916510, loss_D: 0.236960\n",
            "[Epoch 148/200] [Batch 810/938] loss_G: 2.911895, loss_D: 0.265431\n",
            "[Epoch 148/200] [Batch 820/938] loss_G: 2.982493, loss_D: 0.209093\n",
            "[Epoch 148/200] [Batch 830/938] loss_G: 2.824075, loss_D: 0.212468\n",
            "[Epoch 148/200] [Batch 840/938] loss_G: 2.946907, loss_D: 0.228602\n",
            "[Epoch 148/200] [Batch 850/938] loss_G: 3.080293, loss_D: 0.168277\n",
            "[Epoch 148/200] [Batch 860/938] loss_G: 2.993232, loss_D: 0.228308\n",
            "[Epoch 148/200] [Batch 870/938] loss_G: 2.927298, loss_D: 0.207119\n",
            "[Epoch 148/200] [Batch 880/938] loss_G: 3.276772, loss_D: 0.204120\n",
            "[Epoch 148/200] [Batch 890/938] loss_G: 3.346248, loss_D: 0.178576\n",
            "[Epoch 148/200] [Batch 900/938] loss_G: 2.887424, loss_D: 0.242074\n",
            "[Epoch 148/200] [Batch 910/938] loss_G: 3.243150, loss_D: 0.228271\n",
            "[Epoch 148/200] [Batch 920/938] loss_G: 3.194352, loss_D: 0.285529\n",
            "[Epoch 148/200] [Batch 930/938] loss_G: 2.975220, loss_D: 0.271798\n",
            "[Epoch 149/200] [Batch 0/938] loss_G: 3.292129, loss_D: 0.179003\n",
            "[Epoch 149/200] [Batch 10/938] loss_G: 3.060929, loss_D: 0.240336\n",
            "[Epoch 149/200] [Batch 20/938] loss_G: 2.966602, loss_D: 0.310288\n",
            "[Epoch 149/200] [Batch 30/938] loss_G: 3.289195, loss_D: 0.174133\n",
            "[Epoch 149/200] [Batch 40/938] loss_G: 2.752559, loss_D: 0.233569\n",
            "[Epoch 149/200] [Batch 50/938] loss_G: 3.011977, loss_D: 0.202487\n",
            "[Epoch 149/200] [Batch 60/938] loss_G: 3.221273, loss_D: 0.217504\n",
            "[Epoch 149/200] [Batch 70/938] loss_G: 2.874834, loss_D: 0.232637\n",
            "[Epoch 149/200] [Batch 80/938] loss_G: 3.447404, loss_D: 0.207065\n",
            "[Epoch 149/200] [Batch 90/938] loss_G: 3.075703, loss_D: 0.162068\n",
            "[Epoch 149/200] [Batch 100/938] loss_G: 2.854954, loss_D: 0.228873\n",
            "[Epoch 149/200] [Batch 110/938] loss_G: 3.259574, loss_D: 0.225484\n",
            "[Epoch 149/200] [Batch 120/938] loss_G: 3.142082, loss_D: 0.170905\n",
            "[Epoch 149/200] [Batch 130/938] loss_G: 3.140935, loss_D: 0.154498\n",
            "[Epoch 149/200] [Batch 140/938] loss_G: 2.753349, loss_D: 0.264091\n",
            "[Epoch 149/200] [Batch 150/938] loss_G: 3.033844, loss_D: 0.212499\n",
            "[Epoch 149/200] [Batch 160/938] loss_G: 3.159355, loss_D: 0.229917\n",
            "[Epoch 149/200] [Batch 170/938] loss_G: 3.101839, loss_D: 0.159005\n",
            "[Epoch 149/200] [Batch 180/938] loss_G: 3.384089, loss_D: 0.184809\n",
            "[Epoch 149/200] [Batch 190/938] loss_G: 3.738344, loss_D: 0.135319\n",
            "[Epoch 149/200] [Batch 200/938] loss_G: 2.618268, loss_D: 0.178502\n",
            "[Epoch 149/200] [Batch 210/938] loss_G: 3.157649, loss_D: 0.207561\n",
            "[Epoch 149/200] [Batch 220/938] loss_G: 3.264933, loss_D: 0.189562\n",
            "[Epoch 149/200] [Batch 230/938] loss_G: 2.759485, loss_D: 0.204915\n",
            "[Epoch 149/200] [Batch 240/938] loss_G: 2.945469, loss_D: 0.156807\n",
            "[Epoch 149/200] [Batch 250/938] loss_G: 2.863911, loss_D: 0.160986\n",
            "[Epoch 149/200] [Batch 260/938] loss_G: 3.094940, loss_D: 0.188686\n",
            "[Epoch 149/200] [Batch 270/938] loss_G: 3.354826, loss_D: 0.279838\n",
            "[Epoch 149/200] [Batch 280/938] loss_G: 3.154267, loss_D: 0.157086\n",
            "[Epoch 149/200] [Batch 290/938] loss_G: 2.885710, loss_D: 0.230192\n",
            "[Epoch 149/200] [Batch 300/938] loss_G: 3.029705, loss_D: 0.195351\n",
            "[Epoch 149/200] [Batch 310/938] loss_G: 2.939003, loss_D: 0.230881\n",
            "[Epoch 149/200] [Batch 320/938] loss_G: 2.808141, loss_D: 0.105486\n",
            "[Epoch 149/200] [Batch 330/938] loss_G: 3.079093, loss_D: 0.221348\n",
            "[Epoch 149/200] [Batch 340/938] loss_G: 3.299798, loss_D: 0.207291\n",
            "[Epoch 149/200] [Batch 350/938] loss_G: 3.214356, loss_D: 0.215979\n",
            "[Epoch 149/200] [Batch 360/938] loss_G: 2.889403, loss_D: 0.249502\n",
            "[Epoch 149/200] [Batch 370/938] loss_G: 2.899211, loss_D: 0.208234\n",
            "[Epoch 149/200] [Batch 380/938] loss_G: 3.094788, loss_D: 0.225990\n",
            "[Epoch 149/200] [Batch 390/938] loss_G: 3.205726, loss_D: 0.289672\n",
            "[Epoch 149/200] [Batch 400/938] loss_G: 2.910201, loss_D: 0.120191\n",
            "[Epoch 149/200] [Batch 410/938] loss_G: 3.324639, loss_D: 0.224402\n",
            "[Epoch 149/200] [Batch 420/938] loss_G: 3.423873, loss_D: 0.227722\n",
            "[Epoch 149/200] [Batch 430/938] loss_G: 2.957934, loss_D: 0.207790\n",
            "[Epoch 149/200] [Batch 440/938] loss_G: 2.776349, loss_D: 0.186675\n",
            "[Epoch 149/200] [Batch 450/938] loss_G: 3.245481, loss_D: 0.185050\n",
            "[Epoch 149/200] [Batch 460/938] loss_G: 3.353532, loss_D: 0.205299\n",
            "[Epoch 149/200] [Batch 470/938] loss_G: 2.634669, loss_D: 0.239129\n",
            "[Epoch 149/200] [Batch 480/938] loss_G: 2.835431, loss_D: 0.147615\n",
            "[Epoch 149/200] [Batch 490/938] loss_G: 3.417587, loss_D: 0.266350\n",
            "[Epoch 149/200] [Batch 500/938] loss_G: 2.732133, loss_D: 0.421664\n",
            "[Epoch 149/200] [Batch 510/938] loss_G: 3.007329, loss_D: 0.162838\n",
            "[Epoch 149/200] [Batch 520/938] loss_G: 2.784370, loss_D: 0.152219\n",
            "[Epoch 149/200] [Batch 530/938] loss_G: 3.208331, loss_D: 0.278004\n",
            "[Epoch 149/200] [Batch 540/938] loss_G: 2.957498, loss_D: 0.131561\n",
            "[Epoch 149/200] [Batch 550/938] loss_G: 2.751559, loss_D: 0.213889\n",
            "[Epoch 149/200] [Batch 560/938] loss_G: 3.509817, loss_D: 0.183497\n",
            "[Epoch 149/200] [Batch 570/938] loss_G: 2.800452, loss_D: 0.196932\n",
            "[Epoch 149/200] [Batch 580/938] loss_G: 2.987711, loss_D: 0.254831\n",
            "[Epoch 149/200] [Batch 590/938] loss_G: 3.288268, loss_D: 0.233001\n",
            "[Epoch 149/200] [Batch 600/938] loss_G: 2.837044, loss_D: 0.142969\n",
            "[Epoch 149/200] [Batch 610/938] loss_G: 3.059768, loss_D: 0.292215\n",
            "[Epoch 149/200] [Batch 620/938] loss_G: 3.000217, loss_D: 0.148449\n",
            "[Epoch 149/200] [Batch 630/938] loss_G: 2.940889, loss_D: 0.238467\n",
            "[Epoch 149/200] [Batch 640/938] loss_G: 3.296917, loss_D: 0.241415\n",
            "[Epoch 149/200] [Batch 650/938] loss_G: 3.399332, loss_D: 0.258253\n",
            "[Epoch 149/200] [Batch 660/938] loss_G: 3.492718, loss_D: 0.175011\n",
            "[Epoch 149/200] [Batch 670/938] loss_G: 2.941647, loss_D: 0.228713\n",
            "[Epoch 149/200] [Batch 680/938] loss_G: 3.402912, loss_D: 0.212392\n",
            "[Epoch 149/200] [Batch 690/938] loss_G: 2.909126, loss_D: 0.154428\n",
            "[Epoch 149/200] [Batch 700/938] loss_G: 3.189622, loss_D: 0.221839\n",
            "[Epoch 149/200] [Batch 710/938] loss_G: 3.367797, loss_D: 0.192494\n",
            "[Epoch 149/200] [Batch 720/938] loss_G: 2.946523, loss_D: 0.153883\n",
            "[Epoch 149/200] [Batch 730/938] loss_G: 3.170750, loss_D: 0.204327\n",
            "[Epoch 149/200] [Batch 740/938] loss_G: 3.269222, loss_D: 0.289082\n",
            "[Epoch 149/200] [Batch 750/938] loss_G: 3.086674, loss_D: 0.243025\n",
            "[Epoch 149/200] [Batch 760/938] loss_G: 3.001796, loss_D: 0.197246\n",
            "[Epoch 149/200] [Batch 770/938] loss_G: 3.341412, loss_D: 0.227448\n",
            "[Epoch 149/200] [Batch 780/938] loss_G: 2.877452, loss_D: 0.194775\n",
            "[Epoch 149/200] [Batch 790/938] loss_G: 2.879616, loss_D: 0.149650\n",
            "[Epoch 149/200] [Batch 800/938] loss_G: 3.271189, loss_D: 0.198854\n",
            "[Epoch 149/200] [Batch 810/938] loss_G: 3.051156, loss_D: 0.137266\n",
            "[Epoch 149/200] [Batch 820/938] loss_G: 3.058262, loss_D: 0.138418\n",
            "[Epoch 149/200] [Batch 830/938] loss_G: 2.888583, loss_D: 0.222753\n",
            "[Epoch 149/200] [Batch 840/938] loss_G: 3.389195, loss_D: 0.176484\n",
            "[Epoch 149/200] [Batch 850/938] loss_G: 3.056363, loss_D: 0.232951\n",
            "[Epoch 149/200] [Batch 860/938] loss_G: 2.795852, loss_D: 0.252424\n",
            "[Epoch 149/200] [Batch 870/938] loss_G: 2.900715, loss_D: 0.209511\n",
            "[Epoch 149/200] [Batch 880/938] loss_G: 3.525717, loss_D: 0.175098\n",
            "[Epoch 149/200] [Batch 890/938] loss_G: 3.015651, loss_D: 0.133650\n",
            "[Epoch 149/200] [Batch 900/938] loss_G: 3.172970, loss_D: 0.228383\n",
            "[Epoch 149/200] [Batch 910/938] loss_G: 2.974393, loss_D: 0.246898\n",
            "[Epoch 149/200] [Batch 920/938] loss_G: 3.136591, loss_D: 0.139507\n",
            "[Epoch 149/200] [Batch 930/938] loss_G: 3.305663, loss_D: 0.344466\n",
            "[Epoch 150/200] [Batch 0/938] loss_G: 3.246616, loss_D: 0.176149\n",
            "[Epoch 150/200] [Batch 10/938] loss_G: 2.945568, loss_D: 0.134932\n",
            "[Epoch 150/200] [Batch 20/938] loss_G: 3.219309, loss_D: 0.222956\n",
            "[Epoch 150/200] [Batch 30/938] loss_G: 2.793786, loss_D: 0.337163\n",
            "[Epoch 150/200] [Batch 40/938] loss_G: 2.833204, loss_D: 0.282648\n",
            "[Epoch 150/200] [Batch 50/938] loss_G: 3.064909, loss_D: 0.119489\n",
            "[Epoch 150/200] [Batch 60/938] loss_G: 3.039332, loss_D: 0.187943\n",
            "[Epoch 150/200] [Batch 70/938] loss_G: 2.965755, loss_D: 0.236933\n",
            "[Epoch 150/200] [Batch 80/938] loss_G: 3.163852, loss_D: 0.206462\n",
            "[Epoch 150/200] [Batch 90/938] loss_G: 3.210170, loss_D: 0.131896\n",
            "[Epoch 150/200] [Batch 100/938] loss_G: 2.983295, loss_D: 0.161230\n",
            "[Epoch 150/200] [Batch 110/938] loss_G: 2.860754, loss_D: 0.314838\n",
            "[Epoch 150/200] [Batch 120/938] loss_G: 3.072285, loss_D: 0.199632\n",
            "[Epoch 150/200] [Batch 130/938] loss_G: 2.729444, loss_D: 0.232862\n",
            "[Epoch 150/200] [Batch 140/938] loss_G: 3.088087, loss_D: 0.291482\n",
            "[Epoch 150/200] [Batch 150/938] loss_G: 2.825990, loss_D: 0.230991\n",
            "[Epoch 150/200] [Batch 160/938] loss_G: 3.606724, loss_D: 0.247867\n",
            "[Epoch 150/200] [Batch 170/938] loss_G: 3.126728, loss_D: 0.225263\n",
            "[Epoch 150/200] [Batch 180/938] loss_G: 3.070780, loss_D: 0.203965\n",
            "[Epoch 150/200] [Batch 190/938] loss_G: 2.743450, loss_D: 0.179304\n",
            "[Epoch 150/200] [Batch 200/938] loss_G: 3.738265, loss_D: 0.194431\n",
            "[Epoch 150/200] [Batch 210/938] loss_G: 2.613883, loss_D: 0.263424\n",
            "[Epoch 150/200] [Batch 220/938] loss_G: 3.248758, loss_D: 0.179922\n",
            "[Epoch 150/200] [Batch 230/938] loss_G: 2.949205, loss_D: 0.213209\n",
            "[Epoch 150/200] [Batch 240/938] loss_G: 2.936356, loss_D: 0.146420\n",
            "[Epoch 150/200] [Batch 250/938] loss_G: 3.174799, loss_D: 0.219815\n",
            "[Epoch 150/200] [Batch 260/938] loss_G: 3.188330, loss_D: 0.241749\n",
            "[Epoch 150/200] [Batch 270/938] loss_G: 3.008600, loss_D: 0.272856\n",
            "[Epoch 150/200] [Batch 280/938] loss_G: 2.876453, loss_D: 0.204932\n",
            "[Epoch 150/200] [Batch 290/938] loss_G: 3.339956, loss_D: 0.228900\n",
            "[Epoch 150/200] [Batch 300/938] loss_G: 2.812369, loss_D: 0.221314\n",
            "[Epoch 150/200] [Batch 310/938] loss_G: 3.300095, loss_D: 0.204042\n",
            "[Epoch 150/200] [Batch 320/938] loss_G: 3.285683, loss_D: 0.157946\n",
            "[Epoch 150/200] [Batch 330/938] loss_G: 3.178455, loss_D: 0.213177\n",
            "[Epoch 150/200] [Batch 340/938] loss_G: 3.198225, loss_D: 0.182041\n",
            "[Epoch 150/200] [Batch 350/938] loss_G: 3.275016, loss_D: 0.145075\n",
            "[Epoch 150/200] [Batch 360/938] loss_G: 2.927116, loss_D: 0.202508\n",
            "[Epoch 150/200] [Batch 370/938] loss_G: 3.113350, loss_D: 0.225414\n",
            "[Epoch 150/200] [Batch 380/938] loss_G: 2.705500, loss_D: 0.242693\n",
            "[Epoch 150/200] [Batch 390/938] loss_G: 2.820749, loss_D: 0.142029\n",
            "[Epoch 150/200] [Batch 400/938] loss_G: 3.142219, loss_D: 0.223305\n",
            "[Epoch 150/200] [Batch 410/938] loss_G: 3.207752, loss_D: 0.231702\n",
            "[Epoch 150/200] [Batch 420/938] loss_G: 2.977755, loss_D: 0.199171\n",
            "[Epoch 150/200] [Batch 430/938] loss_G: 3.118236, loss_D: 0.225824\n",
            "[Epoch 150/200] [Batch 440/938] loss_G: 2.808424, loss_D: 0.242980\n",
            "[Epoch 150/200] [Batch 450/938] loss_G: 3.040321, loss_D: 0.214231\n",
            "[Epoch 150/200] [Batch 460/938] loss_G: 3.165454, loss_D: 0.227965\n",
            "[Epoch 150/200] [Batch 470/938] loss_G: 2.972884, loss_D: 0.161656\n",
            "[Epoch 150/200] [Batch 480/938] loss_G: 3.400820, loss_D: 0.158021\n",
            "[Epoch 150/200] [Batch 490/938] loss_G: 3.027395, loss_D: 0.145903\n",
            "[Epoch 150/200] [Batch 500/938] loss_G: 3.384531, loss_D: 0.242403\n",
            "[Epoch 150/200] [Batch 510/938] loss_G: 3.087632, loss_D: 0.232755\n",
            "[Epoch 150/200] [Batch 520/938] loss_G: 3.122833, loss_D: 0.203372\n",
            "[Epoch 150/200] [Batch 530/938] loss_G: 3.525306, loss_D: 0.150316\n",
            "[Epoch 150/200] [Batch 540/938] loss_G: 3.514514, loss_D: 0.176396\n",
            "[Epoch 150/200] [Batch 550/938] loss_G: 3.506815, loss_D: 0.250048\n",
            "[Epoch 150/200] [Batch 560/938] loss_G: 3.267807, loss_D: 0.190556\n",
            "[Epoch 150/200] [Batch 570/938] loss_G: 2.978693, loss_D: 0.227709\n",
            "[Epoch 150/200] [Batch 580/938] loss_G: 2.955733, loss_D: 0.176890\n",
            "[Epoch 150/200] [Batch 590/938] loss_G: 3.129003, loss_D: 0.116861\n",
            "[Epoch 150/200] [Batch 600/938] loss_G: 2.679849, loss_D: 0.146689\n",
            "[Epoch 150/200] [Batch 610/938] loss_G: 3.241381, loss_D: 0.223539\n",
            "[Epoch 150/200] [Batch 620/938] loss_G: 3.292116, loss_D: 0.173048\n",
            "[Epoch 150/200] [Batch 630/938] loss_G: 2.810359, loss_D: 0.250335\n",
            "[Epoch 150/200] [Batch 640/938] loss_G: 3.246155, loss_D: 0.231688\n",
            "[Epoch 150/200] [Batch 650/938] loss_G: 3.233191, loss_D: 0.245417\n",
            "[Epoch 150/200] [Batch 660/938] loss_G: 2.472750, loss_D: 0.269048\n",
            "[Epoch 150/200] [Batch 670/938] loss_G: 2.843033, loss_D: 0.263170\n",
            "[Epoch 150/200] [Batch 680/938] loss_G: 2.358641, loss_D: 0.263768\n",
            "[Epoch 150/200] [Batch 690/938] loss_G: 3.405561, loss_D: 0.129648\n",
            "[Epoch 150/200] [Batch 700/938] loss_G: 3.201246, loss_D: 0.172385\n",
            "[Epoch 150/200] [Batch 710/938] loss_G: 2.802959, loss_D: 0.185005\n",
            "[Epoch 150/200] [Batch 720/938] loss_G: 2.935007, loss_D: 0.227203\n",
            "[Epoch 150/200] [Batch 730/938] loss_G: 3.352903, loss_D: 0.208524\n",
            "[Epoch 150/200] [Batch 740/938] loss_G: 2.691262, loss_D: 0.163168\n",
            "[Epoch 150/200] [Batch 750/938] loss_G: 2.950613, loss_D: 0.205679\n",
            "[Epoch 150/200] [Batch 760/938] loss_G: 3.004035, loss_D: 0.170336\n",
            "[Epoch 150/200] [Batch 770/938] loss_G: 2.599271, loss_D: 0.210044\n",
            "[Epoch 150/200] [Batch 780/938] loss_G: 3.143383, loss_D: 0.264113\n",
            "[Epoch 150/200] [Batch 790/938] loss_G: 3.252073, loss_D: 0.154769\n",
            "[Epoch 150/200] [Batch 800/938] loss_G: 2.830450, loss_D: 0.245610\n",
            "[Epoch 150/200] [Batch 810/938] loss_G: 2.997299, loss_D: 0.188818\n",
            "[Epoch 150/200] [Batch 820/938] loss_G: 2.643182, loss_D: 0.197953\n",
            "[Epoch 150/200] [Batch 830/938] loss_G: 2.705723, loss_D: 0.239807\n",
            "[Epoch 150/200] [Batch 840/938] loss_G: 3.463758, loss_D: 0.154787\n",
            "[Epoch 150/200] [Batch 850/938] loss_G: 2.884789, loss_D: 0.215189\n",
            "[Epoch 150/200] [Batch 860/938] loss_G: 3.216712, loss_D: 0.290682\n",
            "[Epoch 150/200] [Batch 870/938] loss_G: 2.893728, loss_D: 0.164524\n",
            "[Epoch 150/200] [Batch 880/938] loss_G: 2.978806, loss_D: 0.188469\n",
            "[Epoch 150/200] [Batch 890/938] loss_G: 2.653626, loss_D: 0.222061\n",
            "[Epoch 150/200] [Batch 900/938] loss_G: 3.075288, loss_D: 0.235119\n",
            "[Epoch 150/200] [Batch 910/938] loss_G: 2.651276, loss_D: 0.199381\n",
            "[Epoch 150/200] [Batch 920/938] loss_G: 3.236548, loss_D: 0.275301\n",
            "[Epoch 150/200] [Batch 930/938] loss_G: 2.811222, loss_D: 0.207188\n",
            "[Epoch 151/200] [Batch 0/938] loss_G: 3.254772, loss_D: 0.208236\n",
            "[Epoch 151/200] [Batch 10/938] loss_G: 3.327916, loss_D: 0.119201\n",
            "[Epoch 151/200] [Batch 20/938] loss_G: 3.224964, loss_D: 0.171108\n",
            "[Epoch 151/200] [Batch 30/938] loss_G: 3.189259, loss_D: 0.172494\n",
            "[Epoch 151/200] [Batch 40/938] loss_G: 2.889158, loss_D: 0.218402\n",
            "[Epoch 151/200] [Batch 50/938] loss_G: 2.884221, loss_D: 0.230658\n",
            "[Epoch 151/200] [Batch 60/938] loss_G: 3.020273, loss_D: 0.107734\n",
            "[Epoch 151/200] [Batch 70/938] loss_G: 2.956179, loss_D: 0.202915\n",
            "[Epoch 151/200] [Batch 80/938] loss_G: 2.898638, loss_D: 0.191091\n",
            "[Epoch 151/200] [Batch 90/938] loss_G: 3.096270, loss_D: 0.134588\n",
            "[Epoch 151/200] [Batch 100/938] loss_G: 3.359455, loss_D: 0.204605\n",
            "[Epoch 151/200] [Batch 110/938] loss_G: 2.921340, loss_D: 0.181338\n",
            "[Epoch 151/200] [Batch 120/938] loss_G: 2.883373, loss_D: 0.202029\n",
            "[Epoch 151/200] [Batch 130/938] loss_G: 3.088811, loss_D: 0.203616\n",
            "[Epoch 151/200] [Batch 140/938] loss_G: 2.836724, loss_D: 0.206239\n",
            "[Epoch 151/200] [Batch 150/938] loss_G: 3.247901, loss_D: 0.202957\n",
            "[Epoch 151/200] [Batch 160/938] loss_G: 3.305148, loss_D: 0.142181\n",
            "[Epoch 151/200] [Batch 170/938] loss_G: 3.371910, loss_D: 0.274343\n",
            "[Epoch 151/200] [Batch 180/938] loss_G: 2.631185, loss_D: 0.275225\n",
            "[Epoch 151/200] [Batch 190/938] loss_G: 2.935780, loss_D: 0.195692\n",
            "[Epoch 151/200] [Batch 200/938] loss_G: 3.395848, loss_D: 0.210898\n",
            "[Epoch 151/200] [Batch 210/938] loss_G: 3.197189, loss_D: 0.192174\n",
            "[Epoch 151/200] [Batch 220/938] loss_G: 3.012143, loss_D: 0.201839\n",
            "[Epoch 151/200] [Batch 230/938] loss_G: 3.202398, loss_D: 0.210826\n",
            "[Epoch 151/200] [Batch 240/938] loss_G: 2.999528, loss_D: 0.261249\n",
            "[Epoch 151/200] [Batch 250/938] loss_G: 2.860544, loss_D: 0.196998\n",
            "[Epoch 151/200] [Batch 260/938] loss_G: 3.207809, loss_D: 0.154203\n",
            "[Epoch 151/200] [Batch 270/938] loss_G: 3.133569, loss_D: 0.244357\n",
            "[Epoch 151/200] [Batch 280/938] loss_G: 3.093479, loss_D: 0.152211\n",
            "[Epoch 151/200] [Batch 290/938] loss_G: 2.754580, loss_D: 0.258845\n",
            "[Epoch 151/200] [Batch 300/938] loss_G: 2.802085, loss_D: 0.234938\n",
            "[Epoch 151/200] [Batch 310/938] loss_G: 3.189478, loss_D: 0.261182\n",
            "[Epoch 151/200] [Batch 320/938] loss_G: 3.260001, loss_D: 0.179704\n",
            "[Epoch 151/200] [Batch 330/938] loss_G: 2.919989, loss_D: 0.199932\n",
            "[Epoch 151/200] [Batch 340/938] loss_G: 2.982048, loss_D: 0.130759\n",
            "[Epoch 151/200] [Batch 350/938] loss_G: 3.182758, loss_D: 0.290052\n",
            "[Epoch 151/200] [Batch 360/938] loss_G: 2.787740, loss_D: 0.227019\n",
            "[Epoch 151/200] [Batch 370/938] loss_G: 2.436221, loss_D: 0.259242\n",
            "[Epoch 151/200] [Batch 380/938] loss_G: 2.795140, loss_D: 0.247404\n",
            "[Epoch 151/200] [Batch 390/938] loss_G: 2.987235, loss_D: 0.173763\n",
            "[Epoch 151/200] [Batch 400/938] loss_G: 3.111554, loss_D: 0.153649\n",
            "[Epoch 151/200] [Batch 410/938] loss_G: 2.996938, loss_D: 0.213119\n",
            "[Epoch 151/200] [Batch 420/938] loss_G: 3.043903, loss_D: 0.145515\n",
            "[Epoch 151/200] [Batch 430/938] loss_G: 2.852786, loss_D: 0.199058\n",
            "[Epoch 151/200] [Batch 440/938] loss_G: 3.163578, loss_D: 0.184318\n",
            "[Epoch 151/200] [Batch 450/938] loss_G: 3.003355, loss_D: 0.189516\n",
            "[Epoch 151/200] [Batch 460/938] loss_G: 3.064178, loss_D: 0.128401\n",
            "[Epoch 151/200] [Batch 470/938] loss_G: 3.051327, loss_D: 0.211348\n",
            "[Epoch 151/200] [Batch 480/938] loss_G: 3.276633, loss_D: 0.262599\n",
            "[Epoch 151/200] [Batch 490/938] loss_G: 3.174913, loss_D: 0.152136\n",
            "[Epoch 151/200] [Batch 500/938] loss_G: 3.508136, loss_D: 0.237696\n",
            "[Epoch 151/200] [Batch 510/938] loss_G: 2.915727, loss_D: 0.188770\n",
            "[Epoch 151/200] [Batch 520/938] loss_G: 3.316525, loss_D: 0.212522\n",
            "[Epoch 151/200] [Batch 530/938] loss_G: 3.269199, loss_D: 0.357471\n",
            "[Epoch 151/200] [Batch 540/938] loss_G: 2.846247, loss_D: 0.244939\n",
            "[Epoch 151/200] [Batch 550/938] loss_G: 2.944892, loss_D: 0.215892\n",
            "[Epoch 151/200] [Batch 560/938] loss_G: 3.170122, loss_D: 0.211428\n",
            "[Epoch 151/200] [Batch 570/938] loss_G: 3.406213, loss_D: 0.113857\n",
            "[Epoch 151/200] [Batch 580/938] loss_G: 2.966566, loss_D: 0.265443\n",
            "[Epoch 151/200] [Batch 590/938] loss_G: 3.220011, loss_D: 0.225653\n",
            "[Epoch 151/200] [Batch 600/938] loss_G: 3.578692, loss_D: 0.209209\n",
            "[Epoch 151/200] [Batch 610/938] loss_G: 3.437737, loss_D: 0.287857\n",
            "[Epoch 151/200] [Batch 620/938] loss_G: 3.385239, loss_D: 0.186761\n",
            "[Epoch 151/200] [Batch 630/938] loss_G: 3.434440, loss_D: 0.127656\n",
            "[Epoch 151/200] [Batch 640/938] loss_G: 2.936158, loss_D: 0.176805\n",
            "[Epoch 151/200] [Batch 650/938] loss_G: 3.369619, loss_D: 0.197479\n",
            "[Epoch 151/200] [Batch 660/938] loss_G: 3.102412, loss_D: 0.194293\n",
            "[Epoch 151/200] [Batch 670/938] loss_G: 2.862914, loss_D: 0.167213\n",
            "[Epoch 151/200] [Batch 680/938] loss_G: 3.265838, loss_D: 0.188931\n",
            "[Epoch 151/200] [Batch 690/938] loss_G: 3.291179, loss_D: 0.189446\n",
            "[Epoch 151/200] [Batch 700/938] loss_G: 2.856753, loss_D: 0.169437\n",
            "[Epoch 151/200] [Batch 710/938] loss_G: 3.184347, loss_D: 0.246353\n",
            "[Epoch 151/200] [Batch 720/938] loss_G: 3.202030, loss_D: 0.195165\n",
            "[Epoch 151/200] [Batch 730/938] loss_G: 3.332516, loss_D: 0.281031\n",
            "[Epoch 151/200] [Batch 740/938] loss_G: 2.912048, loss_D: 0.216182\n",
            "[Epoch 151/200] [Batch 750/938] loss_G: 3.089604, loss_D: 0.206469\n",
            "[Epoch 151/200] [Batch 760/938] loss_G: 3.546828, loss_D: 0.113456\n",
            "[Epoch 151/200] [Batch 770/938] loss_G: 2.893812, loss_D: 0.219256\n",
            "[Epoch 151/200] [Batch 780/938] loss_G: 3.239233, loss_D: 0.174146\n",
            "[Epoch 151/200] [Batch 790/938] loss_G: 3.280102, loss_D: 0.158052\n",
            "[Epoch 151/200] [Batch 800/938] loss_G: 3.017244, loss_D: 0.261614\n",
            "[Epoch 151/200] [Batch 810/938] loss_G: 3.226281, loss_D: 0.226423\n",
            "[Epoch 151/200] [Batch 820/938] loss_G: 2.697046, loss_D: 0.233472\n",
            "[Epoch 151/200] [Batch 830/938] loss_G: 2.968529, loss_D: 0.225360\n",
            "[Epoch 151/200] [Batch 840/938] loss_G: 3.012634, loss_D: 0.237884\n",
            "[Epoch 151/200] [Batch 850/938] loss_G: 2.840312, loss_D: 0.191698\n",
            "[Epoch 151/200] [Batch 860/938] loss_G: 2.935417, loss_D: 0.133645\n",
            "[Epoch 151/200] [Batch 870/938] loss_G: 3.059817, loss_D: 0.172403\n",
            "[Epoch 151/200] [Batch 880/938] loss_G: 2.588846, loss_D: 0.272529\n",
            "[Epoch 151/200] [Batch 890/938] loss_G: 2.973088, loss_D: 0.173419\n",
            "[Epoch 151/200] [Batch 900/938] loss_G: 2.826495, loss_D: 0.171987\n",
            "[Epoch 151/200] [Batch 910/938] loss_G: 3.363335, loss_D: 0.248263\n",
            "[Epoch 151/200] [Batch 920/938] loss_G: 3.181590, loss_D: 0.254275\n",
            "[Epoch 151/200] [Batch 930/938] loss_G: 3.129869, loss_D: 0.145946\n",
            "[Epoch 152/200] [Batch 0/938] loss_G: 2.982722, loss_D: 0.159562\n",
            "[Epoch 152/200] [Batch 10/938] loss_G: 3.001791, loss_D: 0.245767\n",
            "[Epoch 152/200] [Batch 20/938] loss_G: 3.006599, loss_D: 0.194946\n",
            "[Epoch 152/200] [Batch 30/938] loss_G: 3.071056, loss_D: 0.204791\n",
            "[Epoch 152/200] [Batch 40/938] loss_G: 3.371391, loss_D: 0.184866\n",
            "[Epoch 152/200] [Batch 50/938] loss_G: 3.128997, loss_D: 0.101992\n",
            "[Epoch 152/200] [Batch 60/938] loss_G: 3.047460, loss_D: 0.187646\n",
            "[Epoch 152/200] [Batch 70/938] loss_G: 2.765497, loss_D: 0.276549\n",
            "[Epoch 152/200] [Batch 80/938] loss_G: 3.299390, loss_D: 0.121871\n",
            "[Epoch 152/200] [Batch 90/938] loss_G: 3.308233, loss_D: 0.153106\n",
            "[Epoch 152/200] [Batch 100/938] loss_G: 2.893738, loss_D: 0.279407\n",
            "[Epoch 152/200] [Batch 110/938] loss_G: 3.427236, loss_D: 0.310758\n",
            "[Epoch 152/200] [Batch 120/938] loss_G: 2.980573, loss_D: 0.210774\n",
            "[Epoch 152/200] [Batch 130/938] loss_G: 2.811903, loss_D: 0.195946\n",
            "[Epoch 152/200] [Batch 140/938] loss_G: 2.992528, loss_D: 0.200392\n",
            "[Epoch 152/200] [Batch 150/938] loss_G: 2.913558, loss_D: 0.208702\n",
            "[Epoch 152/200] [Batch 160/938] loss_G: 3.126514, loss_D: 0.152448\n",
            "[Epoch 152/200] [Batch 170/938] loss_G: 3.220371, loss_D: 0.163220\n",
            "[Epoch 152/200] [Batch 180/938] loss_G: 3.117591, loss_D: 0.204417\n",
            "[Epoch 152/200] [Batch 190/938] loss_G: 3.388937, loss_D: 0.089006\n",
            "[Epoch 152/200] [Batch 200/938] loss_G: 3.028790, loss_D: 0.199330\n",
            "[Epoch 152/200] [Batch 210/938] loss_G: 3.043456, loss_D: 0.273514\n",
            "[Epoch 152/200] [Batch 220/938] loss_G: 3.003374, loss_D: 0.197116\n",
            "[Epoch 152/200] [Batch 230/938] loss_G: 3.076642, loss_D: 0.159073\n",
            "[Epoch 152/200] [Batch 240/938] loss_G: 2.906327, loss_D: 0.199329\n",
            "[Epoch 152/200] [Batch 250/938] loss_G: 2.999368, loss_D: 0.243989\n",
            "[Epoch 152/200] [Batch 260/938] loss_G: 3.253797, loss_D: 0.202276\n",
            "[Epoch 152/200] [Batch 270/938] loss_G: 3.174265, loss_D: 0.236771\n",
            "[Epoch 152/200] [Batch 280/938] loss_G: 2.546610, loss_D: 0.169043\n",
            "[Epoch 152/200] [Batch 290/938] loss_G: 3.270304, loss_D: 0.208277\n",
            "[Epoch 152/200] [Batch 300/938] loss_G: 3.206140, loss_D: 0.171592\n",
            "[Epoch 152/200] [Batch 310/938] loss_G: 2.722529, loss_D: 0.213643\n",
            "[Epoch 152/200] [Batch 320/938] loss_G: 3.011652, loss_D: 0.182000\n",
            "[Epoch 152/200] [Batch 330/938] loss_G: 2.686610, loss_D: 0.195982\n",
            "[Epoch 152/200] [Batch 340/938] loss_G: 2.890820, loss_D: 0.208698\n",
            "[Epoch 152/200] [Batch 350/938] loss_G: 2.850998, loss_D: 0.170554\n",
            "[Epoch 152/200] [Batch 360/938] loss_G: 3.311339, loss_D: 0.288587\n",
            "[Epoch 152/200] [Batch 370/938] loss_G: 2.717801, loss_D: 0.176478\n",
            "[Epoch 152/200] [Batch 380/938] loss_G: 3.170943, loss_D: 0.163411\n",
            "[Epoch 152/200] [Batch 390/938] loss_G: 3.004377, loss_D: 0.259002\n",
            "[Epoch 152/200] [Batch 400/938] loss_G: 3.052914, loss_D: 0.198029\n",
            "[Epoch 152/200] [Batch 410/938] loss_G: 3.074224, loss_D: 0.249073\n",
            "[Epoch 152/200] [Batch 420/938] loss_G: 3.648157, loss_D: 0.197019\n",
            "[Epoch 152/200] [Batch 430/938] loss_G: 3.521784, loss_D: 0.150550\n",
            "[Epoch 152/200] [Batch 440/938] loss_G: 2.879160, loss_D: 0.267085\n",
            "[Epoch 152/200] [Batch 450/938] loss_G: 3.258975, loss_D: 0.315980\n",
            "[Epoch 152/200] [Batch 460/938] loss_G: 3.200249, loss_D: 0.201823\n",
            "[Epoch 152/200] [Batch 470/938] loss_G: 2.556659, loss_D: 0.290201\n",
            "[Epoch 152/200] [Batch 480/938] loss_G: 3.285604, loss_D: 0.199161\n",
            "[Epoch 152/200] [Batch 490/938] loss_G: 3.174064, loss_D: 0.199519\n",
            "[Epoch 152/200] [Batch 500/938] loss_G: 3.145894, loss_D: 0.161786\n",
            "[Epoch 152/200] [Batch 510/938] loss_G: 2.849280, loss_D: 0.217524\n",
            "[Epoch 152/200] [Batch 520/938] loss_G: 3.090213, loss_D: 0.241270\n",
            "[Epoch 152/200] [Batch 530/938] loss_G: 3.268864, loss_D: 0.123396\n",
            "[Epoch 152/200] [Batch 540/938] loss_G: 3.385634, loss_D: 0.192444\n",
            "[Epoch 152/200] [Batch 550/938] loss_G: 3.081426, loss_D: 0.200140\n",
            "[Epoch 152/200] [Batch 560/938] loss_G: 3.017237, loss_D: 0.188084\n",
            "[Epoch 152/200] [Batch 570/938] loss_G: 3.095813, loss_D: 0.209919\n",
            "[Epoch 152/200] [Batch 580/938] loss_G: 3.111622, loss_D: 0.197897\n",
            "[Epoch 152/200] [Batch 590/938] loss_G: 3.356443, loss_D: 0.192861\n",
            "[Epoch 152/200] [Batch 600/938] loss_G: 2.996960, loss_D: 0.187958\n",
            "[Epoch 152/200] [Batch 610/938] loss_G: 2.947950, loss_D: 0.219320\n",
            "[Epoch 152/200] [Batch 620/938] loss_G: 3.233539, loss_D: 0.210360\n",
            "[Epoch 152/200] [Batch 630/938] loss_G: 2.644117, loss_D: 0.223413\n",
            "[Epoch 152/200] [Batch 640/938] loss_G: 2.497707, loss_D: 0.221016\n",
            "[Epoch 152/200] [Batch 650/938] loss_G: 3.013663, loss_D: 0.138669\n",
            "[Epoch 152/200] [Batch 660/938] loss_G: 3.182860, loss_D: 0.224998\n",
            "[Epoch 152/200] [Batch 670/938] loss_G: 2.558789, loss_D: 0.211007\n",
            "[Epoch 152/200] [Batch 680/938] loss_G: 2.825220, loss_D: 0.328830\n",
            "[Epoch 152/200] [Batch 690/938] loss_G: 3.456552, loss_D: 0.231332\n",
            "[Epoch 152/200] [Batch 700/938] loss_G: 3.222286, loss_D: 0.216575\n",
            "[Epoch 152/200] [Batch 710/938] loss_G: 2.588951, loss_D: 0.321948\n",
            "[Epoch 152/200] [Batch 720/938] loss_G: 3.540318, loss_D: 0.257928\n",
            "[Epoch 152/200] [Batch 730/938] loss_G: 3.029287, loss_D: 0.235107\n",
            "[Epoch 152/200] [Batch 740/938] loss_G: 2.954416, loss_D: 0.226676\n",
            "[Epoch 152/200] [Batch 750/938] loss_G: 3.205675, loss_D: 0.163475\n",
            "[Epoch 152/200] [Batch 760/938] loss_G: 3.128385, loss_D: 0.179448\n",
            "[Epoch 152/200] [Batch 770/938] loss_G: 3.178289, loss_D: 0.259647\n",
            "[Epoch 152/200] [Batch 780/938] loss_G: 2.806887, loss_D: 0.255417\n",
            "[Epoch 152/200] [Batch 790/938] loss_G: 2.728944, loss_D: 0.210759\n",
            "[Epoch 152/200] [Batch 800/938] loss_G: 2.681986, loss_D: 0.251958\n",
            "[Epoch 152/200] [Batch 810/938] loss_G: 2.845116, loss_D: 0.175980\n",
            "[Epoch 152/200] [Batch 820/938] loss_G: 3.125784, loss_D: 0.155401\n",
            "[Epoch 152/200] [Batch 830/938] loss_G: 2.914667, loss_D: 0.132905\n",
            "[Epoch 152/200] [Batch 840/938] loss_G: 3.056213, loss_D: 0.244648\n",
            "[Epoch 152/200] [Batch 850/938] loss_G: 2.988214, loss_D: 0.214530\n",
            "[Epoch 152/200] [Batch 860/938] loss_G: 3.079024, loss_D: 0.229069\n",
            "[Epoch 152/200] [Batch 870/938] loss_G: 3.370881, loss_D: 0.161279\n",
            "[Epoch 152/200] [Batch 880/938] loss_G: 3.057855, loss_D: 0.245409\n",
            "[Epoch 152/200] [Batch 890/938] loss_G: 2.534357, loss_D: 0.238106\n",
            "[Epoch 152/200] [Batch 900/938] loss_G: 3.255890, loss_D: 0.168680\n",
            "[Epoch 152/200] [Batch 910/938] loss_G: 3.154715, loss_D: 0.227625\n",
            "[Epoch 152/200] [Batch 920/938] loss_G: 2.451625, loss_D: 0.287534\n",
            "[Epoch 152/200] [Batch 930/938] loss_G: 2.600179, loss_D: 0.179985\n",
            "[Epoch 153/200] [Batch 0/938] loss_G: 3.164445, loss_D: 0.206391\n",
            "[Epoch 153/200] [Batch 10/938] loss_G: 2.964774, loss_D: 0.188263\n",
            "[Epoch 153/200] [Batch 20/938] loss_G: 3.084059, loss_D: 0.167171\n",
            "[Epoch 153/200] [Batch 30/938] loss_G: 2.841717, loss_D: 0.265104\n",
            "[Epoch 153/200] [Batch 40/938] loss_G: 2.866505, loss_D: 0.232176\n",
            "[Epoch 153/200] [Batch 50/938] loss_G: 2.640615, loss_D: 0.281184\n",
            "[Epoch 153/200] [Batch 60/938] loss_G: 2.747867, loss_D: 0.150676\n",
            "[Epoch 153/200] [Batch 70/938] loss_G: 3.122076, loss_D: 0.167427\n",
            "[Epoch 153/200] [Batch 80/938] loss_G: 3.015647, loss_D: 0.164955\n",
            "[Epoch 153/200] [Batch 90/938] loss_G: 3.222417, loss_D: 0.216571\n",
            "[Epoch 153/200] [Batch 100/938] loss_G: 3.200112, loss_D: 0.169243\n",
            "[Epoch 153/200] [Batch 110/938] loss_G: 2.789135, loss_D: 0.160580\n",
            "[Epoch 153/200] [Batch 120/938] loss_G: 2.997401, loss_D: 0.278716\n",
            "[Epoch 153/200] [Batch 130/938] loss_G: 3.195952, loss_D: 0.265515\n",
            "[Epoch 153/200] [Batch 140/938] loss_G: 3.396965, loss_D: 0.196784\n",
            "[Epoch 153/200] [Batch 150/938] loss_G: 2.812800, loss_D: 0.137351\n",
            "[Epoch 153/200] [Batch 160/938] loss_G: 2.922026, loss_D: 0.160822\n",
            "[Epoch 153/200] [Batch 170/938] loss_G: 3.287395, loss_D: 0.168429\n",
            "[Epoch 153/200] [Batch 180/938] loss_G: 2.875583, loss_D: 0.298973\n",
            "[Epoch 153/200] [Batch 190/938] loss_G: 2.922389, loss_D: 0.201909\n",
            "[Epoch 153/200] [Batch 200/938] loss_G: 3.080067, loss_D: 0.244175\n",
            "[Epoch 153/200] [Batch 210/938] loss_G: 3.660011, loss_D: 0.216710\n",
            "[Epoch 153/200] [Batch 220/938] loss_G: 3.345213, loss_D: 0.259138\n",
            "[Epoch 153/200] [Batch 230/938] loss_G: 3.221558, loss_D: 0.225158\n",
            "[Epoch 153/200] [Batch 240/938] loss_G: 3.088190, loss_D: 0.273865\n",
            "[Epoch 153/200] [Batch 250/938] loss_G: 3.122296, loss_D: 0.324171\n",
            "[Epoch 153/200] [Batch 260/938] loss_G: 3.545833, loss_D: 0.197072\n",
            "[Epoch 153/200] [Batch 270/938] loss_G: 3.195427, loss_D: 0.258375\n",
            "[Epoch 153/200] [Batch 280/938] loss_G: 2.982470, loss_D: 0.232617\n",
            "[Epoch 153/200] [Batch 290/938] loss_G: 3.511462, loss_D: 0.137910\n",
            "[Epoch 153/200] [Batch 300/938] loss_G: 3.073907, loss_D: 0.248405\n",
            "[Epoch 153/200] [Batch 310/938] loss_G: 3.220020, loss_D: 0.203602\n",
            "[Epoch 153/200] [Batch 320/938] loss_G: 3.099169, loss_D: 0.223402\n",
            "[Epoch 153/200] [Batch 330/938] loss_G: 3.065515, loss_D: 0.231943\n",
            "[Epoch 153/200] [Batch 340/938] loss_G: 2.842111, loss_D: 0.189257\n",
            "[Epoch 153/200] [Batch 350/938] loss_G: 2.803320, loss_D: 0.160955\n",
            "[Epoch 153/200] [Batch 360/938] loss_G: 3.363525, loss_D: 0.292905\n",
            "[Epoch 153/200] [Batch 370/938] loss_G: 3.221220, loss_D: 0.153437\n",
            "[Epoch 153/200] [Batch 380/938] loss_G: 3.549474, loss_D: 0.161270\n",
            "[Epoch 153/200] [Batch 390/938] loss_G: 2.679516, loss_D: 0.257575\n",
            "[Epoch 153/200] [Batch 400/938] loss_G: 3.052749, loss_D: 0.323381\n",
            "[Epoch 153/200] [Batch 410/938] loss_G: 3.117715, loss_D: 0.266005\n",
            "[Epoch 153/200] [Batch 420/938] loss_G: 2.760540, loss_D: 0.188819\n",
            "[Epoch 153/200] [Batch 430/938] loss_G: 3.322519, loss_D: 0.164465\n",
            "[Epoch 153/200] [Batch 440/938] loss_G: 2.806350, loss_D: 0.220731\n",
            "[Epoch 153/200] [Batch 450/938] loss_G: 3.123954, loss_D: 0.156342\n",
            "[Epoch 153/200] [Batch 460/938] loss_G: 3.455142, loss_D: 0.176324\n",
            "[Epoch 153/200] [Batch 470/938] loss_G: 2.875337, loss_D: 0.218552\n",
            "[Epoch 153/200] [Batch 480/938] loss_G: 3.484517, loss_D: 0.148351\n",
            "[Epoch 153/200] [Batch 490/938] loss_G: 2.994915, loss_D: 0.248738\n",
            "[Epoch 153/200] [Batch 500/938] loss_G: 3.435639, loss_D: 0.188515\n",
            "[Epoch 153/200] [Batch 510/938] loss_G: 2.951965, loss_D: 0.178794\n",
            "[Epoch 153/200] [Batch 520/938] loss_G: 2.996702, loss_D: 0.197251\n",
            "[Epoch 153/200] [Batch 530/938] loss_G: 3.207644, loss_D: 0.176999\n",
            "[Epoch 153/200] [Batch 540/938] loss_G: 3.188934, loss_D: 0.179180\n",
            "[Epoch 153/200] [Batch 550/938] loss_G: 3.493730, loss_D: 0.193469\n",
            "[Epoch 153/200] [Batch 560/938] loss_G: 2.942929, loss_D: 0.201889\n",
            "[Epoch 153/200] [Batch 570/938] loss_G: 2.922163, loss_D: 0.309948\n",
            "[Epoch 153/200] [Batch 580/938] loss_G: 3.097116, loss_D: 0.166522\n",
            "[Epoch 153/200] [Batch 590/938] loss_G: 3.400913, loss_D: 0.168710\n",
            "[Epoch 153/200] [Batch 600/938] loss_G: 3.399191, loss_D: 0.321173\n",
            "[Epoch 153/200] [Batch 610/938] loss_G: 3.055603, loss_D: 0.216055\n",
            "[Epoch 153/200] [Batch 620/938] loss_G: 2.957966, loss_D: 0.240099\n",
            "[Epoch 153/200] [Batch 630/938] loss_G: 3.340442, loss_D: 0.199492\n",
            "[Epoch 153/200] [Batch 640/938] loss_G: 2.880570, loss_D: 0.221904\n",
            "[Epoch 153/200] [Batch 650/938] loss_G: 3.068335, loss_D: 0.307469\n",
            "[Epoch 153/200] [Batch 660/938] loss_G: 3.163315, loss_D: 0.294113\n",
            "[Epoch 153/200] [Batch 670/938] loss_G: 2.906237, loss_D: 0.235826\n",
            "[Epoch 153/200] [Batch 680/938] loss_G: 3.132969, loss_D: 0.207843\n",
            "[Epoch 153/200] [Batch 690/938] loss_G: 3.567930, loss_D: 0.158783\n",
            "[Epoch 153/200] [Batch 700/938] loss_G: 3.252614, loss_D: 0.186233\n",
            "[Epoch 153/200] [Batch 710/938] loss_G: 3.182940, loss_D: 0.203800\n",
            "[Epoch 153/200] [Batch 720/938] loss_G: 3.501186, loss_D: 0.274630\n",
            "[Epoch 153/200] [Batch 730/938] loss_G: 3.103266, loss_D: 0.222048\n",
            "[Epoch 153/200] [Batch 740/938] loss_G: 2.591765, loss_D: 0.267788\n",
            "[Epoch 153/200] [Batch 750/938] loss_G: 2.967257, loss_D: 0.203454\n",
            "[Epoch 153/200] [Batch 760/938] loss_G: 3.020434, loss_D: 0.232088\n",
            "[Epoch 153/200] [Batch 770/938] loss_G: 3.098022, loss_D: 0.212271\n",
            "[Epoch 153/200] [Batch 780/938] loss_G: 3.406836, loss_D: 0.219426\n",
            "[Epoch 153/200] [Batch 790/938] loss_G: 2.902198, loss_D: 0.192322\n",
            "[Epoch 153/200] [Batch 800/938] loss_G: 3.175674, loss_D: 0.247346\n",
            "[Epoch 153/200] [Batch 810/938] loss_G: 3.076959, loss_D: 0.176499\n",
            "[Epoch 153/200] [Batch 820/938] loss_G: 2.992303, loss_D: 0.206693\n",
            "[Epoch 153/200] [Batch 830/938] loss_G: 2.835231, loss_D: 0.196018\n",
            "[Epoch 153/200] [Batch 840/938] loss_G: 3.116184, loss_D: 0.139065\n",
            "[Epoch 153/200] [Batch 850/938] loss_G: 2.915017, loss_D: 0.187257\n",
            "[Epoch 153/200] [Batch 860/938] loss_G: 3.312075, loss_D: 0.192005\n",
            "[Epoch 153/200] [Batch 870/938] loss_G: 3.311664, loss_D: 0.200853\n",
            "[Epoch 153/200] [Batch 880/938] loss_G: 3.204162, loss_D: 0.165771\n",
            "[Epoch 153/200] [Batch 890/938] loss_G: 3.096789, loss_D: 0.196324\n",
            "[Epoch 153/200] [Batch 900/938] loss_G: 3.064776, loss_D: 0.256727\n",
            "[Epoch 153/200] [Batch 910/938] loss_G: 3.199942, loss_D: 0.169779\n",
            "[Epoch 153/200] [Batch 920/938] loss_G: 2.971646, loss_D: 0.216598\n",
            "[Epoch 153/200] [Batch 930/938] loss_G: 3.086816, loss_D: 0.140510\n",
            "[Epoch 154/200] [Batch 0/938] loss_G: 2.926650, loss_D: 0.233841\n",
            "[Epoch 154/200] [Batch 10/938] loss_G: 3.115923, loss_D: 0.223183\n",
            "[Epoch 154/200] [Batch 20/938] loss_G: 3.304794, loss_D: 0.187876\n",
            "[Epoch 154/200] [Batch 30/938] loss_G: 2.761052, loss_D: 0.201433\n",
            "[Epoch 154/200] [Batch 40/938] loss_G: 2.976966, loss_D: 0.170250\n",
            "[Epoch 154/200] [Batch 50/938] loss_G: 2.811472, loss_D: 0.235150\n",
            "[Epoch 154/200] [Batch 60/938] loss_G: 2.920268, loss_D: 0.230585\n",
            "[Epoch 154/200] [Batch 70/938] loss_G: 3.154830, loss_D: 0.132549\n",
            "[Epoch 154/200] [Batch 80/938] loss_G: 3.417002, loss_D: 0.172940\n",
            "[Epoch 154/200] [Batch 90/938] loss_G: 3.271750, loss_D: 0.255156\n",
            "[Epoch 154/200] [Batch 100/938] loss_G: 2.997150, loss_D: 0.166900\n",
            "[Epoch 154/200] [Batch 110/938] loss_G: 3.012971, loss_D: 0.256838\n",
            "[Epoch 154/200] [Batch 120/938] loss_G: 3.361388, loss_D: 0.186747\n",
            "[Epoch 154/200] [Batch 130/938] loss_G: 3.235405, loss_D: 0.188942\n",
            "[Epoch 154/200] [Batch 140/938] loss_G: 3.508722, loss_D: 0.214246\n",
            "[Epoch 154/200] [Batch 150/938] loss_G: 3.044729, loss_D: 0.202768\n",
            "[Epoch 154/200] [Batch 160/938] loss_G: 3.122546, loss_D: 0.202260\n",
            "[Epoch 154/200] [Batch 170/938] loss_G: 3.349694, loss_D: 0.224591\n",
            "[Epoch 154/200] [Batch 180/938] loss_G: 2.659414, loss_D: 0.212585\n",
            "[Epoch 154/200] [Batch 190/938] loss_G: 2.863079, loss_D: 0.228590\n",
            "[Epoch 154/200] [Batch 200/938] loss_G: 2.895839, loss_D: 0.213977\n",
            "[Epoch 154/200] [Batch 210/938] loss_G: 3.109927, loss_D: 0.193849\n",
            "[Epoch 154/200] [Batch 220/938] loss_G: 3.486557, loss_D: 0.251643\n",
            "[Epoch 154/200] [Batch 230/938] loss_G: 2.415493, loss_D: 0.176414\n",
            "[Epoch 154/200] [Batch 240/938] loss_G: 3.683332, loss_D: 0.238359\n",
            "[Epoch 154/200] [Batch 250/938] loss_G: 3.161798, loss_D: 0.187887\n",
            "[Epoch 154/200] [Batch 260/938] loss_G: 2.779540, loss_D: 0.206568\n",
            "[Epoch 154/200] [Batch 270/938] loss_G: 2.954753, loss_D: 0.244860\n",
            "[Epoch 154/200] [Batch 280/938] loss_G: 2.725276, loss_D: 0.190062\n",
            "[Epoch 154/200] [Batch 290/938] loss_G: 3.037317, loss_D: 0.327341\n",
            "[Epoch 154/200] [Batch 300/938] loss_G: 3.005216, loss_D: 0.309631\n",
            "[Epoch 154/200] [Batch 310/938] loss_G: 3.022467, loss_D: 0.194899\n",
            "[Epoch 154/200] [Batch 320/938] loss_G: 3.085701, loss_D: 0.222462\n",
            "[Epoch 154/200] [Batch 330/938] loss_G: 2.809481, loss_D: 0.263723\n",
            "[Epoch 154/200] [Batch 340/938] loss_G: 3.197680, loss_D: 0.155583\n",
            "[Epoch 154/200] [Batch 350/938] loss_G: 2.808226, loss_D: 0.150019\n",
            "[Epoch 154/200] [Batch 360/938] loss_G: 3.194535, loss_D: 0.224678\n",
            "[Epoch 154/200] [Batch 370/938] loss_G: 2.876749, loss_D: 0.259426\n",
            "[Epoch 154/200] [Batch 380/938] loss_G: 2.955321, loss_D: 0.207387\n",
            "[Epoch 154/200] [Batch 390/938] loss_G: 2.906481, loss_D: 0.201646\n",
            "[Epoch 154/200] [Batch 400/938] loss_G: 3.153863, loss_D: 0.151294\n",
            "[Epoch 154/200] [Batch 410/938] loss_G: 2.809495, loss_D: 0.227083\n",
            "[Epoch 154/200] [Batch 420/938] loss_G: 3.082457, loss_D: 0.234009\n",
            "[Epoch 154/200] [Batch 430/938] loss_G: 3.282472, loss_D: 0.307628\n",
            "[Epoch 154/200] [Batch 440/938] loss_G: 2.903397, loss_D: 0.164459\n",
            "[Epoch 154/200] [Batch 450/938] loss_G: 2.967280, loss_D: 0.213056\n",
            "[Epoch 154/200] [Batch 460/938] loss_G: 3.134905, loss_D: 0.157748\n",
            "[Epoch 154/200] [Batch 470/938] loss_G: 3.097982, loss_D: 0.190449\n",
            "[Epoch 154/200] [Batch 480/938] loss_G: 3.100832, loss_D: 0.218786\n",
            "[Epoch 154/200] [Batch 490/938] loss_G: 3.128592, loss_D: 0.224540\n",
            "[Epoch 154/200] [Batch 500/938] loss_G: 3.491760, loss_D: 0.123201\n",
            "[Epoch 154/200] [Batch 510/938] loss_G: 3.199173, loss_D: 0.221346\n",
            "[Epoch 154/200] [Batch 520/938] loss_G: 3.066575, loss_D: 0.178626\n",
            "[Epoch 154/200] [Batch 530/938] loss_G: 3.093042, loss_D: 0.190095\n",
            "[Epoch 154/200] [Batch 540/938] loss_G: 3.145430, loss_D: 0.179065\n",
            "[Epoch 154/200] [Batch 550/938] loss_G: 2.820642, loss_D: 0.166086\n",
            "[Epoch 154/200] [Batch 560/938] loss_G: 3.233214, loss_D: 0.182344\n",
            "[Epoch 154/200] [Batch 570/938] loss_G: 3.500149, loss_D: 0.185444\n",
            "[Epoch 154/200] [Batch 580/938] loss_G: 3.116117, loss_D: 0.265491\n",
            "[Epoch 154/200] [Batch 590/938] loss_G: 3.346213, loss_D: 0.222799\n",
            "[Epoch 154/200] [Batch 600/938] loss_G: 3.156058, loss_D: 0.208278\n",
            "[Epoch 154/200] [Batch 610/938] loss_G: 3.036389, loss_D: 0.209973\n",
            "[Epoch 154/200] [Batch 620/938] loss_G: 3.032468, loss_D: 0.211033\n",
            "[Epoch 154/200] [Batch 630/938] loss_G: 2.865347, loss_D: 0.191225\n",
            "[Epoch 154/200] [Batch 640/938] loss_G: 2.983745, loss_D: 0.183953\n",
            "[Epoch 154/200] [Batch 650/938] loss_G: 2.758420, loss_D: 0.141287\n",
            "[Epoch 154/200] [Batch 660/938] loss_G: 3.070354, loss_D: 0.152323\n",
            "[Epoch 154/200] [Batch 670/938] loss_G: 2.589293, loss_D: 0.209058\n",
            "[Epoch 154/200] [Batch 680/938] loss_G: 3.559766, loss_D: 0.114078\n",
            "[Epoch 154/200] [Batch 690/938] loss_G: 2.806674, loss_D: 0.175606\n",
            "[Epoch 154/200] [Batch 700/938] loss_G: 3.442995, loss_D: 0.166331\n",
            "[Epoch 154/200] [Batch 710/938] loss_G: 3.163563, loss_D: 0.151172\n",
            "[Epoch 154/200] [Batch 720/938] loss_G: 2.951818, loss_D: 0.224875\n",
            "[Epoch 154/200] [Batch 730/938] loss_G: 3.272686, loss_D: 0.153513\n",
            "[Epoch 154/200] [Batch 740/938] loss_G: 2.786814, loss_D: 0.159761\n",
            "[Epoch 154/200] [Batch 750/938] loss_G: 3.107224, loss_D: 0.136423\n",
            "[Epoch 154/200] [Batch 760/938] loss_G: 2.947983, loss_D: 0.231919\n",
            "[Epoch 154/200] [Batch 770/938] loss_G: 3.340877, loss_D: 0.167310\n",
            "[Epoch 154/200] [Batch 780/938] loss_G: 3.402973, loss_D: 0.273555\n",
            "[Epoch 154/200] [Batch 790/938] loss_G: 3.031072, loss_D: 0.155857\n",
            "[Epoch 154/200] [Batch 800/938] loss_G: 2.877060, loss_D: 0.248742\n",
            "[Epoch 154/200] [Batch 810/938] loss_G: 3.073993, loss_D: 0.204303\n",
            "[Epoch 154/200] [Batch 820/938] loss_G: 3.747493, loss_D: 0.251937\n",
            "[Epoch 154/200] [Batch 830/938] loss_G: 3.377957, loss_D: 0.139089\n",
            "[Epoch 154/200] [Batch 840/938] loss_G: 3.408360, loss_D: 0.173237\n",
            "[Epoch 154/200] [Batch 850/938] loss_G: 3.329862, loss_D: 0.209238\n",
            "[Epoch 154/200] [Batch 860/938] loss_G: 3.264199, loss_D: 0.212630\n",
            "[Epoch 154/200] [Batch 870/938] loss_G: 2.963174, loss_D: 0.212309\n",
            "[Epoch 154/200] [Batch 880/938] loss_G: 3.335823, loss_D: 0.242383\n",
            "[Epoch 154/200] [Batch 890/938] loss_G: 3.013581, loss_D: 0.179188\n",
            "[Epoch 154/200] [Batch 900/938] loss_G: 2.869006, loss_D: 0.188294\n",
            "[Epoch 154/200] [Batch 910/938] loss_G: 2.977715, loss_D: 0.215585\n",
            "[Epoch 154/200] [Batch 920/938] loss_G: 2.971808, loss_D: 0.265477\n",
            "[Epoch 154/200] [Batch 930/938] loss_G: 3.008975, loss_D: 0.275500\n",
            "[Epoch 155/200] [Batch 0/938] loss_G: 3.049810, loss_D: 0.192379\n",
            "[Epoch 155/200] [Batch 10/938] loss_G: 3.066186, loss_D: 0.231040\n",
            "[Epoch 155/200] [Batch 20/938] loss_G: 3.076451, loss_D: 0.231080\n",
            "[Epoch 155/200] [Batch 30/938] loss_G: 3.329250, loss_D: 0.193818\n",
            "[Epoch 155/200] [Batch 40/938] loss_G: 3.045845, loss_D: 0.184063\n",
            "[Epoch 155/200] [Batch 50/938] loss_G: 2.827471, loss_D: 0.307376\n",
            "[Epoch 155/200] [Batch 60/938] loss_G: 3.186009, loss_D: 0.155357\n",
            "[Epoch 155/200] [Batch 70/938] loss_G: 3.375902, loss_D: 0.218376\n",
            "[Epoch 155/200] [Batch 80/938] loss_G: 2.826933, loss_D: 0.209773\n",
            "[Epoch 155/200] [Batch 90/938] loss_G: 3.074983, loss_D: 0.149829\n",
            "[Epoch 155/200] [Batch 100/938] loss_G: 2.909775, loss_D: 0.206095\n",
            "[Epoch 155/200] [Batch 110/938] loss_G: 3.263512, loss_D: 0.154083\n",
            "[Epoch 155/200] [Batch 120/938] loss_G: 3.045671, loss_D: 0.133887\n",
            "[Epoch 155/200] [Batch 130/938] loss_G: 3.271213, loss_D: 0.195436\n",
            "[Epoch 155/200] [Batch 140/938] loss_G: 3.104328, loss_D: 0.187133\n",
            "[Epoch 155/200] [Batch 150/938] loss_G: 3.704807, loss_D: 0.269080\n",
            "[Epoch 155/200] [Batch 160/938] loss_G: 3.381759, loss_D: 0.187257\n",
            "[Epoch 155/200] [Batch 170/938] loss_G: 3.327177, loss_D: 0.204324\n",
            "[Epoch 155/200] [Batch 180/938] loss_G: 3.150977, loss_D: 0.206948\n",
            "[Epoch 155/200] [Batch 190/938] loss_G: 3.093674, loss_D: 0.250964\n",
            "[Epoch 155/200] [Batch 200/938] loss_G: 3.413876, loss_D: 0.110732\n",
            "[Epoch 155/200] [Batch 210/938] loss_G: 3.075522, loss_D: 0.225456\n",
            "[Epoch 155/200] [Batch 220/938] loss_G: 2.951565, loss_D: 0.151916\n",
            "[Epoch 155/200] [Batch 230/938] loss_G: 3.272892, loss_D: 0.150864\n",
            "[Epoch 155/200] [Batch 240/938] loss_G: 3.232093, loss_D: 0.139164\n",
            "[Epoch 155/200] [Batch 250/938] loss_G: 2.961163, loss_D: 0.197307\n",
            "[Epoch 155/200] [Batch 260/938] loss_G: 3.182688, loss_D: 0.219644\n",
            "[Epoch 155/200] [Batch 270/938] loss_G: 2.934853, loss_D: 0.179704\n",
            "[Epoch 155/200] [Batch 280/938] loss_G: 2.971242, loss_D: 0.258053\n",
            "[Epoch 155/200] [Batch 290/938] loss_G: 3.301814, loss_D: 0.189367\n",
            "[Epoch 155/200] [Batch 300/938] loss_G: 2.880800, loss_D: 0.215696\n",
            "[Epoch 155/200] [Batch 310/938] loss_G: 3.508939, loss_D: 0.216751\n",
            "[Epoch 155/200] [Batch 320/938] loss_G: 3.003473, loss_D: 0.200798\n",
            "[Epoch 155/200] [Batch 330/938] loss_G: 3.263491, loss_D: 0.248658\n",
            "[Epoch 155/200] [Batch 340/938] loss_G: 3.585675, loss_D: 0.234742\n",
            "[Epoch 155/200] [Batch 350/938] loss_G: 2.918977, loss_D: 0.197931\n",
            "[Epoch 155/200] [Batch 360/938] loss_G: 3.417797, loss_D: 0.228552\n",
            "[Epoch 155/200] [Batch 370/938] loss_G: 3.142887, loss_D: 0.192330\n",
            "[Epoch 155/200] [Batch 380/938] loss_G: 2.701756, loss_D: 0.273557\n",
            "[Epoch 155/200] [Batch 390/938] loss_G: 3.236942, loss_D: 0.146782\n",
            "[Epoch 155/200] [Batch 400/938] loss_G: 3.014477, loss_D: 0.203767\n",
            "[Epoch 155/200] [Batch 410/938] loss_G: 3.157347, loss_D: 0.275791\n",
            "[Epoch 155/200] [Batch 420/938] loss_G: 3.362984, loss_D: 0.152226\n",
            "[Epoch 155/200] [Batch 430/938] loss_G: 3.081731, loss_D: 0.173882\n",
            "[Epoch 155/200] [Batch 440/938] loss_G: 2.929676, loss_D: 0.267178\n",
            "[Epoch 155/200] [Batch 450/938] loss_G: 2.989074, loss_D: 0.200317\n",
            "[Epoch 155/200] [Batch 460/938] loss_G: 3.127174, loss_D: 0.199023\n",
            "[Epoch 155/200] [Batch 470/938] loss_G: 3.212407, loss_D: 0.227743\n",
            "[Epoch 155/200] [Batch 480/938] loss_G: 3.028880, loss_D: 0.153936\n",
            "[Epoch 155/200] [Batch 490/938] loss_G: 3.281906, loss_D: 0.207513\n",
            "[Epoch 155/200] [Batch 500/938] loss_G: 3.681976, loss_D: 0.189517\n",
            "[Epoch 155/200] [Batch 510/938] loss_G: 3.146988, loss_D: 0.196652\n",
            "[Epoch 155/200] [Batch 520/938] loss_G: 2.786199, loss_D: 0.233549\n",
            "[Epoch 155/200] [Batch 530/938] loss_G: 3.278118, loss_D: 0.181551\n",
            "[Epoch 155/200] [Batch 540/938] loss_G: 3.077763, loss_D: 0.181556\n",
            "[Epoch 155/200] [Batch 550/938] loss_G: 2.523307, loss_D: 0.242785\n",
            "[Epoch 155/200] [Batch 560/938] loss_G: 3.345190, loss_D: 0.200458\n",
            "[Epoch 155/200] [Batch 570/938] loss_G: 3.029406, loss_D: 0.255890\n",
            "[Epoch 155/200] [Batch 580/938] loss_G: 3.180676, loss_D: 0.189109\n",
            "[Epoch 155/200] [Batch 590/938] loss_G: 2.758974, loss_D: 0.230331\n",
            "[Epoch 155/200] [Batch 600/938] loss_G: 2.984948, loss_D: 0.247090\n",
            "[Epoch 155/200] [Batch 610/938] loss_G: 3.272616, loss_D: 0.305036\n",
            "[Epoch 155/200] [Batch 620/938] loss_G: 2.960401, loss_D: 0.248565\n",
            "[Epoch 155/200] [Batch 630/938] loss_G: 3.326210, loss_D: 0.149983\n",
            "[Epoch 155/200] [Batch 640/938] loss_G: 3.613786, loss_D: 0.232106\n",
            "[Epoch 155/200] [Batch 650/938] loss_G: 2.544286, loss_D: 0.229950\n",
            "[Epoch 155/200] [Batch 660/938] loss_G: 2.726952, loss_D: 0.255597\n",
            "[Epoch 155/200] [Batch 670/938] loss_G: 3.349864, loss_D: 0.234325\n",
            "[Epoch 155/200] [Batch 680/938] loss_G: 2.885892, loss_D: 0.315179\n",
            "[Epoch 155/200] [Batch 690/938] loss_G: 3.147917, loss_D: 0.197005\n",
            "[Epoch 155/200] [Batch 700/938] loss_G: 3.344098, loss_D: 0.181164\n",
            "[Epoch 155/200] [Batch 710/938] loss_G: 3.398740, loss_D: 0.193435\n",
            "[Epoch 155/200] [Batch 720/938] loss_G: 3.481583, loss_D: 0.257450\n",
            "[Epoch 155/200] [Batch 730/938] loss_G: 3.352786, loss_D: 0.143285\n",
            "[Epoch 155/200] [Batch 740/938] loss_G: 3.617355, loss_D: 0.246148\n",
            "[Epoch 155/200] [Batch 750/938] loss_G: 2.850874, loss_D: 0.215840\n",
            "[Epoch 155/200] [Batch 760/938] loss_G: 2.958848, loss_D: 0.254149\n",
            "[Epoch 155/200] [Batch 770/938] loss_G: 3.319929, loss_D: 0.167518\n",
            "[Epoch 155/200] [Batch 780/938] loss_G: 3.334123, loss_D: 0.316843\n",
            "[Epoch 155/200] [Batch 790/938] loss_G: 3.019085, loss_D: 0.274599\n",
            "[Epoch 155/200] [Batch 800/938] loss_G: 3.224316, loss_D: 0.173122\n",
            "[Epoch 155/200] [Batch 810/938] loss_G: 3.051634, loss_D: 0.242758\n",
            "[Epoch 155/200] [Batch 820/938] loss_G: 3.036031, loss_D: 0.243641\n",
            "[Epoch 155/200] [Batch 830/938] loss_G: 3.221631, loss_D: 0.185063\n",
            "[Epoch 155/200] [Batch 840/938] loss_G: 2.827970, loss_D: 0.265457\n",
            "[Epoch 155/200] [Batch 850/938] loss_G: 3.423281, loss_D: 0.219265\n",
            "[Epoch 155/200] [Batch 860/938] loss_G: 3.283446, loss_D: 0.254350\n",
            "[Epoch 155/200] [Batch 870/938] loss_G: 2.812876, loss_D: 0.141043\n",
            "[Epoch 155/200] [Batch 880/938] loss_G: 3.473475, loss_D: 0.209042\n",
            "[Epoch 155/200] [Batch 890/938] loss_G: 3.148543, loss_D: 0.251606\n",
            "[Epoch 155/200] [Batch 900/938] loss_G: 2.805387, loss_D: 0.207109\n",
            "[Epoch 155/200] [Batch 910/938] loss_G: 3.368786, loss_D: 0.210078\n",
            "[Epoch 155/200] [Batch 920/938] loss_G: 2.916566, loss_D: 0.288393\n",
            "[Epoch 155/200] [Batch 930/938] loss_G: 3.110445, loss_D: 0.205487\n",
            "[Epoch 156/200] [Batch 0/938] loss_G: 3.114191, loss_D: 0.210518\n",
            "[Epoch 156/200] [Batch 10/938] loss_G: 3.130627, loss_D: 0.160215\n",
            "[Epoch 156/200] [Batch 20/938] loss_G: 2.853693, loss_D: 0.159247\n",
            "[Epoch 156/200] [Batch 30/938] loss_G: 3.359546, loss_D: 0.354612\n",
            "[Epoch 156/200] [Batch 40/938] loss_G: 2.559859, loss_D: 0.297247\n",
            "[Epoch 156/200] [Batch 50/938] loss_G: 3.030604, loss_D: 0.248988\n",
            "[Epoch 156/200] [Batch 60/938] loss_G: 3.282909, loss_D: 0.156947\n",
            "[Epoch 156/200] [Batch 70/938] loss_G: 3.189897, loss_D: 0.204509\n",
            "[Epoch 156/200] [Batch 80/938] loss_G: 3.310143, loss_D: 0.193991\n",
            "[Epoch 156/200] [Batch 90/938] loss_G: 2.819831, loss_D: 0.219965\n",
            "[Epoch 156/200] [Batch 100/938] loss_G: 3.171430, loss_D: 0.183516\n",
            "[Epoch 156/200] [Batch 110/938] loss_G: 3.077123, loss_D: 0.172562\n",
            "[Epoch 156/200] [Batch 120/938] loss_G: 3.238134, loss_D: 0.212681\n",
            "[Epoch 156/200] [Batch 130/938] loss_G: 3.173326, loss_D: 0.265527\n",
            "[Epoch 156/200] [Batch 140/938] loss_G: 2.771710, loss_D: 0.211282\n",
            "[Epoch 156/200] [Batch 150/938] loss_G: 3.333425, loss_D: 0.296114\n",
            "[Epoch 156/200] [Batch 160/938] loss_G: 2.951084, loss_D: 0.180680\n",
            "[Epoch 156/200] [Batch 170/938] loss_G: 2.716003, loss_D: 0.214575\n",
            "[Epoch 156/200] [Batch 180/938] loss_G: 3.138972, loss_D: 0.271174\n",
            "[Epoch 156/200] [Batch 190/938] loss_G: 3.032237, loss_D: 0.230574\n",
            "[Epoch 156/200] [Batch 200/938] loss_G: 3.156730, loss_D: 0.145314\n",
            "[Epoch 156/200] [Batch 210/938] loss_G: 3.149166, loss_D: 0.187203\n",
            "[Epoch 156/200] [Batch 220/938] loss_G: 2.988599, loss_D: 0.277514\n",
            "[Epoch 156/200] [Batch 230/938] loss_G: 3.145990, loss_D: 0.180482\n",
            "[Epoch 156/200] [Batch 240/938] loss_G: 3.124453, loss_D: 0.162134\n",
            "[Epoch 156/200] [Batch 250/938] loss_G: 2.784663, loss_D: 0.218872\n",
            "[Epoch 156/200] [Batch 260/938] loss_G: 2.969116, loss_D: 0.216978\n",
            "[Epoch 156/200] [Batch 270/938] loss_G: 2.789143, loss_D: 0.227490\n",
            "[Epoch 156/200] [Batch 280/938] loss_G: 3.179705, loss_D: 0.210582\n",
            "[Epoch 156/200] [Batch 290/938] loss_G: 3.104250, loss_D: 0.143085\n",
            "[Epoch 156/200] [Batch 300/938] loss_G: 3.198969, loss_D: 0.088609\n",
            "[Epoch 156/200] [Batch 310/938] loss_G: 2.978081, loss_D: 0.242276\n",
            "[Epoch 156/200] [Batch 320/938] loss_G: 3.699435, loss_D: 0.144584\n",
            "[Epoch 156/200] [Batch 330/938] loss_G: 2.763494, loss_D: 0.199701\n",
            "[Epoch 156/200] [Batch 340/938] loss_G: 3.221154, loss_D: 0.150982\n",
            "[Epoch 156/200] [Batch 350/938] loss_G: 2.941095, loss_D: 0.246577\n",
            "[Epoch 156/200] [Batch 360/938] loss_G: 3.223392, loss_D: 0.138619\n",
            "[Epoch 156/200] [Batch 370/938] loss_G: 3.348344, loss_D: 0.172240\n",
            "[Epoch 156/200] [Batch 380/938] loss_G: 3.108818, loss_D: 0.181835\n",
            "[Epoch 156/200] [Batch 390/938] loss_G: 3.148149, loss_D: 0.205043\n",
            "[Epoch 156/200] [Batch 400/938] loss_G: 2.881335, loss_D: 0.203462\n",
            "[Epoch 156/200] [Batch 410/938] loss_G: 3.549909, loss_D: 0.125779\n",
            "[Epoch 156/200] [Batch 420/938] loss_G: 2.852346, loss_D: 0.274293\n",
            "[Epoch 156/200] [Batch 430/938] loss_G: 3.428125, loss_D: 0.247267\n",
            "[Epoch 156/200] [Batch 440/938] loss_G: 3.105562, loss_D: 0.154734\n",
            "[Epoch 156/200] [Batch 450/938] loss_G: 3.317139, loss_D: 0.268029\n",
            "[Epoch 156/200] [Batch 460/938] loss_G: 2.590801, loss_D: 0.227516\n",
            "[Epoch 156/200] [Batch 470/938] loss_G: 3.014117, loss_D: 0.209514\n",
            "[Epoch 156/200] [Batch 480/938] loss_G: 3.113830, loss_D: 0.160213\n",
            "[Epoch 156/200] [Batch 490/938] loss_G: 2.668882, loss_D: 0.219442\n",
            "[Epoch 156/200] [Batch 500/938] loss_G: 3.036510, loss_D: 0.198619\n",
            "[Epoch 156/200] [Batch 510/938] loss_G: 2.867339, loss_D: 0.195247\n",
            "[Epoch 156/200] [Batch 520/938] loss_G: 3.089228, loss_D: 0.234653\n",
            "[Epoch 156/200] [Batch 530/938] loss_G: 3.112106, loss_D: 0.171998\n",
            "[Epoch 156/200] [Batch 540/938] loss_G: 2.981821, loss_D: 0.158610\n",
            "[Epoch 156/200] [Batch 550/938] loss_G: 3.061319, loss_D: 0.192428\n",
            "[Epoch 156/200] [Batch 560/938] loss_G: 3.335453, loss_D: 0.307295\n",
            "[Epoch 156/200] [Batch 570/938] loss_G: 3.231106, loss_D: 0.189613\n",
            "[Epoch 156/200] [Batch 580/938] loss_G: 3.246586, loss_D: 0.118258\n",
            "[Epoch 156/200] [Batch 590/938] loss_G: 3.192911, loss_D: 0.193555\n",
            "[Epoch 156/200] [Batch 600/938] loss_G: 2.850739, loss_D: 0.197383\n",
            "[Epoch 156/200] [Batch 610/938] loss_G: 2.578648, loss_D: 0.182917\n",
            "[Epoch 156/200] [Batch 620/938] loss_G: 2.935042, loss_D: 0.139615\n",
            "[Epoch 156/200] [Batch 630/938] loss_G: 3.004279, loss_D: 0.235506\n",
            "[Epoch 156/200] [Batch 640/938] loss_G: 3.307200, loss_D: 0.124845\n",
            "[Epoch 156/200] [Batch 650/938] loss_G: 2.832052, loss_D: 0.216875\n",
            "[Epoch 156/200] [Batch 660/938] loss_G: 3.120129, loss_D: 0.226080\n",
            "[Epoch 156/200] [Batch 670/938] loss_G: 2.861765, loss_D: 0.242650\n",
            "[Epoch 156/200] [Batch 680/938] loss_G: 3.523401, loss_D: 0.171471\n",
            "[Epoch 156/200] [Batch 690/938] loss_G: 3.193452, loss_D: 0.189953\n",
            "[Epoch 156/200] [Batch 700/938] loss_G: 2.713896, loss_D: 0.176480\n",
            "[Epoch 156/200] [Batch 710/938] loss_G: 2.870099, loss_D: 0.243477\n",
            "[Epoch 156/200] [Batch 720/938] loss_G: 3.255628, loss_D: 0.194767\n",
            "[Epoch 156/200] [Batch 730/938] loss_G: 2.943910, loss_D: 0.204893\n",
            "[Epoch 156/200] [Batch 740/938] loss_G: 3.063597, loss_D: 0.221456\n",
            "[Epoch 156/200] [Batch 750/938] loss_G: 3.000443, loss_D: 0.229681\n",
            "[Epoch 156/200] [Batch 760/938] loss_G: 3.132394, loss_D: 0.226533\n",
            "[Epoch 156/200] [Batch 770/938] loss_G: 3.392287, loss_D: 0.218615\n",
            "[Epoch 156/200] [Batch 780/938] loss_G: 3.122269, loss_D: 0.200394\n",
            "[Epoch 156/200] [Batch 790/938] loss_G: 3.091424, loss_D: 0.183473\n",
            "[Epoch 156/200] [Batch 800/938] loss_G: 3.643171, loss_D: 0.215590\n",
            "[Epoch 156/200] [Batch 810/938] loss_G: 2.867371, loss_D: 0.182440\n",
            "[Epoch 156/200] [Batch 820/938] loss_G: 3.079396, loss_D: 0.242457\n",
            "[Epoch 156/200] [Batch 830/938] loss_G: 3.034569, loss_D: 0.160042\n",
            "[Epoch 156/200] [Batch 840/938] loss_G: 3.156037, loss_D: 0.172562\n",
            "[Epoch 156/200] [Batch 850/938] loss_G: 3.041041, loss_D: 0.283211\n",
            "[Epoch 156/200] [Batch 860/938] loss_G: 2.746707, loss_D: 0.256223\n",
            "[Epoch 156/200] [Batch 870/938] loss_G: 3.387386, loss_D: 0.201663\n",
            "[Epoch 156/200] [Batch 880/938] loss_G: 3.039370, loss_D: 0.226411\n",
            "[Epoch 156/200] [Batch 890/938] loss_G: 3.076912, loss_D: 0.274246\n",
            "[Epoch 156/200] [Batch 900/938] loss_G: 3.337938, loss_D: 0.329156\n",
            "[Epoch 156/200] [Batch 910/938] loss_G: 3.125871, loss_D: 0.308064\n",
            "[Epoch 156/200] [Batch 920/938] loss_G: 3.260599, loss_D: 0.223105\n",
            "[Epoch 156/200] [Batch 930/938] loss_G: 3.216097, loss_D: 0.169343\n",
            "[Epoch 157/200] [Batch 0/938] loss_G: 3.093262, loss_D: 0.230898\n",
            "[Epoch 157/200] [Batch 10/938] loss_G: 2.661281, loss_D: 0.255358\n",
            "[Epoch 157/200] [Batch 20/938] loss_G: 2.988533, loss_D: 0.215134\n",
            "[Epoch 157/200] [Batch 30/938] loss_G: 2.844037, loss_D: 0.194783\n",
            "[Epoch 157/200] [Batch 40/938] loss_G: 3.156069, loss_D: 0.216438\n",
            "[Epoch 157/200] [Batch 50/938] loss_G: 3.373847, loss_D: 0.205309\n",
            "[Epoch 157/200] [Batch 60/938] loss_G: 3.150043, loss_D: 0.256341\n",
            "[Epoch 157/200] [Batch 70/938] loss_G: 3.473954, loss_D: 0.176824\n",
            "[Epoch 157/200] [Batch 80/938] loss_G: 2.755057, loss_D: 0.169836\n",
            "[Epoch 157/200] [Batch 90/938] loss_G: 3.117431, loss_D: 0.227214\n",
            "[Epoch 157/200] [Batch 100/938] loss_G: 3.101246, loss_D: 0.201190\n",
            "[Epoch 157/200] [Batch 110/938] loss_G: 2.941115, loss_D: 0.234122\n",
            "[Epoch 157/200] [Batch 120/938] loss_G: 3.371795, loss_D: 0.155821\n",
            "[Epoch 157/200] [Batch 130/938] loss_G: 2.865851, loss_D: 0.196169\n",
            "[Epoch 157/200] [Batch 140/938] loss_G: 2.859949, loss_D: 0.289271\n",
            "[Epoch 157/200] [Batch 150/938] loss_G: 3.486825, loss_D: 0.256672\n",
            "[Epoch 157/200] [Batch 160/938] loss_G: 3.376828, loss_D: 0.126658\n",
            "[Epoch 157/200] [Batch 170/938] loss_G: 3.151723, loss_D: 0.128062\n",
            "[Epoch 157/200] [Batch 180/938] loss_G: 3.364955, loss_D: 0.174031\n",
            "[Epoch 157/200] [Batch 190/938] loss_G: 2.949093, loss_D: 0.337331\n",
            "[Epoch 157/200] [Batch 200/938] loss_G: 2.788257, loss_D: 0.185236\n",
            "[Epoch 157/200] [Batch 210/938] loss_G: 3.356842, loss_D: 0.299145\n",
            "[Epoch 157/200] [Batch 220/938] loss_G: 3.198568, loss_D: 0.125594\n",
            "[Epoch 157/200] [Batch 230/938] loss_G: 2.875307, loss_D: 0.214397\n",
            "[Epoch 157/200] [Batch 240/938] loss_G: 3.422532, loss_D: 0.198090\n",
            "[Epoch 157/200] [Batch 250/938] loss_G: 2.844924, loss_D: 0.244532\n",
            "[Epoch 157/200] [Batch 260/938] loss_G: 2.720332, loss_D: 0.213122\n",
            "[Epoch 157/200] [Batch 270/938] loss_G: 2.906257, loss_D: 0.216214\n",
            "[Epoch 157/200] [Batch 280/938] loss_G: 3.205436, loss_D: 0.254814\n",
            "[Epoch 157/200] [Batch 290/938] loss_G: 3.175026, loss_D: 0.173941\n",
            "[Epoch 157/200] [Batch 300/938] loss_G: 3.237077, loss_D: 0.204184\n",
            "[Epoch 157/200] [Batch 310/938] loss_G: 3.202063, loss_D: 0.259613\n",
            "[Epoch 157/200] [Batch 320/938] loss_G: 3.338007, loss_D: 0.191603\n",
            "[Epoch 157/200] [Batch 330/938] loss_G: 3.155064, loss_D: 0.308778\n",
            "[Epoch 157/200] [Batch 340/938] loss_G: 3.551680, loss_D: 0.254255\n",
            "[Epoch 157/200] [Batch 350/938] loss_G: 3.148526, loss_D: 0.218294\n",
            "[Epoch 157/200] [Batch 360/938] loss_G: 3.350283, loss_D: 0.222757\n",
            "[Epoch 157/200] [Batch 370/938] loss_G: 2.934536, loss_D: 0.194418\n",
            "[Epoch 157/200] [Batch 380/938] loss_G: 3.301149, loss_D: 0.254279\n",
            "[Epoch 157/200] [Batch 390/938] loss_G: 3.505777, loss_D: 0.112967\n",
            "[Epoch 157/200] [Batch 400/938] loss_G: 3.134199, loss_D: 0.260422\n",
            "[Epoch 157/200] [Batch 410/938] loss_G: 3.089360, loss_D: 0.260456\n",
            "[Epoch 157/200] [Batch 420/938] loss_G: 3.221062, loss_D: 0.235548\n",
            "[Epoch 157/200] [Batch 430/938] loss_G: 2.750840, loss_D: 0.187599\n",
            "[Epoch 157/200] [Batch 440/938] loss_G: 3.222875, loss_D: 0.140118\n",
            "[Epoch 157/200] [Batch 450/938] loss_G: 2.748672, loss_D: 0.178102\n",
            "[Epoch 157/200] [Batch 460/938] loss_G: 2.882571, loss_D: 0.228584\n",
            "[Epoch 157/200] [Batch 470/938] loss_G: 2.920852, loss_D: 0.229130\n",
            "[Epoch 157/200] [Batch 480/938] loss_G: 3.363868, loss_D: 0.171990\n",
            "[Epoch 157/200] [Batch 490/938] loss_G: 2.972537, loss_D: 0.205120\n",
            "[Epoch 157/200] [Batch 500/938] loss_G: 3.061333, loss_D: 0.117194\n",
            "[Epoch 157/200] [Batch 510/938] loss_G: 2.852222, loss_D: 0.197800\n",
            "[Epoch 157/200] [Batch 520/938] loss_G: 3.249806, loss_D: 0.205222\n",
            "[Epoch 157/200] [Batch 530/938] loss_G: 3.354085, loss_D: 0.139505\n",
            "[Epoch 157/200] [Batch 540/938] loss_G: 3.144953, loss_D: 0.238112\n",
            "[Epoch 157/200] [Batch 550/938] loss_G: 3.143262, loss_D: 0.246970\n",
            "[Epoch 157/200] [Batch 560/938] loss_G: 2.947408, loss_D: 0.162698\n",
            "[Epoch 157/200] [Batch 570/938] loss_G: 2.959738, loss_D: 0.136226\n",
            "[Epoch 157/200] [Batch 580/938] loss_G: 3.234928, loss_D: 0.075237\n",
            "[Epoch 157/200] [Batch 590/938] loss_G: 3.018090, loss_D: 0.275299\n",
            "[Epoch 157/200] [Batch 600/938] loss_G: 3.077549, loss_D: 0.128227\n",
            "[Epoch 157/200] [Batch 610/938] loss_G: 2.953092, loss_D: 0.142237\n",
            "[Epoch 157/200] [Batch 620/938] loss_G: 2.760892, loss_D: 0.192953\n",
            "[Epoch 157/200] [Batch 630/938] loss_G: 3.217530, loss_D: 0.176696\n",
            "[Epoch 157/200] [Batch 640/938] loss_G: 2.915560, loss_D: 0.220000\n",
            "[Epoch 157/200] [Batch 650/938] loss_G: 3.400961, loss_D: 0.218868\n",
            "[Epoch 157/200] [Batch 660/938] loss_G: 3.116117, loss_D: 0.232357\n",
            "[Epoch 157/200] [Batch 670/938] loss_G: 2.943072, loss_D: 0.201167\n",
            "[Epoch 157/200] [Batch 680/938] loss_G: 2.948936, loss_D: 0.245573\n",
            "[Epoch 157/200] [Batch 690/938] loss_G: 2.689316, loss_D: 0.217561\n",
            "[Epoch 157/200] [Batch 700/938] loss_G: 3.199014, loss_D: 0.137732\n",
            "[Epoch 157/200] [Batch 710/938] loss_G: 3.239460, loss_D: 0.135852\n",
            "[Epoch 157/200] [Batch 720/938] loss_G: 3.150490, loss_D: 0.185994\n",
            "[Epoch 157/200] [Batch 730/938] loss_G: 3.172374, loss_D: 0.200942\n",
            "[Epoch 157/200] [Batch 740/938] loss_G: 3.308933, loss_D: 0.256543\n",
            "[Epoch 157/200] [Batch 750/938] loss_G: 3.382042, loss_D: 0.215507\n",
            "[Epoch 157/200] [Batch 760/938] loss_G: 3.131781, loss_D: 0.279103\n",
            "[Epoch 157/200] [Batch 770/938] loss_G: 3.105071, loss_D: 0.241674\n",
            "[Epoch 157/200] [Batch 780/938] loss_G: 3.095387, loss_D: 0.198031\n",
            "[Epoch 157/200] [Batch 790/938] loss_G: 3.278952, loss_D: 0.276188\n",
            "[Epoch 157/200] [Batch 800/938] loss_G: 3.220156, loss_D: 0.154524\n",
            "[Epoch 157/200] [Batch 810/938] loss_G: 3.266197, loss_D: 0.136013\n",
            "[Epoch 157/200] [Batch 820/938] loss_G: 3.141601, loss_D: 0.224361\n",
            "[Epoch 157/200] [Batch 830/938] loss_G: 3.314053, loss_D: 0.179614\n",
            "[Epoch 157/200] [Batch 840/938] loss_G: 3.358974, loss_D: 0.188946\n",
            "[Epoch 157/200] [Batch 850/938] loss_G: 2.676305, loss_D: 0.337836\n",
            "[Epoch 157/200] [Batch 860/938] loss_G: 3.119381, loss_D: 0.293816\n",
            "[Epoch 157/200] [Batch 870/938] loss_G: 3.089675, loss_D: 0.298084\n",
            "[Epoch 157/200] [Batch 880/938] loss_G: 3.145194, loss_D: 0.227453\n",
            "[Epoch 157/200] [Batch 890/938] loss_G: 2.945539, loss_D: 0.162558\n",
            "[Epoch 157/200] [Batch 900/938] loss_G: 3.138216, loss_D: 0.158959\n",
            "[Epoch 157/200] [Batch 910/938] loss_G: 3.384156, loss_D: 0.292521\n",
            "[Epoch 157/200] [Batch 920/938] loss_G: 3.008524, loss_D: 0.224612\n",
            "[Epoch 157/200] [Batch 930/938] loss_G: 3.037380, loss_D: 0.196005\n",
            "[Epoch 158/200] [Batch 0/938] loss_G: 3.121953, loss_D: 0.179303\n",
            "[Epoch 158/200] [Batch 10/938] loss_G: 2.586594, loss_D: 0.173197\n",
            "[Epoch 158/200] [Batch 20/938] loss_G: 2.890469, loss_D: 0.222615\n",
            "[Epoch 158/200] [Batch 30/938] loss_G: 2.857792, loss_D: 0.206529\n",
            "[Epoch 158/200] [Batch 40/938] loss_G: 2.726435, loss_D: 0.234136\n",
            "[Epoch 158/200] [Batch 50/938] loss_G: 2.891550, loss_D: 0.307292\n",
            "[Epoch 158/200] [Batch 60/938] loss_G: 3.146762, loss_D: 0.227196\n",
            "[Epoch 158/200] [Batch 70/938] loss_G: 2.607552, loss_D: 0.194065\n",
            "[Epoch 158/200] [Batch 80/938] loss_G: 2.738692, loss_D: 0.211360\n",
            "[Epoch 158/200] [Batch 90/938] loss_G: 2.911453, loss_D: 0.284221\n",
            "[Epoch 158/200] [Batch 100/938] loss_G: 3.002761, loss_D: 0.255415\n",
            "[Epoch 158/200] [Batch 110/938] loss_G: 2.673626, loss_D: 0.222929\n",
            "[Epoch 158/200] [Batch 120/938] loss_G: 2.778362, loss_D: 0.092312\n",
            "[Epoch 158/200] [Batch 130/938] loss_G: 2.982244, loss_D: 0.219653\n",
            "[Epoch 158/200] [Batch 140/938] loss_G: 2.988423, loss_D: 0.163554\n",
            "[Epoch 158/200] [Batch 150/938] loss_G: 3.056303, loss_D: 0.218305\n",
            "[Epoch 158/200] [Batch 160/938] loss_G: 3.119462, loss_D: 0.145689\n",
            "[Epoch 158/200] [Batch 170/938] loss_G: 2.838364, loss_D: 0.193497\n",
            "[Epoch 158/200] [Batch 180/938] loss_G: 3.313493, loss_D: 0.131898\n",
            "[Epoch 158/200] [Batch 190/938] loss_G: 2.767425, loss_D: 0.145060\n",
            "[Epoch 158/200] [Batch 200/938] loss_G: 3.016500, loss_D: 0.159856\n",
            "[Epoch 158/200] [Batch 210/938] loss_G: 2.842805, loss_D: 0.192835\n",
            "[Epoch 158/200] [Batch 220/938] loss_G: 3.177420, loss_D: 0.208832\n",
            "[Epoch 158/200] [Batch 230/938] loss_G: 3.385090, loss_D: 0.233996\n",
            "[Epoch 158/200] [Batch 240/938] loss_G: 2.724872, loss_D: 0.256380\n",
            "[Epoch 158/200] [Batch 250/938] loss_G: 3.359327, loss_D: 0.152042\n",
            "[Epoch 158/200] [Batch 260/938] loss_G: 2.971185, loss_D: 0.158731\n",
            "[Epoch 158/200] [Batch 270/938] loss_G: 3.446349, loss_D: 0.235193\n",
            "[Epoch 158/200] [Batch 280/938] loss_G: 2.990876, loss_D: 0.269277\n",
            "[Epoch 158/200] [Batch 290/938] loss_G: 3.116599, loss_D: 0.184509\n",
            "[Epoch 158/200] [Batch 300/938] loss_G: 3.556628, loss_D: 0.237076\n",
            "[Epoch 158/200] [Batch 310/938] loss_G: 2.876209, loss_D: 0.277436\n",
            "[Epoch 158/200] [Batch 320/938] loss_G: 2.810559, loss_D: 0.197869\n",
            "[Epoch 158/200] [Batch 330/938] loss_G: 3.037123, loss_D: 0.244006\n",
            "[Epoch 158/200] [Batch 340/938] loss_G: 3.320898, loss_D: 0.161284\n",
            "[Epoch 158/200] [Batch 350/938] loss_G: 3.160825, loss_D: 0.250447\n",
            "[Epoch 158/200] [Batch 360/938] loss_G: 3.195942, loss_D: 0.222427\n",
            "[Epoch 158/200] [Batch 370/938] loss_G: 3.393784, loss_D: 0.158095\n",
            "[Epoch 158/200] [Batch 380/938] loss_G: 3.324568, loss_D: 0.214902\n",
            "[Epoch 158/200] [Batch 390/938] loss_G: 3.341008, loss_D: 0.181837\n",
            "[Epoch 158/200] [Batch 400/938] loss_G: 2.928253, loss_D: 0.151783\n",
            "[Epoch 158/200] [Batch 410/938] loss_G: 3.166922, loss_D: 0.213860\n",
            "[Epoch 158/200] [Batch 420/938] loss_G: 2.994290, loss_D: 0.194424\n",
            "[Epoch 158/200] [Batch 430/938] loss_G: 3.168445, loss_D: 0.189045\n",
            "[Epoch 158/200] [Batch 440/938] loss_G: 3.168571, loss_D: 0.206651\n",
            "[Epoch 158/200] [Batch 450/938] loss_G: 2.905008, loss_D: 0.237028\n",
            "[Epoch 158/200] [Batch 460/938] loss_G: 3.161010, loss_D: 0.345163\n",
            "[Epoch 158/200] [Batch 470/938] loss_G: 3.107489, loss_D: 0.204469\n",
            "[Epoch 158/200] [Batch 480/938] loss_G: 3.145482, loss_D: 0.237256\n",
            "[Epoch 158/200] [Batch 490/938] loss_G: 3.053734, loss_D: 0.144074\n",
            "[Epoch 158/200] [Batch 500/938] loss_G: 3.203263, loss_D: 0.237840\n",
            "[Epoch 158/200] [Batch 510/938] loss_G: 2.720795, loss_D: 0.216823\n",
            "[Epoch 158/200] [Batch 520/938] loss_G: 2.952512, loss_D: 0.256140\n",
            "[Epoch 158/200] [Batch 530/938] loss_G: 3.215796, loss_D: 0.164987\n",
            "[Epoch 158/200] [Batch 540/938] loss_G: 2.976062, loss_D: 0.190226\n",
            "[Epoch 158/200] [Batch 550/938] loss_G: 3.130264, loss_D: 0.278354\n",
            "[Epoch 158/200] [Batch 560/938] loss_G: 3.097441, loss_D: 0.189893\n",
            "[Epoch 158/200] [Batch 570/938] loss_G: 2.811881, loss_D: 0.258834\n",
            "[Epoch 158/200] [Batch 580/938] loss_G: 3.037918, loss_D: 0.262161\n",
            "[Epoch 158/200] [Batch 590/938] loss_G: 3.356213, loss_D: 0.169935\n",
            "[Epoch 158/200] [Batch 600/938] loss_G: 3.564671, loss_D: 0.166921\n",
            "[Epoch 158/200] [Batch 610/938] loss_G: 2.790513, loss_D: 0.119585\n",
            "[Epoch 158/200] [Batch 620/938] loss_G: 2.524896, loss_D: 0.276058\n",
            "[Epoch 158/200] [Batch 630/938] loss_G: 3.217755, loss_D: 0.286528\n",
            "[Epoch 158/200] [Batch 640/938] loss_G: 3.260764, loss_D: 0.170251\n",
            "[Epoch 158/200] [Batch 650/938] loss_G: 3.008635, loss_D: 0.200075\n",
            "[Epoch 158/200] [Batch 660/938] loss_G: 3.084800, loss_D: 0.247831\n",
            "[Epoch 158/200] [Batch 670/938] loss_G: 2.980569, loss_D: 0.151175\n",
            "[Epoch 158/200] [Batch 680/938] loss_G: 2.912770, loss_D: 0.312830\n",
            "[Epoch 158/200] [Batch 690/938] loss_G: 3.146647, loss_D: 0.160098\n",
            "[Epoch 158/200] [Batch 700/938] loss_G: 3.388820, loss_D: 0.223785\n",
            "[Epoch 158/200] [Batch 710/938] loss_G: 3.187600, loss_D: 0.187018\n",
            "[Epoch 158/200] [Batch 720/938] loss_G: 2.965914, loss_D: 0.183263\n",
            "[Epoch 158/200] [Batch 730/938] loss_G: 3.027065, loss_D: 0.207547\n",
            "[Epoch 158/200] [Batch 740/938] loss_G: 2.937007, loss_D: 0.176064\n",
            "[Epoch 158/200] [Batch 750/938] loss_G: 3.086095, loss_D: 0.293567\n",
            "[Epoch 158/200] [Batch 760/938] loss_G: 3.136878, loss_D: 0.165913\n",
            "[Epoch 158/200] [Batch 770/938] loss_G: 3.252116, loss_D: 0.188316\n",
            "[Epoch 158/200] [Batch 780/938] loss_G: 3.098233, loss_D: 0.194112\n",
            "[Epoch 158/200] [Batch 790/938] loss_G: 3.276092, loss_D: 0.207215\n",
            "[Epoch 158/200] [Batch 800/938] loss_G: 3.207375, loss_D: 0.169534\n",
            "[Epoch 158/200] [Batch 810/938] loss_G: 2.903089, loss_D: 0.193789\n",
            "[Epoch 158/200] [Batch 820/938] loss_G: 3.146972, loss_D: 0.209171\n",
            "[Epoch 158/200] [Batch 830/938] loss_G: 3.248005, loss_D: 0.222161\n",
            "[Epoch 158/200] [Batch 840/938] loss_G: 3.453705, loss_D: 0.210973\n",
            "[Epoch 158/200] [Batch 850/938] loss_G: 2.991631, loss_D: 0.169565\n",
            "[Epoch 158/200] [Batch 860/938] loss_G: 3.140600, loss_D: 0.176988\n",
            "[Epoch 158/200] [Batch 870/938] loss_G: 3.305140, loss_D: 0.135440\n",
            "[Epoch 158/200] [Batch 880/938] loss_G: 2.719030, loss_D: 0.241472\n",
            "[Epoch 158/200] [Batch 890/938] loss_G: 2.921502, loss_D: 0.224712\n",
            "[Epoch 158/200] [Batch 900/938] loss_G: 3.198474, loss_D: 0.210365\n",
            "[Epoch 158/200] [Batch 910/938] loss_G: 3.295016, loss_D: 0.093687\n",
            "[Epoch 158/200] [Batch 920/938] loss_G: 3.127808, loss_D: 0.277676\n",
            "[Epoch 158/200] [Batch 930/938] loss_G: 3.251054, loss_D: 0.196449\n",
            "[Epoch 159/200] [Batch 0/938] loss_G: 2.994165, loss_D: 0.242153\n",
            "[Epoch 159/200] [Batch 10/938] loss_G: 2.946972, loss_D: 0.135696\n",
            "[Epoch 159/200] [Batch 20/938] loss_G: 2.828021, loss_D: 0.174564\n",
            "[Epoch 159/200] [Batch 30/938] loss_G: 2.787449, loss_D: 0.221786\n",
            "[Epoch 159/200] [Batch 40/938] loss_G: 3.499806, loss_D: 0.197032\n",
            "[Epoch 159/200] [Batch 50/938] loss_G: 2.906513, loss_D: 0.207558\n",
            "[Epoch 159/200] [Batch 60/938] loss_G: 3.184577, loss_D: 0.185542\n",
            "[Epoch 159/200] [Batch 70/938] loss_G: 3.061188, loss_D: 0.238236\n",
            "[Epoch 159/200] [Batch 80/938] loss_G: 2.973653, loss_D: 0.265967\n",
            "[Epoch 159/200] [Batch 90/938] loss_G: 3.057524, loss_D: 0.228205\n",
            "[Epoch 159/200] [Batch 100/938] loss_G: 3.378517, loss_D: 0.203659\n",
            "[Epoch 159/200] [Batch 110/938] loss_G: 2.920433, loss_D: 0.190586\n",
            "[Epoch 159/200] [Batch 120/938] loss_G: 3.033112, loss_D: 0.199550\n",
            "[Epoch 159/200] [Batch 130/938] loss_G: 3.033331, loss_D: 0.149721\n",
            "[Epoch 159/200] [Batch 140/938] loss_G: 3.198541, loss_D: 0.218955\n",
            "[Epoch 159/200] [Batch 150/938] loss_G: 3.209515, loss_D: 0.134077\n",
            "[Epoch 159/200] [Batch 160/938] loss_G: 3.122660, loss_D: 0.158911\n",
            "[Epoch 159/200] [Batch 170/938] loss_G: 3.531217, loss_D: 0.090676\n",
            "[Epoch 159/200] [Batch 180/938] loss_G: 3.021739, loss_D: 0.272170\n",
            "[Epoch 159/200] [Batch 190/938] loss_G: 3.149503, loss_D: 0.249854\n",
            "[Epoch 159/200] [Batch 200/938] loss_G: 2.816158, loss_D: 0.235288\n",
            "[Epoch 159/200] [Batch 210/938] loss_G: 2.910789, loss_D: 0.203568\n",
            "[Epoch 159/200] [Batch 220/938] loss_G: 3.265832, loss_D: 0.180195\n",
            "[Epoch 159/200] [Batch 230/938] loss_G: 2.855708, loss_D: 0.193132\n",
            "[Epoch 159/200] [Batch 240/938] loss_G: 3.458024, loss_D: 0.263859\n",
            "[Epoch 159/200] [Batch 250/938] loss_G: 2.899893, loss_D: 0.188995\n",
            "[Epoch 159/200] [Batch 260/938] loss_G: 3.141073, loss_D: 0.222969\n",
            "[Epoch 159/200] [Batch 270/938] loss_G: 3.302091, loss_D: 0.188546\n",
            "[Epoch 159/200] [Batch 280/938] loss_G: 2.859819, loss_D: 0.150408\n",
            "[Epoch 159/200] [Batch 290/938] loss_G: 3.243468, loss_D: 0.177297\n",
            "[Epoch 159/200] [Batch 300/938] loss_G: 2.919147, loss_D: 0.173609\n",
            "[Epoch 159/200] [Batch 310/938] loss_G: 3.038606, loss_D: 0.169024\n",
            "[Epoch 159/200] [Batch 320/938] loss_G: 3.510004, loss_D: 0.234212\n",
            "[Epoch 159/200] [Batch 330/938] loss_G: 2.970109, loss_D: 0.208132\n",
            "[Epoch 159/200] [Batch 340/938] loss_G: 2.965090, loss_D: 0.194325\n",
            "[Epoch 159/200] [Batch 350/938] loss_G: 3.228738, loss_D: 0.141003\n",
            "[Epoch 159/200] [Batch 360/938] loss_G: 3.102242, loss_D: 0.182028\n",
            "[Epoch 159/200] [Batch 370/938] loss_G: 2.971927, loss_D: 0.300597\n",
            "[Epoch 159/200] [Batch 380/938] loss_G: 2.940871, loss_D: 0.153592\n",
            "[Epoch 159/200] [Batch 390/938] loss_G: 3.107741, loss_D: 0.212348\n",
            "[Epoch 159/200] [Batch 400/938] loss_G: 2.478738, loss_D: 0.258816\n",
            "[Epoch 159/200] [Batch 410/938] loss_G: 2.980227, loss_D: 0.210584\n",
            "[Epoch 159/200] [Batch 420/938] loss_G: 3.029864, loss_D: 0.208049\n",
            "[Epoch 159/200] [Batch 430/938] loss_G: 3.030866, loss_D: 0.181392\n",
            "[Epoch 159/200] [Batch 440/938] loss_G: 3.214404, loss_D: 0.197308\n",
            "[Epoch 159/200] [Batch 450/938] loss_G: 2.819251, loss_D: 0.195677\n",
            "[Epoch 159/200] [Batch 460/938] loss_G: 3.057780, loss_D: 0.177289\n",
            "[Epoch 159/200] [Batch 470/938] loss_G: 3.205241, loss_D: 0.124603\n",
            "[Epoch 159/200] [Batch 480/938] loss_G: 3.122721, loss_D: 0.247577\n",
            "[Epoch 159/200] [Batch 490/938] loss_G: 3.251850, loss_D: 0.131399\n",
            "[Epoch 159/200] [Batch 500/938] loss_G: 2.994336, loss_D: 0.139820\n",
            "[Epoch 159/200] [Batch 510/938] loss_G: 3.115825, loss_D: 0.290668\n",
            "[Epoch 159/200] [Batch 520/938] loss_G: 3.554201, loss_D: 0.198692\n",
            "[Epoch 159/200] [Batch 530/938] loss_G: 3.094322, loss_D: 0.212895\n",
            "[Epoch 159/200] [Batch 540/938] loss_G: 3.154765, loss_D: 0.226296\n",
            "[Epoch 159/200] [Batch 550/938] loss_G: 2.998856, loss_D: 0.244337\n",
            "[Epoch 159/200] [Batch 560/938] loss_G: 3.104014, loss_D: 0.189406\n",
            "[Epoch 159/200] [Batch 570/938] loss_G: 3.028578, loss_D: 0.207021\n",
            "[Epoch 159/200] [Batch 580/938] loss_G: 2.913330, loss_D: 0.257346\n",
            "[Epoch 159/200] [Batch 590/938] loss_G: 3.452526, loss_D: 0.223735\n",
            "[Epoch 159/200] [Batch 600/938] loss_G: 3.401307, loss_D: 0.197792\n",
            "[Epoch 159/200] [Batch 610/938] loss_G: 3.016294, loss_D: 0.285033\n",
            "[Epoch 159/200] [Batch 620/938] loss_G: 3.582122, loss_D: 0.222755\n",
            "[Epoch 159/200] [Batch 630/938] loss_G: 3.002073, loss_D: 0.201059\n",
            "[Epoch 159/200] [Batch 640/938] loss_G: 3.093262, loss_D: 0.227200\n",
            "[Epoch 159/200] [Batch 650/938] loss_G: 3.413896, loss_D: 0.250795\n",
            "[Epoch 159/200] [Batch 660/938] loss_G: 3.132749, loss_D: 0.231950\n",
            "[Epoch 159/200] [Batch 670/938] loss_G: 3.151463, loss_D: 0.184484\n",
            "[Epoch 159/200] [Batch 680/938] loss_G: 3.395376, loss_D: 0.312825\n",
            "[Epoch 159/200] [Batch 690/938] loss_G: 2.862146, loss_D: 0.228367\n",
            "[Epoch 159/200] [Batch 700/938] loss_G: 3.472568, loss_D: 0.224069\n",
            "[Epoch 159/200] [Batch 710/938] loss_G: 3.109778, loss_D: 0.239686\n",
            "[Epoch 159/200] [Batch 720/938] loss_G: 3.358665, loss_D: 0.175631\n",
            "[Epoch 159/200] [Batch 730/938] loss_G: 2.962059, loss_D: 0.153900\n",
            "[Epoch 159/200] [Batch 740/938] loss_G: 3.222816, loss_D: 0.135243\n",
            "[Epoch 159/200] [Batch 750/938] loss_G: 3.051475, loss_D: 0.248971\n",
            "[Epoch 159/200] [Batch 760/938] loss_G: 3.204651, loss_D: 0.172195\n",
            "[Epoch 159/200] [Batch 770/938] loss_G: 2.959977, loss_D: 0.173048\n",
            "[Epoch 159/200] [Batch 780/938] loss_G: 2.930899, loss_D: 0.203453\n",
            "[Epoch 159/200] [Batch 790/938] loss_G: 3.052857, loss_D: 0.157001\n",
            "[Epoch 159/200] [Batch 800/938] loss_G: 3.004293, loss_D: 0.251910\n",
            "[Epoch 159/200] [Batch 810/938] loss_G: 2.925541, loss_D: 0.211205\n",
            "[Epoch 159/200] [Batch 820/938] loss_G: 3.116144, loss_D: 0.202274\n",
            "[Epoch 159/200] [Batch 830/938] loss_G: 3.040774, loss_D: 0.226127\n",
            "[Epoch 159/200] [Batch 840/938] loss_G: 3.065255, loss_D: 0.165794\n",
            "[Epoch 159/200] [Batch 850/938] loss_G: 3.007109, loss_D: 0.187167\n",
            "[Epoch 159/200] [Batch 860/938] loss_G: 2.778259, loss_D: 0.295031\n",
            "[Epoch 159/200] [Batch 870/938] loss_G: 3.312999, loss_D: 0.148785\n",
            "[Epoch 159/200] [Batch 880/938] loss_G: 2.788126, loss_D: 0.301987\n",
            "[Epoch 159/200] [Batch 890/938] loss_G: 3.125796, loss_D: 0.190915\n",
            "[Epoch 159/200] [Batch 900/938] loss_G: 2.960677, loss_D: 0.234255\n",
            "[Epoch 159/200] [Batch 910/938] loss_G: 2.902260, loss_D: 0.200804\n",
            "[Epoch 159/200] [Batch 920/938] loss_G: 3.036158, loss_D: 0.158779\n",
            "[Epoch 159/200] [Batch 930/938] loss_G: 3.337829, loss_D: 0.172926\n",
            "[Epoch 160/200] [Batch 0/938] loss_G: 3.021584, loss_D: 0.229277\n",
            "[Epoch 160/200] [Batch 10/938] loss_G: 3.105786, loss_D: 0.188859\n",
            "[Epoch 160/200] [Batch 20/938] loss_G: 2.749534, loss_D: 0.288729\n",
            "[Epoch 160/200] [Batch 30/938] loss_G: 3.072653, loss_D: 0.130205\n",
            "[Epoch 160/200] [Batch 40/938] loss_G: 3.036896, loss_D: 0.192640\n",
            "[Epoch 160/200] [Batch 50/938] loss_G: 2.964747, loss_D: 0.277046\n",
            "[Epoch 160/200] [Batch 60/938] loss_G: 2.912611, loss_D: 0.187449\n",
            "[Epoch 160/200] [Batch 70/938] loss_G: 3.118223, loss_D: 0.134349\n",
            "[Epoch 160/200] [Batch 80/938] loss_G: 3.166724, loss_D: 0.272853\n",
            "[Epoch 160/200] [Batch 90/938] loss_G: 3.642084, loss_D: 0.148359\n",
            "[Epoch 160/200] [Batch 100/938] loss_G: 3.010691, loss_D: 0.314389\n",
            "[Epoch 160/200] [Batch 110/938] loss_G: 3.007235, loss_D: 0.173873\n",
            "[Epoch 160/200] [Batch 120/938] loss_G: 3.009277, loss_D: 0.130468\n",
            "[Epoch 160/200] [Batch 130/938] loss_G: 3.009915, loss_D: 0.201541\n",
            "[Epoch 160/200] [Batch 140/938] loss_G: 2.930499, loss_D: 0.211210\n",
            "[Epoch 160/200] [Batch 150/938] loss_G: 3.100878, loss_D: 0.171031\n",
            "[Epoch 160/200] [Batch 160/938] loss_G: 3.264088, loss_D: 0.173920\n",
            "[Epoch 160/200] [Batch 170/938] loss_G: 2.747842, loss_D: 0.235477\n",
            "[Epoch 160/200] [Batch 180/938] loss_G: 2.945466, loss_D: 0.282084\n",
            "[Epoch 160/200] [Batch 190/938] loss_G: 2.965324, loss_D: 0.182135\n",
            "[Epoch 160/200] [Batch 200/938] loss_G: 2.763433, loss_D: 0.143545\n",
            "[Epoch 160/200] [Batch 210/938] loss_G: 3.424494, loss_D: 0.165596\n",
            "[Epoch 160/200] [Batch 220/938] loss_G: 2.714985, loss_D: 0.139669\n",
            "[Epoch 160/200] [Batch 230/938] loss_G: 2.607815, loss_D: 0.234714\n",
            "[Epoch 160/200] [Batch 240/938] loss_G: 3.220744, loss_D: 0.192678\n",
            "[Epoch 160/200] [Batch 250/938] loss_G: 3.281713, loss_D: 0.252072\n",
            "[Epoch 160/200] [Batch 260/938] loss_G: 2.944775, loss_D: 0.219995\n",
            "[Epoch 160/200] [Batch 270/938] loss_G: 3.245824, loss_D: 0.180965\n",
            "[Epoch 160/200] [Batch 280/938] loss_G: 2.778083, loss_D: 0.249164\n",
            "[Epoch 160/200] [Batch 290/938] loss_G: 3.184955, loss_D: 0.170585\n",
            "[Epoch 160/200] [Batch 300/938] loss_G: 3.264427, loss_D: 0.281118\n",
            "[Epoch 160/200] [Batch 310/938] loss_G: 3.029049, loss_D: 0.131905\n",
            "[Epoch 160/200] [Batch 320/938] loss_G: 3.337975, loss_D: 0.231953\n",
            "[Epoch 160/200] [Batch 330/938] loss_G: 3.077760, loss_D: 0.258607\n",
            "[Epoch 160/200] [Batch 340/938] loss_G: 2.743832, loss_D: 0.237998\n",
            "[Epoch 160/200] [Batch 350/938] loss_G: 2.938938, loss_D: 0.216495\n",
            "[Epoch 160/200] [Batch 360/938] loss_G: 3.513031, loss_D: 0.162141\n",
            "[Epoch 160/200] [Batch 370/938] loss_G: 3.161575, loss_D: 0.158253\n",
            "[Epoch 160/200] [Batch 380/938] loss_G: 3.057698, loss_D: 0.192555\n",
            "[Epoch 160/200] [Batch 390/938] loss_G: 3.207185, loss_D: 0.212316\n",
            "[Epoch 160/200] [Batch 400/938] loss_G: 2.835746, loss_D: 0.221664\n",
            "[Epoch 160/200] [Batch 410/938] loss_G: 2.756366, loss_D: 0.158660\n",
            "[Epoch 160/200] [Batch 420/938] loss_G: 3.085032, loss_D: 0.156594\n",
            "[Epoch 160/200] [Batch 430/938] loss_G: 3.135855, loss_D: 0.153781\n",
            "[Epoch 160/200] [Batch 440/938] loss_G: 2.637727, loss_D: 0.188300\n",
            "[Epoch 160/200] [Batch 450/938] loss_G: 3.120783, loss_D: 0.193638\n",
            "[Epoch 160/200] [Batch 460/938] loss_G: 3.058735, loss_D: 0.289210\n",
            "[Epoch 160/200] [Batch 470/938] loss_G: 2.869663, loss_D: 0.203248\n",
            "[Epoch 160/200] [Batch 480/938] loss_G: 3.022994, loss_D: 0.203301\n",
            "[Epoch 160/200] [Batch 490/938] loss_G: 3.344561, loss_D: 0.189265\n",
            "[Epoch 160/200] [Batch 500/938] loss_G: 3.070870, loss_D: 0.201352\n",
            "[Epoch 160/200] [Batch 510/938] loss_G: 3.282662, loss_D: 0.174635\n",
            "[Epoch 160/200] [Batch 520/938] loss_G: 3.326977, loss_D: 0.132962\n",
            "[Epoch 160/200] [Batch 530/938] loss_G: 3.302280, loss_D: 0.225742\n",
            "[Epoch 160/200] [Batch 540/938] loss_G: 3.496942, loss_D: 0.249824\n",
            "[Epoch 160/200] [Batch 550/938] loss_G: 3.136063, loss_D: 0.172534\n",
            "[Epoch 160/200] [Batch 560/938] loss_G: 3.187376, loss_D: 0.193812\n",
            "[Epoch 160/200] [Batch 570/938] loss_G: 2.849226, loss_D: 0.138754\n",
            "[Epoch 160/200] [Batch 580/938] loss_G: 3.652848, loss_D: 0.237820\n",
            "[Epoch 160/200] [Batch 590/938] loss_G: 3.232116, loss_D: 0.214678\n",
            "[Epoch 160/200] [Batch 600/938] loss_G: 2.717909, loss_D: 0.225062\n",
            "[Epoch 160/200] [Batch 610/938] loss_G: 3.833181, loss_D: 0.241546\n",
            "[Epoch 160/200] [Batch 620/938] loss_G: 3.171073, loss_D: 0.177304\n",
            "[Epoch 160/200] [Batch 630/938] loss_G: 3.054374, loss_D: 0.205509\n",
            "[Epoch 160/200] [Batch 640/938] loss_G: 3.171712, loss_D: 0.201853\n",
            "[Epoch 160/200] [Batch 650/938] loss_G: 2.949829, loss_D: 0.258091\n",
            "[Epoch 160/200] [Batch 660/938] loss_G: 3.303954, loss_D: 0.257668\n",
            "[Epoch 160/200] [Batch 670/938] loss_G: 3.149844, loss_D: 0.204533\n",
            "[Epoch 160/200] [Batch 680/938] loss_G: 3.496062, loss_D: 0.179803\n",
            "[Epoch 160/200] [Batch 690/938] loss_G: 2.726354, loss_D: 0.169176\n",
            "[Epoch 160/200] [Batch 700/938] loss_G: 2.978569, loss_D: 0.257068\n",
            "[Epoch 160/200] [Batch 710/938] loss_G: 2.781396, loss_D: 0.263368\n",
            "[Epoch 160/200] [Batch 720/938] loss_G: 3.027903, loss_D: 0.276122\n",
            "[Epoch 160/200] [Batch 730/938] loss_G: 2.854120, loss_D: 0.109665\n",
            "[Epoch 160/200] [Batch 740/938] loss_G: 3.049790, loss_D: 0.175737\n",
            "[Epoch 160/200] [Batch 750/938] loss_G: 3.118997, loss_D: 0.201737\n",
            "[Epoch 160/200] [Batch 760/938] loss_G: 3.289208, loss_D: 0.164243\n",
            "[Epoch 160/200] [Batch 770/938] loss_G: 3.063605, loss_D: 0.199951\n",
            "[Epoch 160/200] [Batch 780/938] loss_G: 3.155283, loss_D: 0.182362\n",
            "[Epoch 160/200] [Batch 790/938] loss_G: 3.195008, loss_D: 0.202895\n",
            "[Epoch 160/200] [Batch 800/938] loss_G: 3.285165, loss_D: 0.263690\n",
            "[Epoch 160/200] [Batch 810/938] loss_G: 3.016576, loss_D: 0.257064\n",
            "[Epoch 160/200] [Batch 820/938] loss_G: 3.250695, loss_D: 0.194517\n",
            "[Epoch 160/200] [Batch 830/938] loss_G: 3.197467, loss_D: 0.153754\n",
            "[Epoch 160/200] [Batch 840/938] loss_G: 3.167725, loss_D: 0.232667\n",
            "[Epoch 160/200] [Batch 850/938] loss_G: 2.958435, loss_D: 0.146611\n",
            "[Epoch 160/200] [Batch 860/938] loss_G: 3.058747, loss_D: 0.203825\n",
            "[Epoch 160/200] [Batch 870/938] loss_G: 2.940771, loss_D: 0.157096\n",
            "[Epoch 160/200] [Batch 880/938] loss_G: 3.212698, loss_D: 0.212947\n",
            "[Epoch 160/200] [Batch 890/938] loss_G: 3.360528, loss_D: 0.157666\n",
            "[Epoch 160/200] [Batch 900/938] loss_G: 2.890987, loss_D: 0.216458\n",
            "[Epoch 160/200] [Batch 910/938] loss_G: 2.935652, loss_D: 0.259045\n",
            "[Epoch 160/200] [Batch 920/938] loss_G: 3.223600, loss_D: 0.194615\n",
            "[Epoch 160/200] [Batch 930/938] loss_G: 3.256541, loss_D: 0.243690\n",
            "[Epoch 161/200] [Batch 0/938] loss_G: 2.893648, loss_D: 0.261365\n",
            "[Epoch 161/200] [Batch 10/938] loss_G: 3.283813, loss_D: 0.237370\n",
            "[Epoch 161/200] [Batch 20/938] loss_G: 2.857317, loss_D: 0.219124\n",
            "[Epoch 161/200] [Batch 30/938] loss_G: 3.153025, loss_D: 0.174279\n",
            "[Epoch 161/200] [Batch 40/938] loss_G: 3.115377, loss_D: 0.217423\n",
            "[Epoch 161/200] [Batch 50/938] loss_G: 3.202634, loss_D: 0.173604\n",
            "[Epoch 161/200] [Batch 60/938] loss_G: 2.806061, loss_D: 0.190797\n",
            "[Epoch 161/200] [Batch 70/938] loss_G: 3.091854, loss_D: 0.177240\n",
            "[Epoch 161/200] [Batch 80/938] loss_G: 3.018447, loss_D: 0.264296\n",
            "[Epoch 161/200] [Batch 90/938] loss_G: 2.960993, loss_D: 0.181999\n",
            "[Epoch 161/200] [Batch 100/938] loss_G: 3.506228, loss_D: 0.170630\n",
            "[Epoch 161/200] [Batch 110/938] loss_G: 3.076233, loss_D: 0.235501\n",
            "[Epoch 161/200] [Batch 120/938] loss_G: 3.239978, loss_D: 0.168654\n",
            "[Epoch 161/200] [Batch 130/938] loss_G: 3.162415, loss_D: 0.174044\n",
            "[Epoch 161/200] [Batch 140/938] loss_G: 2.978388, loss_D: 0.173652\n",
            "[Epoch 161/200] [Batch 150/938] loss_G: 3.187173, loss_D: 0.204879\n",
            "[Epoch 161/200] [Batch 160/938] loss_G: 2.961928, loss_D: 0.202575\n",
            "[Epoch 161/200] [Batch 170/938] loss_G: 3.048714, loss_D: 0.188702\n",
            "[Epoch 161/200] [Batch 180/938] loss_G: 3.466158, loss_D: 0.174320\n",
            "[Epoch 161/200] [Batch 190/938] loss_G: 2.622492, loss_D: 0.336514\n",
            "[Epoch 161/200] [Batch 200/938] loss_G: 3.266456, loss_D: 0.203839\n",
            "[Epoch 161/200] [Batch 210/938] loss_G: 3.302072, loss_D: 0.166717\n",
            "[Epoch 161/200] [Batch 220/938] loss_G: 2.956663, loss_D: 0.195871\n",
            "[Epoch 161/200] [Batch 230/938] loss_G: 3.238842, loss_D: 0.270170\n",
            "[Epoch 161/200] [Batch 240/938] loss_G: 2.939844, loss_D: 0.223317\n",
            "[Epoch 161/200] [Batch 250/938] loss_G: 2.978855, loss_D: 0.214317\n",
            "[Epoch 161/200] [Batch 260/938] loss_G: 2.929132, loss_D: 0.176883\n",
            "[Epoch 161/200] [Batch 270/938] loss_G: 3.165470, loss_D: 0.233318\n",
            "[Epoch 161/200] [Batch 280/938] loss_G: 3.301605, loss_D: 0.181691\n",
            "[Epoch 161/200] [Batch 290/938] loss_G: 2.854315, loss_D: 0.203480\n",
            "[Epoch 161/200] [Batch 300/938] loss_G: 3.401005, loss_D: 0.176771\n",
            "[Epoch 161/200] [Batch 310/938] loss_G: 2.840061, loss_D: 0.177519\n",
            "[Epoch 161/200] [Batch 320/938] loss_G: 3.316970, loss_D: 0.192208\n",
            "[Epoch 161/200] [Batch 330/938] loss_G: 3.189163, loss_D: 0.164908\n",
            "[Epoch 161/200] [Batch 340/938] loss_G: 3.066670, loss_D: 0.251128\n",
            "[Epoch 161/200] [Batch 350/938] loss_G: 3.168222, loss_D: 0.177147\n",
            "[Epoch 161/200] [Batch 360/938] loss_G: 3.210445, loss_D: 0.285360\n",
            "[Epoch 161/200] [Batch 370/938] loss_G: 3.198208, loss_D: 0.201019\n",
            "[Epoch 161/200] [Batch 380/938] loss_G: 2.938027, loss_D: 0.254583\n",
            "[Epoch 161/200] [Batch 390/938] loss_G: 3.143322, loss_D: 0.206503\n",
            "[Epoch 161/200] [Batch 400/938] loss_G: 3.004694, loss_D: 0.215177\n",
            "[Epoch 161/200] [Batch 410/938] loss_G: 3.254207, loss_D: 0.231640\n",
            "[Epoch 161/200] [Batch 420/938] loss_G: 2.983632, loss_D: 0.209805\n",
            "[Epoch 161/200] [Batch 430/938] loss_G: 3.071564, loss_D: 0.224321\n",
            "[Epoch 161/200] [Batch 440/938] loss_G: 3.083728, loss_D: 0.214925\n",
            "[Epoch 161/200] [Batch 450/938] loss_G: 3.347230, loss_D: 0.145239\n",
            "[Epoch 161/200] [Batch 460/938] loss_G: 3.118854, loss_D: 0.176680\n",
            "[Epoch 161/200] [Batch 470/938] loss_G: 3.062134, loss_D: 0.236754\n",
            "[Epoch 161/200] [Batch 480/938] loss_G: 3.213233, loss_D: 0.248604\n",
            "[Epoch 161/200] [Batch 490/938] loss_G: 3.119584, loss_D: 0.202929\n",
            "[Epoch 161/200] [Batch 500/938] loss_G: 3.277761, loss_D: 0.219880\n",
            "[Epoch 161/200] [Batch 510/938] loss_G: 3.373846, loss_D: 0.143365\n",
            "[Epoch 161/200] [Batch 520/938] loss_G: 3.449722, loss_D: 0.219381\n",
            "[Epoch 161/200] [Batch 530/938] loss_G: 3.488470, loss_D: 0.201872\n",
            "[Epoch 161/200] [Batch 540/938] loss_G: 3.151055, loss_D: 0.238143\n",
            "[Epoch 161/200] [Batch 550/938] loss_G: 3.457696, loss_D: 0.157416\n",
            "[Epoch 161/200] [Batch 560/938] loss_G: 3.179038, loss_D: 0.174141\n",
            "[Epoch 161/200] [Batch 570/938] loss_G: 3.122884, loss_D: 0.216026\n",
            "[Epoch 161/200] [Batch 580/938] loss_G: 2.988129, loss_D: 0.165882\n",
            "[Epoch 161/200] [Batch 590/938] loss_G: 3.429000, loss_D: 0.178143\n",
            "[Epoch 161/200] [Batch 600/938] loss_G: 3.432829, loss_D: 0.255220\n",
            "[Epoch 161/200] [Batch 610/938] loss_G: 3.871611, loss_D: 0.144357\n",
            "[Epoch 161/200] [Batch 620/938] loss_G: 2.955998, loss_D: 0.217710\n",
            "[Epoch 161/200] [Batch 630/938] loss_G: 2.957017, loss_D: 0.134950\n",
            "[Epoch 161/200] [Batch 640/938] loss_G: 3.072677, loss_D: 0.165589\n",
            "[Epoch 161/200] [Batch 650/938] loss_G: 2.777250, loss_D: 0.184288\n",
            "[Epoch 161/200] [Batch 660/938] loss_G: 3.657860, loss_D: 0.190724\n",
            "[Epoch 161/200] [Batch 670/938] loss_G: 3.241066, loss_D: 0.261503\n",
            "[Epoch 161/200] [Batch 680/938] loss_G: 2.866684, loss_D: 0.246551\n",
            "[Epoch 161/200] [Batch 690/938] loss_G: 3.190834, loss_D: 0.248827\n",
            "[Epoch 161/200] [Batch 700/938] loss_G: 3.042227, loss_D: 0.212299\n",
            "[Epoch 161/200] [Batch 710/938] loss_G: 3.476155, loss_D: 0.212635\n",
            "[Epoch 161/200] [Batch 720/938] loss_G: 3.094318, loss_D: 0.234942\n",
            "[Epoch 161/200] [Batch 730/938] loss_G: 3.180509, loss_D: 0.259996\n",
            "[Epoch 161/200] [Batch 740/938] loss_G: 3.023434, loss_D: 0.258529\n",
            "[Epoch 161/200] [Batch 750/938] loss_G: 3.123079, loss_D: 0.201939\n",
            "[Epoch 161/200] [Batch 760/938] loss_G: 3.173310, loss_D: 0.303825\n",
            "[Epoch 161/200] [Batch 770/938] loss_G: 3.460906, loss_D: 0.320196\n",
            "[Epoch 161/200] [Batch 780/938] loss_G: 3.012966, loss_D: 0.217044\n",
            "[Epoch 161/200] [Batch 790/938] loss_G: 3.116052, loss_D: 0.255762\n",
            "[Epoch 161/200] [Batch 800/938] loss_G: 2.929282, loss_D: 0.196388\n",
            "[Epoch 161/200] [Batch 810/938] loss_G: 3.051112, loss_D: 0.222446\n",
            "[Epoch 161/200] [Batch 820/938] loss_G: 3.434079, loss_D: 0.227620\n",
            "[Epoch 161/200] [Batch 830/938] loss_G: 2.805862, loss_D: 0.231142\n",
            "[Epoch 161/200] [Batch 840/938] loss_G: 3.330375, loss_D: 0.149630\n",
            "[Epoch 161/200] [Batch 850/938] loss_G: 3.154183, loss_D: 0.192121\n",
            "[Epoch 161/200] [Batch 860/938] loss_G: 2.962966, loss_D: 0.264983\n",
            "[Epoch 161/200] [Batch 870/938] loss_G: 3.384971, loss_D: 0.138400\n",
            "[Epoch 161/200] [Batch 880/938] loss_G: 3.424977, loss_D: 0.175672\n",
            "[Epoch 161/200] [Batch 890/938] loss_G: 3.318551, loss_D: 0.143222\n",
            "[Epoch 161/200] [Batch 900/938] loss_G: 3.399467, loss_D: 0.172547\n",
            "[Epoch 161/200] [Batch 910/938] loss_G: 2.827989, loss_D: 0.241668\n",
            "[Epoch 161/200] [Batch 920/938] loss_G: 3.187514, loss_D: 0.134464\n",
            "[Epoch 161/200] [Batch 930/938] loss_G: 2.814397, loss_D: 0.348103\n",
            "[Epoch 162/200] [Batch 0/938] loss_G: 2.831446, loss_D: 0.266319\n",
            "[Epoch 162/200] [Batch 10/938] loss_G: 3.157686, loss_D: 0.202747\n",
            "[Epoch 162/200] [Batch 20/938] loss_G: 3.106789, loss_D: 0.183910\n",
            "[Epoch 162/200] [Batch 30/938] loss_G: 3.093865, loss_D: 0.200055\n",
            "[Epoch 162/200] [Batch 40/938] loss_G: 3.150651, loss_D: 0.255733\n",
            "[Epoch 162/200] [Batch 50/938] loss_G: 3.253942, loss_D: 0.175578\n",
            "[Epoch 162/200] [Batch 60/938] loss_G: 3.324286, loss_D: 0.112877\n",
            "[Epoch 162/200] [Batch 70/938] loss_G: 2.952305, loss_D: 0.253486\n",
            "[Epoch 162/200] [Batch 80/938] loss_G: 3.423188, loss_D: 0.249450\n",
            "[Epoch 162/200] [Batch 90/938] loss_G: 2.769209, loss_D: 0.225202\n",
            "[Epoch 162/200] [Batch 100/938] loss_G: 3.340546, loss_D: 0.100340\n",
            "[Epoch 162/200] [Batch 110/938] loss_G: 3.334074, loss_D: 0.253212\n",
            "[Epoch 162/200] [Batch 120/938] loss_G: 3.007818, loss_D: 0.151086\n",
            "[Epoch 162/200] [Batch 130/938] loss_G: 3.099381, loss_D: 0.157004\n",
            "[Epoch 162/200] [Batch 140/938] loss_G: 3.287745, loss_D: 0.116582\n",
            "[Epoch 162/200] [Batch 150/938] loss_G: 3.312975, loss_D: 0.205603\n",
            "[Epoch 162/200] [Batch 160/938] loss_G: 3.036443, loss_D: 0.187501\n",
            "[Epoch 162/200] [Batch 170/938] loss_G: 2.638639, loss_D: 0.304049\n",
            "[Epoch 162/200] [Batch 180/938] loss_G: 3.094582, loss_D: 0.132595\n",
            "[Epoch 162/200] [Batch 190/938] loss_G: 2.963270, loss_D: 0.149168\n",
            "[Epoch 162/200] [Batch 200/938] loss_G: 2.593152, loss_D: 0.203026\n",
            "[Epoch 162/200] [Batch 210/938] loss_G: 2.637568, loss_D: 0.232664\n",
            "[Epoch 162/200] [Batch 220/938] loss_G: 3.243458, loss_D: 0.174242\n",
            "[Epoch 162/200] [Batch 230/938] loss_G: 3.355110, loss_D: 0.171027\n",
            "[Epoch 162/200] [Batch 240/938] loss_G: 3.246107, loss_D: 0.187515\n",
            "[Epoch 162/200] [Batch 250/938] loss_G: 3.377261, loss_D: 0.163285\n",
            "[Epoch 162/200] [Batch 260/938] loss_G: 3.139220, loss_D: 0.302238\n",
            "[Epoch 162/200] [Batch 270/938] loss_G: 2.923948, loss_D: 0.218512\n",
            "[Epoch 162/200] [Batch 280/938] loss_G: 2.651875, loss_D: 0.154733\n",
            "[Epoch 162/200] [Batch 290/938] loss_G: 2.758037, loss_D: 0.226496\n",
            "[Epoch 162/200] [Batch 300/938] loss_G: 2.950673, loss_D: 0.233692\n",
            "[Epoch 162/200] [Batch 310/938] loss_G: 2.779646, loss_D: 0.184761\n",
            "[Epoch 162/200] [Batch 320/938] loss_G: 3.164446, loss_D: 0.258138\n",
            "[Epoch 162/200] [Batch 330/938] loss_G: 3.223166, loss_D: 0.163449\n",
            "[Epoch 162/200] [Batch 340/938] loss_G: 2.888058, loss_D: 0.259007\n",
            "[Epoch 162/200] [Batch 350/938] loss_G: 2.827687, loss_D: 0.232412\n",
            "[Epoch 162/200] [Batch 360/938] loss_G: 3.242821, loss_D: 0.311627\n",
            "[Epoch 162/200] [Batch 370/938] loss_G: 3.139705, loss_D: 0.225037\n",
            "[Epoch 162/200] [Batch 380/938] loss_G: 3.450512, loss_D: 0.153308\n",
            "[Epoch 162/200] [Batch 390/938] loss_G: 2.835878, loss_D: 0.250476\n",
            "[Epoch 162/200] [Batch 400/938] loss_G: 3.175599, loss_D: 0.218198\n",
            "[Epoch 162/200] [Batch 410/938] loss_G: 3.575972, loss_D: 0.150164\n",
            "[Epoch 162/200] [Batch 420/938] loss_G: 3.416583, loss_D: 0.197144\n",
            "[Epoch 162/200] [Batch 430/938] loss_G: 2.962312, loss_D: 0.239278\n",
            "[Epoch 162/200] [Batch 440/938] loss_G: 3.076174, loss_D: 0.136189\n",
            "[Epoch 162/200] [Batch 450/938] loss_G: 2.860527, loss_D: 0.205428\n",
            "[Epoch 162/200] [Batch 460/938] loss_G: 3.030469, loss_D: 0.230346\n",
            "[Epoch 162/200] [Batch 470/938] loss_G: 3.167022, loss_D: 0.233698\n",
            "[Epoch 162/200] [Batch 480/938] loss_G: 3.493584, loss_D: 0.160454\n",
            "[Epoch 162/200] [Batch 490/938] loss_G: 3.332299, loss_D: 0.225706\n",
            "[Epoch 162/200] [Batch 500/938] loss_G: 3.176271, loss_D: 0.176793\n",
            "[Epoch 162/200] [Batch 510/938] loss_G: 3.388930, loss_D: 0.127646\n",
            "[Epoch 162/200] [Batch 520/938] loss_G: 3.449103, loss_D: 0.250854\n",
            "[Epoch 162/200] [Batch 530/938] loss_G: 3.375340, loss_D: 0.242731\n",
            "[Epoch 162/200] [Batch 540/938] loss_G: 3.406187, loss_D: 0.221350\n",
            "[Epoch 162/200] [Batch 550/938] loss_G: 3.363345, loss_D: 0.190507\n",
            "[Epoch 162/200] [Batch 560/938] loss_G: 3.578145, loss_D: 0.125072\n",
            "[Epoch 162/200] [Batch 570/938] loss_G: 3.184916, loss_D: 0.271554\n",
            "[Epoch 162/200] [Batch 580/938] loss_G: 3.125924, loss_D: 0.280969\n",
            "[Epoch 162/200] [Batch 590/938] loss_G: 2.993963, loss_D: 0.154411\n",
            "[Epoch 162/200] [Batch 600/938] loss_G: 3.403788, loss_D: 0.195183\n",
            "[Epoch 162/200] [Batch 610/938] loss_G: 3.202748, loss_D: 0.160493\n",
            "[Epoch 162/200] [Batch 620/938] loss_G: 2.949976, loss_D: 0.244538\n",
            "[Epoch 162/200] [Batch 630/938] loss_G: 3.031063, loss_D: 0.157905\n",
            "[Epoch 162/200] [Batch 640/938] loss_G: 3.222349, loss_D: 0.163651\n",
            "[Epoch 162/200] [Batch 650/938] loss_G: 2.846375, loss_D: 0.235119\n",
            "[Epoch 162/200] [Batch 660/938] loss_G: 2.829005, loss_D: 0.189403\n",
            "[Epoch 162/200] [Batch 670/938] loss_G: 3.159696, loss_D: 0.138861\n",
            "[Epoch 162/200] [Batch 680/938] loss_G: 3.096380, loss_D: 0.173923\n",
            "[Epoch 162/200] [Batch 690/938] loss_G: 2.891387, loss_D: 0.195980\n",
            "[Epoch 162/200] [Batch 700/938] loss_G: 3.072595, loss_D: 0.179294\n",
            "[Epoch 162/200] [Batch 710/938] loss_G: 3.245144, loss_D: 0.175504\n",
            "[Epoch 162/200] [Batch 720/938] loss_G: 2.905143, loss_D: 0.135650\n",
            "[Epoch 162/200] [Batch 730/938] loss_G: 2.995347, loss_D: 0.218760\n",
            "[Epoch 162/200] [Batch 740/938] loss_G: 3.184649, loss_D: 0.203514\n",
            "[Epoch 162/200] [Batch 750/938] loss_G: 3.134764, loss_D: 0.142188\n",
            "[Epoch 162/200] [Batch 760/938] loss_G: 2.984766, loss_D: 0.125190\n",
            "[Epoch 162/200] [Batch 770/938] loss_G: 3.005442, loss_D: 0.239495\n",
            "[Epoch 162/200] [Batch 780/938] loss_G: 3.316504, loss_D: 0.212058\n",
            "[Epoch 162/200] [Batch 790/938] loss_G: 3.162907, loss_D: 0.315365\n",
            "[Epoch 162/200] [Batch 800/938] loss_G: 2.798062, loss_D: 0.301880\n",
            "[Epoch 162/200] [Batch 810/938] loss_G: 2.861882, loss_D: 0.253128\n",
            "[Epoch 162/200] [Batch 820/938] loss_G: 3.161896, loss_D: 0.240991\n",
            "[Epoch 162/200] [Batch 830/938] loss_G: 2.861423, loss_D: 0.253394\n",
            "[Epoch 162/200] [Batch 840/938] loss_G: 3.062349, loss_D: 0.216893\n",
            "[Epoch 162/200] [Batch 850/938] loss_G: 3.145375, loss_D: 0.255580\n",
            "[Epoch 162/200] [Batch 860/938] loss_G: 3.336570, loss_D: 0.253654\n",
            "[Epoch 162/200] [Batch 870/938] loss_G: 2.903970, loss_D: 0.171167\n",
            "[Epoch 162/200] [Batch 880/938] loss_G: 3.098699, loss_D: 0.257167\n",
            "[Epoch 162/200] [Batch 890/938] loss_G: 3.053645, loss_D: 0.153370\n",
            "[Epoch 162/200] [Batch 900/938] loss_G: 2.884014, loss_D: 0.287290\n",
            "[Epoch 162/200] [Batch 910/938] loss_G: 2.927778, loss_D: 0.181092\n",
            "[Epoch 162/200] [Batch 920/938] loss_G: 3.335191, loss_D: 0.130674\n",
            "[Epoch 162/200] [Batch 930/938] loss_G: 3.307924, loss_D: 0.187842\n",
            "[Epoch 163/200] [Batch 0/938] loss_G: 3.150600, loss_D: 0.150303\n",
            "[Epoch 163/200] [Batch 10/938] loss_G: 3.176117, loss_D: 0.218914\n",
            "[Epoch 163/200] [Batch 20/938] loss_G: 3.147710, loss_D: 0.219738\n",
            "[Epoch 163/200] [Batch 30/938] loss_G: 3.231695, loss_D: 0.137428\n",
            "[Epoch 163/200] [Batch 40/938] loss_G: 3.255511, loss_D: 0.105883\n",
            "[Epoch 163/200] [Batch 50/938] loss_G: 3.516193, loss_D: 0.137116\n",
            "[Epoch 163/200] [Batch 60/938] loss_G: 2.965587, loss_D: 0.159807\n",
            "[Epoch 163/200] [Batch 70/938] loss_G: 3.207441, loss_D: 0.295244\n",
            "[Epoch 163/200] [Batch 80/938] loss_G: 3.258664, loss_D: 0.209811\n",
            "[Epoch 163/200] [Batch 90/938] loss_G: 2.867654, loss_D: 0.223493\n",
            "[Epoch 163/200] [Batch 100/938] loss_G: 3.338986, loss_D: 0.227018\n",
            "[Epoch 163/200] [Batch 110/938] loss_G: 3.180096, loss_D: 0.169952\n",
            "[Epoch 163/200] [Batch 120/938] loss_G: 3.408803, loss_D: 0.133493\n",
            "[Epoch 163/200] [Batch 130/938] loss_G: 2.979767, loss_D: 0.199295\n",
            "[Epoch 163/200] [Batch 140/938] loss_G: 3.259271, loss_D: 0.178333\n",
            "[Epoch 163/200] [Batch 150/938] loss_G: 3.012958, loss_D: 0.229543\n",
            "[Epoch 163/200] [Batch 160/938] loss_G: 3.346102, loss_D: 0.236463\n",
            "[Epoch 163/200] [Batch 170/938] loss_G: 2.669555, loss_D: 0.229063\n",
            "[Epoch 163/200] [Batch 180/938] loss_G: 2.958019, loss_D: 0.165865\n",
            "[Epoch 163/200] [Batch 190/938] loss_G: 2.937813, loss_D: 0.151659\n",
            "[Epoch 163/200] [Batch 200/938] loss_G: 3.488542, loss_D: 0.132982\n",
            "[Epoch 163/200] [Batch 210/938] loss_G: 3.082843, loss_D: 0.124501\n",
            "[Epoch 163/200] [Batch 220/938] loss_G: 3.016684, loss_D: 0.161653\n",
            "[Epoch 163/200] [Batch 230/938] loss_G: 2.994457, loss_D: 0.225523\n",
            "[Epoch 163/200] [Batch 240/938] loss_G: 3.125065, loss_D: 0.152558\n",
            "[Epoch 163/200] [Batch 250/938] loss_G: 3.219392, loss_D: 0.242551\n",
            "[Epoch 163/200] [Batch 260/938] loss_G: 3.206462, loss_D: 0.234524\n",
            "[Epoch 163/200] [Batch 270/938] loss_G: 3.328691, loss_D: 0.175325\n",
            "[Epoch 163/200] [Batch 280/938] loss_G: 2.988700, loss_D: 0.371702\n",
            "[Epoch 163/200] [Batch 290/938] loss_G: 2.627872, loss_D: 0.210108\n",
            "[Epoch 163/200] [Batch 300/938] loss_G: 3.359323, loss_D: 0.180238\n",
            "[Epoch 163/200] [Batch 310/938] loss_G: 2.920353, loss_D: 0.232175\n",
            "[Epoch 163/200] [Batch 320/938] loss_G: 3.433151, loss_D: 0.144998\n",
            "[Epoch 163/200] [Batch 330/938] loss_G: 3.506102, loss_D: 0.133750\n",
            "[Epoch 163/200] [Batch 340/938] loss_G: 3.163836, loss_D: 0.166741\n",
            "[Epoch 163/200] [Batch 350/938] loss_G: 3.385264, loss_D: 0.139748\n",
            "[Epoch 163/200] [Batch 360/938] loss_G: 3.094550, loss_D: 0.273610\n",
            "[Epoch 163/200] [Batch 370/938] loss_G: 3.068832, loss_D: 0.221401\n",
            "[Epoch 163/200] [Batch 380/938] loss_G: 3.129086, loss_D: 0.169081\n",
            "[Epoch 163/200] [Batch 390/938] loss_G: 3.283219, loss_D: 0.198769\n",
            "[Epoch 163/200] [Batch 400/938] loss_G: 3.208579, loss_D: 0.143301\n",
            "[Epoch 163/200] [Batch 410/938] loss_G: 3.356873, loss_D: 0.165958\n",
            "[Epoch 163/200] [Batch 420/938] loss_G: 3.052627, loss_D: 0.260541\n",
            "[Epoch 163/200] [Batch 430/938] loss_G: 3.540621, loss_D: 0.218934\n",
            "[Epoch 163/200] [Batch 440/938] loss_G: 3.323420, loss_D: 0.248999\n",
            "[Epoch 163/200] [Batch 450/938] loss_G: 3.266016, loss_D: 0.281117\n",
            "[Epoch 163/200] [Batch 460/938] loss_G: 2.746641, loss_D: 0.283468\n",
            "[Epoch 163/200] [Batch 470/938] loss_G: 3.348178, loss_D: 0.237374\n",
            "[Epoch 163/200] [Batch 480/938] loss_G: 3.034943, loss_D: 0.251791\n",
            "[Epoch 163/200] [Batch 490/938] loss_G: 3.077536, loss_D: 0.173340\n",
            "[Epoch 163/200] [Batch 500/938] loss_G: 3.423987, loss_D: 0.255174\n",
            "[Epoch 163/200] [Batch 510/938] loss_G: 2.789986, loss_D: 0.196684\n",
            "[Epoch 163/200] [Batch 520/938] loss_G: 3.331809, loss_D: 0.184567\n",
            "[Epoch 163/200] [Batch 530/938] loss_G: 3.361901, loss_D: 0.243995\n",
            "[Epoch 163/200] [Batch 540/938] loss_G: 3.531393, loss_D: 0.186224\n",
            "[Epoch 163/200] [Batch 550/938] loss_G: 3.342013, loss_D: 0.188152\n",
            "[Epoch 163/200] [Batch 560/938] loss_G: 2.927833, loss_D: 0.174902\n",
            "[Epoch 163/200] [Batch 570/938] loss_G: 3.038118, loss_D: 0.182497\n",
            "[Epoch 163/200] [Batch 580/938] loss_G: 2.940721, loss_D: 0.219023\n",
            "[Epoch 163/200] [Batch 590/938] loss_G: 3.125448, loss_D: 0.204183\n",
            "[Epoch 163/200] [Batch 600/938] loss_G: 3.313053, loss_D: 0.221536\n",
            "[Epoch 163/200] [Batch 610/938] loss_G: 3.221944, loss_D: 0.254284\n",
            "[Epoch 163/200] [Batch 620/938] loss_G: 3.116652, loss_D: 0.202265\n",
            "[Epoch 163/200] [Batch 630/938] loss_G: 3.298785, loss_D: 0.185094\n",
            "[Epoch 163/200] [Batch 640/938] loss_G: 3.189903, loss_D: 0.246763\n",
            "[Epoch 163/200] [Batch 650/938] loss_G: 3.048982, loss_D: 0.230001\n",
            "[Epoch 163/200] [Batch 660/938] loss_G: 2.912915, loss_D: 0.283014\n",
            "[Epoch 163/200] [Batch 670/938] loss_G: 2.917848, loss_D: 0.278728\n",
            "[Epoch 163/200] [Batch 680/938] loss_G: 3.028259, loss_D: 0.224057\n",
            "[Epoch 163/200] [Batch 690/938] loss_G: 3.420005, loss_D: 0.127473\n",
            "[Epoch 163/200] [Batch 700/938] loss_G: 3.206309, loss_D: 0.259700\n",
            "[Epoch 163/200] [Batch 710/938] loss_G: 2.788540, loss_D: 0.163769\n",
            "[Epoch 163/200] [Batch 720/938] loss_G: 3.154094, loss_D: 0.225943\n",
            "[Epoch 163/200] [Batch 730/938] loss_G: 3.779439, loss_D: 0.189879\n",
            "[Epoch 163/200] [Batch 740/938] loss_G: 3.045210, loss_D: 0.266934\n",
            "[Epoch 163/200] [Batch 750/938] loss_G: 3.550437, loss_D: 0.155085\n",
            "[Epoch 163/200] [Batch 760/938] loss_G: 2.976213, loss_D: 0.210722\n",
            "[Epoch 163/200] [Batch 770/938] loss_G: 3.180267, loss_D: 0.182992\n",
            "[Epoch 163/200] [Batch 780/938] loss_G: 2.866974, loss_D: 0.240486\n",
            "[Epoch 163/200] [Batch 790/938] loss_G: 3.135724, loss_D: 0.200189\n",
            "[Epoch 163/200] [Batch 800/938] loss_G: 3.198479, loss_D: 0.195102\n",
            "[Epoch 163/200] [Batch 810/938] loss_G: 2.815757, loss_D: 0.252680\n",
            "[Epoch 163/200] [Batch 820/938] loss_G: 2.951205, loss_D: 0.178799\n",
            "[Epoch 163/200] [Batch 830/938] loss_G: 3.220456, loss_D: 0.218497\n",
            "[Epoch 163/200] [Batch 840/938] loss_G: 3.023440, loss_D: 0.202226\n",
            "[Epoch 163/200] [Batch 850/938] loss_G: 3.123486, loss_D: 0.157835\n",
            "[Epoch 163/200] [Batch 860/938] loss_G: 2.894844, loss_D: 0.242512\n",
            "[Epoch 163/200] [Batch 870/938] loss_G: 3.210205, loss_D: 0.260355\n",
            "[Epoch 163/200] [Batch 880/938] loss_G: 3.086367, loss_D: 0.180691\n",
            "[Epoch 163/200] [Batch 890/938] loss_G: 3.052218, loss_D: 0.163159\n",
            "[Epoch 163/200] [Batch 900/938] loss_G: 3.270718, loss_D: 0.174416\n",
            "[Epoch 163/200] [Batch 910/938] loss_G: 2.741484, loss_D: 0.217399\n",
            "[Epoch 163/200] [Batch 920/938] loss_G: 3.202669, loss_D: 0.261001\n",
            "[Epoch 163/200] [Batch 930/938] loss_G: 3.022728, loss_D: 0.164253\n",
            "[Epoch 164/200] [Batch 0/938] loss_G: 3.136935, loss_D: 0.146138\n",
            "[Epoch 164/200] [Batch 10/938] loss_G: 2.856244, loss_D: 0.168362\n",
            "[Epoch 164/200] [Batch 20/938] loss_G: 3.072766, loss_D: 0.184069\n",
            "[Epoch 164/200] [Batch 30/938] loss_G: 2.658488, loss_D: 0.206246\n",
            "[Epoch 164/200] [Batch 40/938] loss_G: 2.994602, loss_D: 0.194920\n",
            "[Epoch 164/200] [Batch 50/938] loss_G: 3.196251, loss_D: 0.273892\n",
            "[Epoch 164/200] [Batch 60/938] loss_G: 3.222692, loss_D: 0.233004\n",
            "[Epoch 164/200] [Batch 70/938] loss_G: 3.406459, loss_D: 0.136276\n",
            "[Epoch 164/200] [Batch 80/938] loss_G: 3.105412, loss_D: 0.188915\n",
            "[Epoch 164/200] [Batch 90/938] loss_G: 3.172830, loss_D: 0.190154\n",
            "[Epoch 164/200] [Batch 100/938] loss_G: 3.266143, loss_D: 0.211527\n",
            "[Epoch 164/200] [Batch 110/938] loss_G: 3.231286, loss_D: 0.170769\n",
            "[Epoch 164/200] [Batch 120/938] loss_G: 2.882689, loss_D: 0.247865\n",
            "[Epoch 164/200] [Batch 130/938] loss_G: 2.827314, loss_D: 0.224435\n",
            "[Epoch 164/200] [Batch 140/938] loss_G: 3.246593, loss_D: 0.112436\n",
            "[Epoch 164/200] [Batch 150/938] loss_G: 3.125881, loss_D: 0.233727\n",
            "[Epoch 164/200] [Batch 160/938] loss_G: 2.972939, loss_D: 0.256905\n",
            "[Epoch 164/200] [Batch 170/938] loss_G: 3.244143, loss_D: 0.212856\n",
            "[Epoch 164/200] [Batch 180/938] loss_G: 3.520077, loss_D: 0.142541\n",
            "[Epoch 164/200] [Batch 190/938] loss_G: 3.694177, loss_D: 0.109443\n",
            "[Epoch 164/200] [Batch 200/938] loss_G: 3.555044, loss_D: 0.240806\n",
            "[Epoch 164/200] [Batch 210/938] loss_G: 2.908836, loss_D: 0.215634\n",
            "[Epoch 164/200] [Batch 220/938] loss_G: 3.106544, loss_D: 0.138230\n",
            "[Epoch 164/200] [Batch 230/938] loss_G: 3.303035, loss_D: 0.217604\n",
            "[Epoch 164/200] [Batch 240/938] loss_G: 2.989081, loss_D: 0.113083\n",
            "[Epoch 164/200] [Batch 250/938] loss_G: 3.203799, loss_D: 0.231796\n",
            "[Epoch 164/200] [Batch 260/938] loss_G: 3.269791, loss_D: 0.172076\n",
            "[Epoch 164/200] [Batch 270/938] loss_G: 2.709732, loss_D: 0.196442\n",
            "[Epoch 164/200] [Batch 280/938] loss_G: 3.230064, loss_D: 0.241345\n",
            "[Epoch 164/200] [Batch 290/938] loss_G: 3.540563, loss_D: 0.289583\n",
            "[Epoch 164/200] [Batch 300/938] loss_G: 3.015430, loss_D: 0.210868\n",
            "[Epoch 164/200] [Batch 310/938] loss_G: 2.919507, loss_D: 0.185252\n",
            "[Epoch 164/200] [Batch 320/938] loss_G: 3.290011, loss_D: 0.292203\n",
            "[Epoch 164/200] [Batch 330/938] loss_G: 3.350643, loss_D: 0.168104\n",
            "[Epoch 164/200] [Batch 340/938] loss_G: 3.421960, loss_D: 0.241494\n",
            "[Epoch 164/200] [Batch 350/938] loss_G: 3.420721, loss_D: 0.193683\n",
            "[Epoch 164/200] [Batch 360/938] loss_G: 3.114093, loss_D: 0.164326\n",
            "[Epoch 164/200] [Batch 370/938] loss_G: 3.331911, loss_D: 0.184460\n",
            "[Epoch 164/200] [Batch 380/938] loss_G: 3.005588, loss_D: 0.173016\n",
            "[Epoch 164/200] [Batch 390/938] loss_G: 3.038676, loss_D: 0.169985\n",
            "[Epoch 164/200] [Batch 400/938] loss_G: 3.272353, loss_D: 0.110921\n",
            "[Epoch 164/200] [Batch 410/938] loss_G: 3.171431, loss_D: 0.178111\n",
            "[Epoch 164/200] [Batch 420/938] loss_G: 3.328918, loss_D: 0.173111\n",
            "[Epoch 164/200] [Batch 430/938] loss_G: 3.046825, loss_D: 0.185966\n",
            "[Epoch 164/200] [Batch 440/938] loss_G: 3.069955, loss_D: 0.161101\n",
            "[Epoch 164/200] [Batch 450/938] loss_G: 3.154715, loss_D: 0.133298\n",
            "[Epoch 164/200] [Batch 460/938] loss_G: 2.870692, loss_D: 0.141829\n",
            "[Epoch 164/200] [Batch 470/938] loss_G: 3.054875, loss_D: 0.233924\n",
            "[Epoch 164/200] [Batch 480/938] loss_G: 3.177749, loss_D: 0.305829\n",
            "[Epoch 164/200] [Batch 490/938] loss_G: 3.113983, loss_D: 0.198005\n",
            "[Epoch 164/200] [Batch 500/938] loss_G: 3.184063, loss_D: 0.157945\n",
            "[Epoch 164/200] [Batch 510/938] loss_G: 3.354303, loss_D: 0.265186\n",
            "[Epoch 164/200] [Batch 520/938] loss_G: 3.181616, loss_D: 0.184849\n",
            "[Epoch 164/200] [Batch 530/938] loss_G: 3.141902, loss_D: 0.169468\n",
            "[Epoch 164/200] [Batch 540/938] loss_G: 3.238002, loss_D: 0.263638\n",
            "[Epoch 164/200] [Batch 550/938] loss_G: 3.322453, loss_D: 0.206431\n",
            "[Epoch 164/200] [Batch 560/938] loss_G: 3.346234, loss_D: 0.148056\n",
            "[Epoch 164/200] [Batch 570/938] loss_G: 3.370119, loss_D: 0.251406\n",
            "[Epoch 164/200] [Batch 580/938] loss_G: 3.256316, loss_D: 0.114534\n",
            "[Epoch 164/200] [Batch 590/938] loss_G: 3.227717, loss_D: 0.191109\n",
            "[Epoch 164/200] [Batch 600/938] loss_G: 3.066034, loss_D: 0.163461\n",
            "[Epoch 164/200] [Batch 610/938] loss_G: 3.056063, loss_D: 0.242777\n",
            "[Epoch 164/200] [Batch 620/938] loss_G: 3.202506, loss_D: 0.171001\n",
            "[Epoch 164/200] [Batch 630/938] loss_G: 3.014143, loss_D: 0.170745\n",
            "[Epoch 164/200] [Batch 640/938] loss_G: 3.062886, loss_D: 0.185797\n",
            "[Epoch 164/200] [Batch 650/938] loss_G: 3.318961, loss_D: 0.167448\n",
            "[Epoch 164/200] [Batch 660/938] loss_G: 3.312287, loss_D: 0.283032\n",
            "[Epoch 164/200] [Batch 670/938] loss_G: 2.762731, loss_D: 0.133473\n",
            "[Epoch 164/200] [Batch 680/938] loss_G: 3.315412, loss_D: 0.246102\n",
            "[Epoch 164/200] [Batch 690/938] loss_G: 3.369784, loss_D: 0.137908\n",
            "[Epoch 164/200] [Batch 700/938] loss_G: 3.283225, loss_D: 0.141995\n",
            "[Epoch 164/200] [Batch 710/938] loss_G: 3.498661, loss_D: 0.226873\n",
            "[Epoch 164/200] [Batch 720/938] loss_G: 3.121762, loss_D: 0.097694\n",
            "[Epoch 164/200] [Batch 730/938] loss_G: 3.109332, loss_D: 0.172638\n",
            "[Epoch 164/200] [Batch 740/938] loss_G: 3.353932, loss_D: 0.136103\n",
            "[Epoch 164/200] [Batch 750/938] loss_G: 2.992229, loss_D: 0.215616\n",
            "[Epoch 164/200] [Batch 760/938] loss_G: 3.159968, loss_D: 0.195070\n",
            "[Epoch 164/200] [Batch 770/938] loss_G: 3.266644, loss_D: 0.133448\n",
            "[Epoch 164/200] [Batch 780/938] loss_G: 3.096153, loss_D: 0.226580\n",
            "[Epoch 164/200] [Batch 790/938] loss_G: 3.225803, loss_D: 0.209857\n",
            "[Epoch 164/200] [Batch 800/938] loss_G: 3.294388, loss_D: 0.159197\n",
            "[Epoch 164/200] [Batch 810/938] loss_G: 3.136423, loss_D: 0.308496\n",
            "[Epoch 164/200] [Batch 820/938] loss_G: 2.787909, loss_D: 0.259455\n",
            "[Epoch 164/200] [Batch 830/938] loss_G: 3.131117, loss_D: 0.248324\n",
            "[Epoch 164/200] [Batch 840/938] loss_G: 3.090735, loss_D: 0.246648\n",
            "[Epoch 164/200] [Batch 850/938] loss_G: 3.133925, loss_D: 0.163404\n",
            "[Epoch 164/200] [Batch 860/938] loss_G: 2.949916, loss_D: 0.218124\n",
            "[Epoch 164/200] [Batch 870/938] loss_G: 2.840730, loss_D: 0.196498\n",
            "[Epoch 164/200] [Batch 880/938] loss_G: 3.247895, loss_D: 0.235562\n",
            "[Epoch 164/200] [Batch 890/938] loss_G: 3.133337, loss_D: 0.119074\n",
            "[Epoch 164/200] [Batch 900/938] loss_G: 3.257536, loss_D: 0.189974\n",
            "[Epoch 164/200] [Batch 910/938] loss_G: 3.177580, loss_D: 0.245924\n",
            "[Epoch 164/200] [Batch 920/938] loss_G: 2.696832, loss_D: 0.305676\n",
            "[Epoch 164/200] [Batch 930/938] loss_G: 2.982560, loss_D: 0.165274\n",
            "[Epoch 165/200] [Batch 0/938] loss_G: 3.040363, loss_D: 0.259644\n",
            "[Epoch 165/200] [Batch 10/938] loss_G: 2.744366, loss_D: 0.263889\n",
            "[Epoch 165/200] [Batch 20/938] loss_G: 2.769756, loss_D: 0.178794\n",
            "[Epoch 165/200] [Batch 30/938] loss_G: 3.176542, loss_D: 0.150156\n",
            "[Epoch 165/200] [Batch 40/938] loss_G: 2.961248, loss_D: 0.163770\n",
            "[Epoch 165/200] [Batch 50/938] loss_G: 2.886951, loss_D: 0.177147\n",
            "[Epoch 165/200] [Batch 60/938] loss_G: 2.957105, loss_D: 0.173564\n",
            "[Epoch 165/200] [Batch 70/938] loss_G: 3.120107, loss_D: 0.248552\n",
            "[Epoch 165/200] [Batch 80/938] loss_G: 3.059056, loss_D: 0.140800\n",
            "[Epoch 165/200] [Batch 90/938] loss_G: 3.127138, loss_D: 0.277821\n",
            "[Epoch 165/200] [Batch 100/938] loss_G: 2.894205, loss_D: 0.179608\n",
            "[Epoch 165/200] [Batch 110/938] loss_G: 3.133660, loss_D: 0.145713\n",
            "[Epoch 165/200] [Batch 120/938] loss_G: 3.460958, loss_D: 0.186116\n",
            "[Epoch 165/200] [Batch 130/938] loss_G: 3.132559, loss_D: 0.196558\n",
            "[Epoch 165/200] [Batch 140/938] loss_G: 3.036484, loss_D: 0.216326\n",
            "[Epoch 165/200] [Batch 150/938] loss_G: 3.248186, loss_D: 0.169526\n",
            "[Epoch 165/200] [Batch 160/938] loss_G: 3.112620, loss_D: 0.262974\n",
            "[Epoch 165/200] [Batch 170/938] loss_G: 3.395349, loss_D: 0.176972\n",
            "[Epoch 165/200] [Batch 180/938] loss_G: 3.246987, loss_D: 0.259714\n",
            "[Epoch 165/200] [Batch 190/938] loss_G: 3.009135, loss_D: 0.298338\n",
            "[Epoch 165/200] [Batch 200/938] loss_G: 2.787287, loss_D: 0.268907\n",
            "[Epoch 165/200] [Batch 210/938] loss_G: 2.838674, loss_D: 0.335190\n",
            "[Epoch 165/200] [Batch 220/938] loss_G: 3.065494, loss_D: 0.238152\n",
            "[Epoch 165/200] [Batch 230/938] loss_G: 3.339102, loss_D: 0.098662\n",
            "[Epoch 165/200] [Batch 240/938] loss_G: 3.110627, loss_D: 0.134651\n",
            "[Epoch 165/200] [Batch 250/938] loss_G: 3.060821, loss_D: 0.196733\n",
            "[Epoch 165/200] [Batch 260/938] loss_G: 3.146449, loss_D: 0.169022\n",
            "[Epoch 165/200] [Batch 270/938] loss_G: 2.845313, loss_D: 0.265368\n",
            "[Epoch 165/200] [Batch 280/938] loss_G: 3.322552, loss_D: 0.162921\n",
            "[Epoch 165/200] [Batch 290/938] loss_G: 3.254509, loss_D: 0.165850\n",
            "[Epoch 165/200] [Batch 300/938] loss_G: 2.980545, loss_D: 0.255571\n",
            "[Epoch 165/200] [Batch 310/938] loss_G: 3.184415, loss_D: 0.108362\n",
            "[Epoch 165/200] [Batch 320/938] loss_G: 2.969144, loss_D: 0.263355\n",
            "[Epoch 165/200] [Batch 330/938] loss_G: 3.150339, loss_D: 0.179698\n",
            "[Epoch 165/200] [Batch 340/938] loss_G: 3.245737, loss_D: 0.101037\n",
            "[Epoch 165/200] [Batch 350/938] loss_G: 3.271881, loss_D: 0.165318\n",
            "[Epoch 165/200] [Batch 360/938] loss_G: 3.248548, loss_D: 0.180049\n",
            "[Epoch 165/200] [Batch 370/938] loss_G: 3.427245, loss_D: 0.269332\n",
            "[Epoch 165/200] [Batch 380/938] loss_G: 3.032140, loss_D: 0.173345\n",
            "[Epoch 165/200] [Batch 390/938] loss_G: 3.621418, loss_D: 0.128139\n",
            "[Epoch 165/200] [Batch 400/938] loss_G: 3.251737, loss_D: 0.304019\n",
            "[Epoch 165/200] [Batch 410/938] loss_G: 3.010936, loss_D: 0.287104\n",
            "[Epoch 165/200] [Batch 420/938] loss_G: 3.316660, loss_D: 0.167422\n",
            "[Epoch 165/200] [Batch 430/938] loss_G: 3.115208, loss_D: 0.255765\n",
            "[Epoch 165/200] [Batch 440/938] loss_G: 3.514611, loss_D: 0.175936\n",
            "[Epoch 165/200] [Batch 450/938] loss_G: 3.302850, loss_D: 0.112728\n",
            "[Epoch 165/200] [Batch 460/938] loss_G: 3.273988, loss_D: 0.250025\n",
            "[Epoch 165/200] [Batch 470/938] loss_G: 3.072349, loss_D: 0.224504\n",
            "[Epoch 165/200] [Batch 480/938] loss_G: 3.091727, loss_D: 0.211102\n",
            "[Epoch 165/200] [Batch 490/938] loss_G: 3.292373, loss_D: 0.139809\n",
            "[Epoch 165/200] [Batch 500/938] loss_G: 2.928603, loss_D: 0.200835\n",
            "[Epoch 165/200] [Batch 510/938] loss_G: 3.020445, loss_D: 0.238316\n",
            "[Epoch 165/200] [Batch 520/938] loss_G: 3.421821, loss_D: 0.167209\n",
            "[Epoch 165/200] [Batch 530/938] loss_G: 3.141254, loss_D: 0.186100\n",
            "[Epoch 165/200] [Batch 540/938] loss_G: 3.085999, loss_D: 0.156162\n",
            "[Epoch 165/200] [Batch 550/938] loss_G: 3.390932, loss_D: 0.200990\n",
            "[Epoch 165/200] [Batch 560/938] loss_G: 3.306440, loss_D: 0.212348\n",
            "[Epoch 165/200] [Batch 570/938] loss_G: 3.462514, loss_D: 0.163260\n",
            "[Epoch 165/200] [Batch 580/938] loss_G: 3.029576, loss_D: 0.152520\n",
            "[Epoch 165/200] [Batch 590/938] loss_G: 2.882384, loss_D: 0.139408\n",
            "[Epoch 165/200] [Batch 600/938] loss_G: 3.236916, loss_D: 0.233083\n",
            "[Epoch 165/200] [Batch 610/938] loss_G: 3.608203, loss_D: 0.162268\n",
            "[Epoch 165/200] [Batch 620/938] loss_G: 3.247007, loss_D: 0.239230\n",
            "[Epoch 165/200] [Batch 630/938] loss_G: 3.262900, loss_D: 0.184738\n",
            "[Epoch 165/200] [Batch 640/938] loss_G: 3.337444, loss_D: 0.226539\n",
            "[Epoch 165/200] [Batch 650/938] loss_G: 2.813983, loss_D: 0.156407\n",
            "[Epoch 165/200] [Batch 660/938] loss_G: 3.386262, loss_D: 0.139205\n",
            "[Epoch 165/200] [Batch 670/938] loss_G: 3.117710, loss_D: 0.306738\n",
            "[Epoch 165/200] [Batch 680/938] loss_G: 3.495516, loss_D: 0.138790\n",
            "[Epoch 165/200] [Batch 690/938] loss_G: 3.348481, loss_D: 0.174772\n",
            "[Epoch 165/200] [Batch 700/938] loss_G: 2.887049, loss_D: 0.195122\n",
            "[Epoch 165/200] [Batch 710/938] loss_G: 2.950524, loss_D: 0.228229\n",
            "[Epoch 165/200] [Batch 720/938] loss_G: 2.973464, loss_D: 0.176524\n",
            "[Epoch 165/200] [Batch 730/938] loss_G: 3.309381, loss_D: 0.131258\n",
            "[Epoch 165/200] [Batch 740/938] loss_G: 3.042832, loss_D: 0.182176\n",
            "[Epoch 165/200] [Batch 750/938] loss_G: 3.056605, loss_D: 0.193726\n",
            "[Epoch 165/200] [Batch 760/938] loss_G: 3.144279, loss_D: 0.220060\n",
            "[Epoch 165/200] [Batch 770/938] loss_G: 3.223128, loss_D: 0.207238\n",
            "[Epoch 165/200] [Batch 780/938] loss_G: 3.200173, loss_D: 0.121249\n",
            "[Epoch 165/200] [Batch 790/938] loss_G: 3.298978, loss_D: 0.200390\n",
            "[Epoch 165/200] [Batch 800/938] loss_G: 2.778255, loss_D: 0.236337\n",
            "[Epoch 165/200] [Batch 810/938] loss_G: 3.266965, loss_D: 0.171440\n",
            "[Epoch 165/200] [Batch 820/938] loss_G: 2.813624, loss_D: 0.345663\n",
            "[Epoch 165/200] [Batch 830/938] loss_G: 2.615850, loss_D: 0.188025\n",
            "[Epoch 165/200] [Batch 840/938] loss_G: 3.247950, loss_D: 0.139042\n",
            "[Epoch 165/200] [Batch 850/938] loss_G: 2.982965, loss_D: 0.228523\n",
            "[Epoch 165/200] [Batch 860/938] loss_G: 3.390785, loss_D: 0.231599\n",
            "[Epoch 165/200] [Batch 870/938] loss_G: 2.982495, loss_D: 0.196591\n",
            "[Epoch 165/200] [Batch 880/938] loss_G: 2.934714, loss_D: 0.215850\n",
            "[Epoch 165/200] [Batch 890/938] loss_G: 3.291835, loss_D: 0.191701\n",
            "[Epoch 165/200] [Batch 900/938] loss_G: 3.390710, loss_D: 0.084262\n",
            "[Epoch 165/200] [Batch 910/938] loss_G: 2.921977, loss_D: 0.234251\n",
            "[Epoch 165/200] [Batch 920/938] loss_G: 3.072146, loss_D: 0.136322\n",
            "[Epoch 165/200] [Batch 930/938] loss_G: 3.116949, loss_D: 0.183944\n",
            "[Epoch 166/200] [Batch 0/938] loss_G: 3.272452, loss_D: 0.201471\n",
            "[Epoch 166/200] [Batch 10/938] loss_G: 2.994581, loss_D: 0.157807\n",
            "[Epoch 166/200] [Batch 20/938] loss_G: 2.708658, loss_D: 0.145769\n",
            "[Epoch 166/200] [Batch 30/938] loss_G: 3.279605, loss_D: 0.191883\n",
            "[Epoch 166/200] [Batch 40/938] loss_G: 2.963262, loss_D: 0.224179\n",
            "[Epoch 166/200] [Batch 50/938] loss_G: 3.273289, loss_D: 0.169368\n",
            "[Epoch 166/200] [Batch 60/938] loss_G: 2.766371, loss_D: 0.233535\n",
            "[Epoch 166/200] [Batch 70/938] loss_G: 3.247983, loss_D: 0.158152\n",
            "[Epoch 166/200] [Batch 80/938] loss_G: 3.285480, loss_D: 0.221459\n",
            "[Epoch 166/200] [Batch 90/938] loss_G: 3.509006, loss_D: 0.200679\n",
            "[Epoch 166/200] [Batch 100/938] loss_G: 3.007664, loss_D: 0.220888\n",
            "[Epoch 166/200] [Batch 110/938] loss_G: 3.074363, loss_D: 0.193534\n",
            "[Epoch 166/200] [Batch 120/938] loss_G: 3.168892, loss_D: 0.188023\n",
            "[Epoch 166/200] [Batch 130/938] loss_G: 3.315886, loss_D: 0.176052\n",
            "[Epoch 166/200] [Batch 140/938] loss_G: 3.385473, loss_D: 0.143792\n",
            "[Epoch 166/200] [Batch 150/938] loss_G: 3.035636, loss_D: 0.188855\n",
            "[Epoch 166/200] [Batch 160/938] loss_G: 3.227926, loss_D: 0.194931\n",
            "[Epoch 166/200] [Batch 170/938] loss_G: 3.365587, loss_D: 0.186297\n",
            "[Epoch 166/200] [Batch 180/938] loss_G: 2.876144, loss_D: 0.111855\n",
            "[Epoch 166/200] [Batch 190/938] loss_G: 3.363583, loss_D: 0.234937\n",
            "[Epoch 166/200] [Batch 200/938] loss_G: 3.011654, loss_D: 0.191871\n",
            "[Epoch 166/200] [Batch 210/938] loss_G: 2.825738, loss_D: 0.212786\n",
            "[Epoch 166/200] [Batch 220/938] loss_G: 3.341489, loss_D: 0.229642\n",
            "[Epoch 166/200] [Batch 230/938] loss_G: 3.744344, loss_D: 0.133721\n",
            "[Epoch 166/200] [Batch 240/938] loss_G: 3.059914, loss_D: 0.234807\n",
            "[Epoch 166/200] [Batch 250/938] loss_G: 3.152421, loss_D: 0.240534\n",
            "[Epoch 166/200] [Batch 260/938] loss_G: 3.428622, loss_D: 0.175727\n",
            "[Epoch 166/200] [Batch 270/938] loss_G: 3.245827, loss_D: 0.201102\n",
            "[Epoch 166/200] [Batch 280/938] loss_G: 3.164347, loss_D: 0.122422\n",
            "[Epoch 166/200] [Batch 290/938] loss_G: 2.973247, loss_D: 0.265553\n",
            "[Epoch 166/200] [Batch 300/938] loss_G: 3.121475, loss_D: 0.165237\n",
            "[Epoch 166/200] [Batch 310/938] loss_G: 3.027279, loss_D: 0.260432\n",
            "[Epoch 166/200] [Batch 320/938] loss_G: 2.845376, loss_D: 0.191342\n",
            "[Epoch 166/200] [Batch 330/938] loss_G: 2.988509, loss_D: 0.172379\n",
            "[Epoch 166/200] [Batch 340/938] loss_G: 3.072312, loss_D: 0.189040\n",
            "[Epoch 166/200] [Batch 350/938] loss_G: 3.260371, loss_D: 0.189764\n",
            "[Epoch 166/200] [Batch 360/938] loss_G: 3.096007, loss_D: 0.179608\n",
            "[Epoch 166/200] [Batch 370/938] loss_G: 2.685447, loss_D: 0.215210\n",
            "[Epoch 166/200] [Batch 380/938] loss_G: 3.391877, loss_D: 0.214611\n",
            "[Epoch 166/200] [Batch 390/938] loss_G: 3.275666, loss_D: 0.197836\n",
            "[Epoch 166/200] [Batch 400/938] loss_G: 3.350752, loss_D: 0.173448\n",
            "[Epoch 166/200] [Batch 410/938] loss_G: 2.791460, loss_D: 0.293449\n",
            "[Epoch 166/200] [Batch 420/938] loss_G: 3.401851, loss_D: 0.151444\n",
            "[Epoch 166/200] [Batch 430/938] loss_G: 2.940246, loss_D: 0.202024\n",
            "[Epoch 166/200] [Batch 440/938] loss_G: 2.957689, loss_D: 0.178114\n",
            "[Epoch 166/200] [Batch 450/938] loss_G: 3.194800, loss_D: 0.150123\n",
            "[Epoch 166/200] [Batch 460/938] loss_G: 3.204738, loss_D: 0.241060\n",
            "[Epoch 166/200] [Batch 470/938] loss_G: 3.672153, loss_D: 0.232898\n",
            "[Epoch 166/200] [Batch 480/938] loss_G: 2.684651, loss_D: 0.379397\n",
            "[Epoch 166/200] [Batch 490/938] loss_G: 2.910725, loss_D: 0.201287\n",
            "[Epoch 166/200] [Batch 500/938] loss_G: 3.449719, loss_D: 0.205275\n",
            "[Epoch 166/200] [Batch 510/938] loss_G: 3.258870, loss_D: 0.211044\n",
            "[Epoch 166/200] [Batch 520/938] loss_G: 3.144380, loss_D: 0.209749\n",
            "[Epoch 166/200] [Batch 530/938] loss_G: 3.327648, loss_D: 0.195948\n",
            "[Epoch 166/200] [Batch 540/938] loss_G: 2.861289, loss_D: 0.178872\n",
            "[Epoch 166/200] [Batch 550/938] loss_G: 3.080252, loss_D: 0.285445\n",
            "[Epoch 166/200] [Batch 560/938] loss_G: 3.399064, loss_D: 0.170289\n",
            "[Epoch 166/200] [Batch 570/938] loss_G: 3.458596, loss_D: 0.174432\n",
            "[Epoch 166/200] [Batch 580/938] loss_G: 3.156358, loss_D: 0.203377\n",
            "[Epoch 166/200] [Batch 590/938] loss_G: 3.346095, loss_D: 0.174703\n",
            "[Epoch 166/200] [Batch 600/938] loss_G: 3.335859, loss_D: 0.168726\n",
            "[Epoch 166/200] [Batch 610/938] loss_G: 2.985802, loss_D: 0.260850\n",
            "[Epoch 166/200] [Batch 620/938] loss_G: 3.313330, loss_D: 0.182767\n",
            "[Epoch 166/200] [Batch 630/938] loss_G: 3.283977, loss_D: 0.218920\n",
            "[Epoch 166/200] [Batch 640/938] loss_G: 3.160312, loss_D: 0.176225\n",
            "[Epoch 166/200] [Batch 650/938] loss_G: 3.167475, loss_D: 0.268147\n",
            "[Epoch 166/200] [Batch 660/938] loss_G: 3.040116, loss_D: 0.246861\n",
            "[Epoch 166/200] [Batch 670/938] loss_G: 2.864392, loss_D: 0.194582\n",
            "[Epoch 166/200] [Batch 680/938] loss_G: 3.015003, loss_D: 0.192301\n",
            "[Epoch 166/200] [Batch 690/938] loss_G: 3.285221, loss_D: 0.215804\n",
            "[Epoch 166/200] [Batch 700/938] loss_G: 3.011369, loss_D: 0.203917\n",
            "[Epoch 166/200] [Batch 710/938] loss_G: 3.411817, loss_D: 0.217659\n",
            "[Epoch 166/200] [Batch 720/938] loss_G: 3.334900, loss_D: 0.250541\n",
            "[Epoch 166/200] [Batch 730/938] loss_G: 2.952399, loss_D: 0.196504\n",
            "[Epoch 166/200] [Batch 740/938] loss_G: 3.039705, loss_D: 0.230808\n",
            "[Epoch 166/200] [Batch 750/938] loss_G: 3.113144, loss_D: 0.161316\n",
            "[Epoch 166/200] [Batch 760/938] loss_G: 2.936500, loss_D: 0.199088\n",
            "[Epoch 166/200] [Batch 770/938] loss_G: 2.686381, loss_D: 0.231463\n",
            "[Epoch 166/200] [Batch 780/938] loss_G: 3.172296, loss_D: 0.186210\n",
            "[Epoch 166/200] [Batch 790/938] loss_G: 3.184299, loss_D: 0.198091\n",
            "[Epoch 166/200] [Batch 800/938] loss_G: 3.249318, loss_D: 0.168144\n",
            "[Epoch 166/200] [Batch 810/938] loss_G: 3.239905, loss_D: 0.098282\n",
            "[Epoch 166/200] [Batch 820/938] loss_G: 3.203428, loss_D: 0.220131\n",
            "[Epoch 166/200] [Batch 830/938] loss_G: 3.408532, loss_D: 0.168641\n",
            "[Epoch 166/200] [Batch 840/938] loss_G: 2.883300, loss_D: 0.197595\n",
            "[Epoch 166/200] [Batch 850/938] loss_G: 3.087867, loss_D: 0.221401\n",
            "[Epoch 166/200] [Batch 860/938] loss_G: 2.984024, loss_D: 0.199908\n",
            "[Epoch 166/200] [Batch 870/938] loss_G: 2.943831, loss_D: 0.290726\n",
            "[Epoch 166/200] [Batch 880/938] loss_G: 2.751524, loss_D: 0.211629\n",
            "[Epoch 166/200] [Batch 890/938] loss_G: 3.396173, loss_D: 0.123241\n",
            "[Epoch 166/200] [Batch 900/938] loss_G: 3.293300, loss_D: 0.296407\n",
            "[Epoch 166/200] [Batch 910/938] loss_G: 3.183094, loss_D: 0.183157\n",
            "[Epoch 166/200] [Batch 920/938] loss_G: 3.060684, loss_D: 0.142373\n",
            "[Epoch 166/200] [Batch 930/938] loss_G: 3.227118, loss_D: 0.171806\n",
            "[Epoch 167/200] [Batch 0/938] loss_G: 3.058707, loss_D: 0.255609\n",
            "[Epoch 167/200] [Batch 10/938] loss_G: 3.432459, loss_D: 0.196855\n",
            "[Epoch 167/200] [Batch 20/938] loss_G: 3.557804, loss_D: 0.193105\n",
            "[Epoch 167/200] [Batch 30/938] loss_G: 3.055939, loss_D: 0.189174\n",
            "[Epoch 167/200] [Batch 40/938] loss_G: 2.982438, loss_D: 0.202801\n",
            "[Epoch 167/200] [Batch 50/938] loss_G: 3.143136, loss_D: 0.265261\n",
            "[Epoch 167/200] [Batch 60/938] loss_G: 3.046855, loss_D: 0.182981\n",
            "[Epoch 167/200] [Batch 70/938] loss_G: 3.191092, loss_D: 0.239380\n",
            "[Epoch 167/200] [Batch 80/938] loss_G: 2.946007, loss_D: 0.148456\n",
            "[Epoch 167/200] [Batch 90/938] loss_G: 3.053179, loss_D: 0.335325\n",
            "[Epoch 167/200] [Batch 100/938] loss_G: 3.148056, loss_D: 0.258175\n",
            "[Epoch 167/200] [Batch 110/938] loss_G: 3.095400, loss_D: 0.175140\n",
            "[Epoch 167/200] [Batch 120/938] loss_G: 3.210504, loss_D: 0.229356\n",
            "[Epoch 167/200] [Batch 130/938] loss_G: 3.028200, loss_D: 0.179093\n",
            "[Epoch 167/200] [Batch 140/938] loss_G: 3.152926, loss_D: 0.325844\n",
            "[Epoch 167/200] [Batch 150/938] loss_G: 3.365866, loss_D: 0.217908\n",
            "[Epoch 167/200] [Batch 160/938] loss_G: 3.029649, loss_D: 0.159986\n",
            "[Epoch 167/200] [Batch 170/938] loss_G: 3.184555, loss_D: 0.158567\n",
            "[Epoch 167/200] [Batch 180/938] loss_G: 3.003153, loss_D: 0.229354\n",
            "[Epoch 167/200] [Batch 190/938] loss_G: 3.283342, loss_D: 0.243329\n",
            "[Epoch 167/200] [Batch 200/938] loss_G: 2.838156, loss_D: 0.217436\n",
            "[Epoch 167/200] [Batch 210/938] loss_G: 3.366156, loss_D: 0.158939\n",
            "[Epoch 167/200] [Batch 220/938] loss_G: 2.892787, loss_D: 0.164997\n",
            "[Epoch 167/200] [Batch 230/938] loss_G: 2.745617, loss_D: 0.239332\n",
            "[Epoch 167/200] [Batch 240/938] loss_G: 3.022241, loss_D: 0.197137\n",
            "[Epoch 167/200] [Batch 250/938] loss_G: 3.510062, loss_D: 0.324277\n",
            "[Epoch 167/200] [Batch 260/938] loss_G: 3.071703, loss_D: 0.149225\n",
            "[Epoch 167/200] [Batch 270/938] loss_G: 3.401970, loss_D: 0.232637\n",
            "[Epoch 167/200] [Batch 280/938] loss_G: 3.004404, loss_D: 0.290466\n",
            "[Epoch 167/200] [Batch 290/938] loss_G: 3.180718, loss_D: 0.208496\n",
            "[Epoch 167/200] [Batch 300/938] loss_G: 3.100021, loss_D: 0.183378\n",
            "[Epoch 167/200] [Batch 310/938] loss_G: 3.334102, loss_D: 0.178721\n",
            "[Epoch 167/200] [Batch 320/938] loss_G: 2.847890, loss_D: 0.235235\n",
            "[Epoch 167/200] [Batch 330/938] loss_G: 3.234191, loss_D: 0.231418\n",
            "[Epoch 167/200] [Batch 340/938] loss_G: 3.356653, loss_D: 0.209555\n",
            "[Epoch 167/200] [Batch 350/938] loss_G: 3.022135, loss_D: 0.185549\n",
            "[Epoch 167/200] [Batch 360/938] loss_G: 3.002955, loss_D: 0.194689\n",
            "[Epoch 167/200] [Batch 370/938] loss_G: 2.999466, loss_D: 0.225338\n",
            "[Epoch 167/200] [Batch 380/938] loss_G: 3.368844, loss_D: 0.155134\n",
            "[Epoch 167/200] [Batch 390/938] loss_G: 3.561249, loss_D: 0.178175\n",
            "[Epoch 167/200] [Batch 400/938] loss_G: 3.175189, loss_D: 0.285226\n",
            "[Epoch 167/200] [Batch 410/938] loss_G: 3.233391, loss_D: 0.210720\n",
            "[Epoch 167/200] [Batch 420/938] loss_G: 3.331581, loss_D: 0.141080\n",
            "[Epoch 167/200] [Batch 430/938] loss_G: 3.165644, loss_D: 0.209865\n",
            "[Epoch 167/200] [Batch 440/938] loss_G: 3.164037, loss_D: 0.285240\n",
            "[Epoch 167/200] [Batch 450/938] loss_G: 3.093921, loss_D: 0.226294\n",
            "[Epoch 167/200] [Batch 460/938] loss_G: 2.860142, loss_D: 0.157840\n",
            "[Epoch 167/200] [Batch 470/938] loss_G: 3.788916, loss_D: 0.198482\n",
            "[Epoch 167/200] [Batch 480/938] loss_G: 2.911271, loss_D: 0.227911\n",
            "[Epoch 167/200] [Batch 490/938] loss_G: 3.113775, loss_D: 0.279305\n",
            "[Epoch 167/200] [Batch 500/938] loss_G: 2.523272, loss_D: 0.235406\n",
            "[Epoch 167/200] [Batch 510/938] loss_G: 3.058974, loss_D: 0.237507\n",
            "[Epoch 167/200] [Batch 520/938] loss_G: 3.211534, loss_D: 0.183391\n",
            "[Epoch 167/200] [Batch 530/938] loss_G: 3.198869, loss_D: 0.193026\n",
            "[Epoch 167/200] [Batch 540/938] loss_G: 3.137950, loss_D: 0.126418\n",
            "[Epoch 167/200] [Batch 550/938] loss_G: 3.263028, loss_D: 0.247448\n",
            "[Epoch 167/200] [Batch 560/938] loss_G: 3.317983, loss_D: 0.245446\n",
            "[Epoch 167/200] [Batch 570/938] loss_G: 3.283459, loss_D: 0.247388\n",
            "[Epoch 167/200] [Batch 580/938] loss_G: 3.132381, loss_D: 0.189801\n",
            "[Epoch 167/200] [Batch 590/938] loss_G: 3.045088, loss_D: 0.196113\n",
            "[Epoch 167/200] [Batch 600/938] loss_G: 3.262728, loss_D: 0.202641\n",
            "[Epoch 167/200] [Batch 610/938] loss_G: 3.074581, loss_D: 0.162432\n",
            "[Epoch 167/200] [Batch 620/938] loss_G: 3.214979, loss_D: 0.215666\n",
            "[Epoch 167/200] [Batch 630/938] loss_G: 3.257527, loss_D: 0.286279\n",
            "[Epoch 167/200] [Batch 640/938] loss_G: 3.639479, loss_D: 0.200061\n",
            "[Epoch 167/200] [Batch 650/938] loss_G: 2.619020, loss_D: 0.267303\n",
            "[Epoch 167/200] [Batch 660/938] loss_G: 3.649351, loss_D: 0.207148\n",
            "[Epoch 167/200] [Batch 670/938] loss_G: 3.157803, loss_D: 0.166214\n",
            "[Epoch 167/200] [Batch 680/938] loss_G: 3.408048, loss_D: 0.167442\n",
            "[Epoch 167/200] [Batch 690/938] loss_G: 3.296966, loss_D: 0.184519\n",
            "[Epoch 167/200] [Batch 700/938] loss_G: 2.963080, loss_D: 0.220093\n",
            "[Epoch 167/200] [Batch 710/938] loss_G: 2.937962, loss_D: 0.203777\n",
            "[Epoch 167/200] [Batch 720/938] loss_G: 3.452044, loss_D: 0.151179\n",
            "[Epoch 167/200] [Batch 730/938] loss_G: 2.938976, loss_D: 0.194797\n",
            "[Epoch 167/200] [Batch 740/938] loss_G: 3.317559, loss_D: 0.349934\n",
            "[Epoch 167/200] [Batch 750/938] loss_G: 2.984077, loss_D: 0.187511\n",
            "[Epoch 167/200] [Batch 760/938] loss_G: 3.217352, loss_D: 0.245739\n",
            "[Epoch 167/200] [Batch 770/938] loss_G: 3.212041, loss_D: 0.286670\n",
            "[Epoch 167/200] [Batch 780/938] loss_G: 3.204340, loss_D: 0.177113\n",
            "[Epoch 167/200] [Batch 790/938] loss_G: 3.401793, loss_D: 0.210117\n",
            "[Epoch 167/200] [Batch 800/938] loss_G: 2.978820, loss_D: 0.131942\n",
            "[Epoch 167/200] [Batch 810/938] loss_G: 2.993793, loss_D: 0.215359\n",
            "[Epoch 167/200] [Batch 820/938] loss_G: 3.428666, loss_D: 0.152415\n",
            "[Epoch 167/200] [Batch 830/938] loss_G: 3.361732, loss_D: 0.191011\n",
            "[Epoch 167/200] [Batch 840/938] loss_G: 2.786162, loss_D: 0.196130\n",
            "[Epoch 167/200] [Batch 850/938] loss_G: 3.160482, loss_D: 0.211417\n",
            "[Epoch 167/200] [Batch 860/938] loss_G: 3.008680, loss_D: 0.227586\n",
            "[Epoch 167/200] [Batch 870/938] loss_G: 3.234105, loss_D: 0.212600\n",
            "[Epoch 167/200] [Batch 880/938] loss_G: 3.191727, loss_D: 0.202159\n",
            "[Epoch 167/200] [Batch 890/938] loss_G: 2.902050, loss_D: 0.276158\n",
            "[Epoch 167/200] [Batch 900/938] loss_G: 3.573319, loss_D: 0.223343\n",
            "[Epoch 167/200] [Batch 910/938] loss_G: 3.077068, loss_D: 0.302358\n",
            "[Epoch 167/200] [Batch 920/938] loss_G: 3.304440, loss_D: 0.171085\n",
            "[Epoch 167/200] [Batch 930/938] loss_G: 2.719492, loss_D: 0.247858\n",
            "[Epoch 168/200] [Batch 0/938] loss_G: 3.293939, loss_D: 0.240074\n",
            "[Epoch 168/200] [Batch 10/938] loss_G: 2.789862, loss_D: 0.229796\n",
            "[Epoch 168/200] [Batch 20/938] loss_G: 3.316142, loss_D: 0.189011\n",
            "[Epoch 168/200] [Batch 30/938] loss_G: 2.857820, loss_D: 0.195954\n",
            "[Epoch 168/200] [Batch 40/938] loss_G: 2.882934, loss_D: 0.193865\n",
            "[Epoch 168/200] [Batch 50/938] loss_G: 3.364980, loss_D: 0.167095\n",
            "[Epoch 168/200] [Batch 60/938] loss_G: 3.139323, loss_D: 0.201771\n",
            "[Epoch 168/200] [Batch 70/938] loss_G: 2.982866, loss_D: 0.254446\n",
            "[Epoch 168/200] [Batch 80/938] loss_G: 3.063666, loss_D: 0.286167\n",
            "[Epoch 168/200] [Batch 90/938] loss_G: 2.875982, loss_D: 0.223217\n",
            "[Epoch 168/200] [Batch 100/938] loss_G: 2.872192, loss_D: 0.133995\n",
            "[Epoch 168/200] [Batch 110/938] loss_G: 2.946878, loss_D: 0.177669\n",
            "[Epoch 168/200] [Batch 120/938] loss_G: 3.019958, loss_D: 0.214658\n",
            "[Epoch 168/200] [Batch 130/938] loss_G: 3.308886, loss_D: 0.135543\n",
            "[Epoch 168/200] [Batch 140/938] loss_G: 3.077373, loss_D: 0.194488\n",
            "[Epoch 168/200] [Batch 150/938] loss_G: 3.074955, loss_D: 0.143196\n",
            "[Epoch 168/200] [Batch 160/938] loss_G: 3.052284, loss_D: 0.262862\n",
            "[Epoch 168/200] [Batch 170/938] loss_G: 3.378375, loss_D: 0.208743\n",
            "[Epoch 168/200] [Batch 180/938] loss_G: 3.098100, loss_D: 0.163811\n",
            "[Epoch 168/200] [Batch 190/938] loss_G: 2.893124, loss_D: 0.276874\n",
            "[Epoch 168/200] [Batch 200/938] loss_G: 3.160096, loss_D: 0.160221\n",
            "[Epoch 168/200] [Batch 210/938] loss_G: 3.231031, loss_D: 0.213469\n",
            "[Epoch 168/200] [Batch 220/938] loss_G: 3.188704, loss_D: 0.161849\n",
            "[Epoch 168/200] [Batch 230/938] loss_G: 3.150961, loss_D: 0.173790\n",
            "[Epoch 168/200] [Batch 240/938] loss_G: 2.858182, loss_D: 0.187629\n",
            "[Epoch 168/200] [Batch 250/938] loss_G: 3.125197, loss_D: 0.263740\n",
            "[Epoch 168/200] [Batch 260/938] loss_G: 2.984656, loss_D: 0.178315\n",
            "[Epoch 168/200] [Batch 270/938] loss_G: 3.234935, loss_D: 0.193721\n",
            "[Epoch 168/200] [Batch 280/938] loss_G: 3.275396, loss_D: 0.179941\n",
            "[Epoch 168/200] [Batch 290/938] loss_G: 3.091869, loss_D: 0.218006\n",
            "[Epoch 168/200] [Batch 300/938] loss_G: 2.938073, loss_D: 0.262760\n",
            "[Epoch 168/200] [Batch 310/938] loss_G: 2.843006, loss_D: 0.191045\n",
            "[Epoch 168/200] [Batch 320/938] loss_G: 2.999103, loss_D: 0.094518\n",
            "[Epoch 168/200] [Batch 330/938] loss_G: 2.840782, loss_D: 0.229033\n",
            "[Epoch 168/200] [Batch 340/938] loss_G: 3.343442, loss_D: 0.294732\n",
            "[Epoch 168/200] [Batch 350/938] loss_G: 3.298603, loss_D: 0.210686\n",
            "[Epoch 168/200] [Batch 360/938] loss_G: 3.320873, loss_D: 0.139232\n",
            "[Epoch 168/200] [Batch 370/938] loss_G: 3.071481, loss_D: 0.205081\n",
            "[Epoch 168/200] [Batch 380/938] loss_G: 3.260460, loss_D: 0.170726\n",
            "[Epoch 168/200] [Batch 390/938] loss_G: 3.048106, loss_D: 0.189591\n",
            "[Epoch 168/200] [Batch 400/938] loss_G: 3.006910, loss_D: 0.229782\n",
            "[Epoch 168/200] [Batch 410/938] loss_G: 3.061715, loss_D: 0.207352\n",
            "[Epoch 168/200] [Batch 420/938] loss_G: 3.217101, loss_D: 0.265848\n",
            "[Epoch 168/200] [Batch 430/938] loss_G: 3.229038, loss_D: 0.136474\n",
            "[Epoch 168/200] [Batch 440/938] loss_G: 3.136468, loss_D: 0.222570\n",
            "[Epoch 168/200] [Batch 450/938] loss_G: 2.746630, loss_D: 0.163246\n",
            "[Epoch 168/200] [Batch 460/938] loss_G: 2.853287, loss_D: 0.202956\n",
            "[Epoch 168/200] [Batch 470/938] loss_G: 3.291640, loss_D: 0.118880\n",
            "[Epoch 168/200] [Batch 480/938] loss_G: 2.936434, loss_D: 0.243993\n",
            "[Epoch 168/200] [Batch 490/938] loss_G: 3.139354, loss_D: 0.181885\n",
            "[Epoch 168/200] [Batch 500/938] loss_G: 2.904158, loss_D: 0.385785\n",
            "[Epoch 168/200] [Batch 510/938] loss_G: 3.070080, loss_D: 0.247961\n",
            "[Epoch 168/200] [Batch 520/938] loss_G: 3.379405, loss_D: 0.194537\n",
            "[Epoch 168/200] [Batch 530/938] loss_G: 3.168376, loss_D: 0.217619\n",
            "[Epoch 168/200] [Batch 540/938] loss_G: 2.821877, loss_D: 0.221272\n",
            "[Epoch 168/200] [Batch 550/938] loss_G: 3.065070, loss_D: 0.210634\n",
            "[Epoch 168/200] [Batch 560/938] loss_G: 3.224457, loss_D: 0.352925\n",
            "[Epoch 168/200] [Batch 570/938] loss_G: 3.025638, loss_D: 0.184406\n",
            "[Epoch 168/200] [Batch 580/938] loss_G: 3.151467, loss_D: 0.166490\n",
            "[Epoch 168/200] [Batch 590/938] loss_G: 3.038182, loss_D: 0.235208\n",
            "[Epoch 168/200] [Batch 600/938] loss_G: 2.605523, loss_D: 0.244553\n",
            "[Epoch 168/200] [Batch 610/938] loss_G: 2.921108, loss_D: 0.200577\n",
            "[Epoch 168/200] [Batch 620/938] loss_G: 3.441198, loss_D: 0.247928\n",
            "[Epoch 168/200] [Batch 630/938] loss_G: 3.296117, loss_D: 0.207999\n",
            "[Epoch 168/200] [Batch 640/938] loss_G: 2.899243, loss_D: 0.231739\n",
            "[Epoch 168/200] [Batch 650/938] loss_G: 3.319844, loss_D: 0.196161\n",
            "[Epoch 168/200] [Batch 660/938] loss_G: 3.591662, loss_D: 0.181023\n",
            "[Epoch 168/200] [Batch 670/938] loss_G: 3.136528, loss_D: 0.157074\n",
            "[Epoch 168/200] [Batch 680/938] loss_G: 3.295525, loss_D: 0.160231\n",
            "[Epoch 168/200] [Batch 690/938] loss_G: 3.135439, loss_D: 0.143416\n",
            "[Epoch 168/200] [Batch 700/938] loss_G: 3.336491, loss_D: 0.145185\n",
            "[Epoch 168/200] [Batch 710/938] loss_G: 3.072914, loss_D: 0.204320\n",
            "[Epoch 168/200] [Batch 720/938] loss_G: 2.951977, loss_D: 0.172770\n",
            "[Epoch 168/200] [Batch 730/938] loss_G: 3.147885, loss_D: 0.243677\n",
            "[Epoch 168/200] [Batch 740/938] loss_G: 2.868386, loss_D: 0.238571\n",
            "[Epoch 168/200] [Batch 750/938] loss_G: 3.156316, loss_D: 0.242127\n",
            "[Epoch 168/200] [Batch 760/938] loss_G: 2.877654, loss_D: 0.129765\n",
            "[Epoch 168/200] [Batch 770/938] loss_G: 3.167353, loss_D: 0.270755\n",
            "[Epoch 168/200] [Batch 780/938] loss_G: 3.076571, loss_D: 0.167116\n",
            "[Epoch 168/200] [Batch 790/938] loss_G: 3.332476, loss_D: 0.137765\n",
            "[Epoch 168/200] [Batch 800/938] loss_G: 3.223805, loss_D: 0.209715\n",
            "[Epoch 168/200] [Batch 810/938] loss_G: 2.881005, loss_D: 0.134401\n",
            "[Epoch 168/200] [Batch 820/938] loss_G: 2.856670, loss_D: 0.226907\n",
            "[Epoch 168/200] [Batch 830/938] loss_G: 2.946328, loss_D: 0.288139\n",
            "[Epoch 168/200] [Batch 840/938] loss_G: 3.099690, loss_D: 0.159678\n",
            "[Epoch 168/200] [Batch 850/938] loss_G: 3.116161, loss_D: 0.167854\n",
            "[Epoch 168/200] [Batch 860/938] loss_G: 3.268445, loss_D: 0.175828\n",
            "[Epoch 168/200] [Batch 870/938] loss_G: 3.118886, loss_D: 0.163011\n",
            "[Epoch 168/200] [Batch 880/938] loss_G: 3.333138, loss_D: 0.136045\n",
            "[Epoch 168/200] [Batch 890/938] loss_G: 3.253508, loss_D: 0.149132\n",
            "[Epoch 168/200] [Batch 900/938] loss_G: 2.689796, loss_D: 0.182420\n",
            "[Epoch 168/200] [Batch 910/938] loss_G: 3.179069, loss_D: 0.280024\n",
            "[Epoch 168/200] [Batch 920/938] loss_G: 3.351085, loss_D: 0.222845\n",
            "[Epoch 168/200] [Batch 930/938] loss_G: 3.434439, loss_D: 0.183730\n",
            "[Epoch 169/200] [Batch 0/938] loss_G: 3.261572, loss_D: 0.161446\n",
            "[Epoch 169/200] [Batch 10/938] loss_G: 2.963583, loss_D: 0.198148\n",
            "[Epoch 169/200] [Batch 20/938] loss_G: 3.182998, loss_D: 0.169177\n",
            "[Epoch 169/200] [Batch 30/938] loss_G: 3.271826, loss_D: 0.297026\n",
            "[Epoch 169/200] [Batch 40/938] loss_G: 3.361540, loss_D: 0.217406\n",
            "[Epoch 169/200] [Batch 50/938] loss_G: 3.191296, loss_D: 0.164150\n",
            "[Epoch 169/200] [Batch 60/938] loss_G: 3.941811, loss_D: 0.264149\n",
            "[Epoch 169/200] [Batch 70/938] loss_G: 3.179095, loss_D: 0.184703\n",
            "[Epoch 169/200] [Batch 80/938] loss_G: 3.145761, loss_D: 0.211794\n",
            "[Epoch 169/200] [Batch 90/938] loss_G: 3.363078, loss_D: 0.216094\n",
            "[Epoch 169/200] [Batch 100/938] loss_G: 3.195086, loss_D: 0.236641\n",
            "[Epoch 169/200] [Batch 110/938] loss_G: 3.142357, loss_D: 0.193071\n",
            "[Epoch 169/200] [Batch 120/938] loss_G: 3.325039, loss_D: 0.218988\n",
            "[Epoch 169/200] [Batch 130/938] loss_G: 3.129413, loss_D: 0.151560\n",
            "[Epoch 169/200] [Batch 140/938] loss_G: 3.141914, loss_D: 0.127885\n",
            "[Epoch 169/200] [Batch 150/938] loss_G: 2.944653, loss_D: 0.282493\n",
            "[Epoch 169/200] [Batch 160/938] loss_G: 3.007586, loss_D: 0.256303\n",
            "[Epoch 169/200] [Batch 170/938] loss_G: 3.349087, loss_D: 0.191452\n",
            "[Epoch 169/200] [Batch 180/938] loss_G: 3.279291, loss_D: 0.154484\n",
            "[Epoch 169/200] [Batch 190/938] loss_G: 2.974304, loss_D: 0.115719\n",
            "[Epoch 169/200] [Batch 200/938] loss_G: 2.869372, loss_D: 0.257823\n",
            "[Epoch 169/200] [Batch 210/938] loss_G: 3.106813, loss_D: 0.118812\n",
            "[Epoch 169/200] [Batch 220/938] loss_G: 3.510478, loss_D: 0.324136\n",
            "[Epoch 169/200] [Batch 230/938] loss_G: 3.282141, loss_D: 0.232417\n",
            "[Epoch 169/200] [Batch 240/938] loss_G: 2.946809, loss_D: 0.155283\n",
            "[Epoch 169/200] [Batch 250/938] loss_G: 3.385585, loss_D: 0.308408\n",
            "[Epoch 169/200] [Batch 260/938] loss_G: 2.737617, loss_D: 0.213270\n",
            "[Epoch 169/200] [Batch 270/938] loss_G: 2.941824, loss_D: 0.156310\n",
            "[Epoch 169/200] [Batch 280/938] loss_G: 3.011226, loss_D: 0.168356\n",
            "[Epoch 169/200] [Batch 290/938] loss_G: 3.197891, loss_D: 0.210560\n",
            "[Epoch 169/200] [Batch 300/938] loss_G: 3.070142, loss_D: 0.193887\n",
            "[Epoch 169/200] [Batch 310/938] loss_G: 3.168993, loss_D: 0.170627\n",
            "[Epoch 169/200] [Batch 320/938] loss_G: 3.081599, loss_D: 0.283246\n",
            "[Epoch 169/200] [Batch 330/938] loss_G: 3.614082, loss_D: 0.214838\n",
            "[Epoch 169/200] [Batch 340/938] loss_G: 3.321049, loss_D: 0.237054\n",
            "[Epoch 169/200] [Batch 350/938] loss_G: 3.065226, loss_D: 0.190168\n",
            "[Epoch 169/200] [Batch 360/938] loss_G: 3.250566, loss_D: 0.172790\n",
            "[Epoch 169/200] [Batch 370/938] loss_G: 3.177344, loss_D: 0.161600\n",
            "[Epoch 169/200] [Batch 380/938] loss_G: 3.105393, loss_D: 0.197867\n",
            "[Epoch 169/200] [Batch 390/938] loss_G: 3.012037, loss_D: 0.198517\n",
            "[Epoch 169/200] [Batch 400/938] loss_G: 3.379950, loss_D: 0.209854\n",
            "[Epoch 169/200] [Batch 410/938] loss_G: 3.154198, loss_D: 0.242195\n",
            "[Epoch 169/200] [Batch 420/938] loss_G: 3.333169, loss_D: 0.167513\n",
            "[Epoch 169/200] [Batch 430/938] loss_G: 3.096819, loss_D: 0.147117\n",
            "[Epoch 169/200] [Batch 440/938] loss_G: 3.196074, loss_D: 0.230787\n",
            "[Epoch 169/200] [Batch 450/938] loss_G: 3.242827, loss_D: 0.101024\n",
            "[Epoch 169/200] [Batch 460/938] loss_G: 3.253065, loss_D: 0.138361\n",
            "[Epoch 169/200] [Batch 470/938] loss_G: 3.265352, loss_D: 0.139840\n",
            "[Epoch 169/200] [Batch 480/938] loss_G: 3.188454, loss_D: 0.133118\n",
            "[Epoch 169/200] [Batch 490/938] loss_G: 3.246636, loss_D: 0.195797\n",
            "[Epoch 169/200] [Batch 500/938] loss_G: 3.196938, loss_D: 0.254490\n",
            "[Epoch 169/200] [Batch 510/938] loss_G: 3.125421, loss_D: 0.194724\n",
            "[Epoch 169/200] [Batch 520/938] loss_G: 3.298856, loss_D: 0.217674\n",
            "[Epoch 169/200] [Batch 530/938] loss_G: 3.263481, loss_D: 0.170028\n",
            "[Epoch 169/200] [Batch 540/938] loss_G: 3.340197, loss_D: 0.134529\n",
            "[Epoch 169/200] [Batch 550/938] loss_G: 2.872125, loss_D: 0.252859\n",
            "[Epoch 169/200] [Batch 560/938] loss_G: 3.503440, loss_D: 0.220126\n",
            "[Epoch 169/200] [Batch 570/938] loss_G: 3.188322, loss_D: 0.215687\n",
            "[Epoch 169/200] [Batch 580/938] loss_G: 3.013181, loss_D: 0.160639\n",
            "[Epoch 169/200] [Batch 590/938] loss_G: 3.371560, loss_D: 0.174526\n",
            "[Epoch 169/200] [Batch 600/938] loss_G: 3.524668, loss_D: 0.181944\n",
            "[Epoch 169/200] [Batch 610/938] loss_G: 3.519914, loss_D: 0.205064\n",
            "[Epoch 169/200] [Batch 620/938] loss_G: 3.201257, loss_D: 0.212666\n",
            "[Epoch 169/200] [Batch 630/938] loss_G: 3.152603, loss_D: 0.159168\n",
            "[Epoch 169/200] [Batch 640/938] loss_G: 3.407500, loss_D: 0.224720\n",
            "[Epoch 169/200] [Batch 650/938] loss_G: 3.276537, loss_D: 0.153288\n",
            "[Epoch 169/200] [Batch 660/938] loss_G: 3.265541, loss_D: 0.290017\n",
            "[Epoch 169/200] [Batch 670/938] loss_G: 3.280749, loss_D: 0.222771\n",
            "[Epoch 169/200] [Batch 680/938] loss_G: 3.448553, loss_D: 0.313812\n",
            "[Epoch 169/200] [Batch 690/938] loss_G: 2.945276, loss_D: 0.235874\n",
            "[Epoch 169/200] [Batch 700/938] loss_G: 3.113404, loss_D: 0.220744\n",
            "[Epoch 169/200] [Batch 710/938] loss_G: 3.245979, loss_D: 0.238098\n",
            "[Epoch 169/200] [Batch 720/938] loss_G: 3.213739, loss_D: 0.185011\n",
            "[Epoch 169/200] [Batch 730/938] loss_G: 3.112375, loss_D: 0.199896\n",
            "[Epoch 169/200] [Batch 740/938] loss_G: 2.954567, loss_D: 0.183194\n",
            "[Epoch 169/200] [Batch 750/938] loss_G: 2.868536, loss_D: 0.157846\n",
            "[Epoch 169/200] [Batch 760/938] loss_G: 3.113726, loss_D: 0.239931\n",
            "[Epoch 169/200] [Batch 770/938] loss_G: 2.924158, loss_D: 0.219946\n",
            "[Epoch 169/200] [Batch 780/938] loss_G: 3.311244, loss_D: 0.182704\n",
            "[Epoch 169/200] [Batch 790/938] loss_G: 3.720670, loss_D: 0.159252\n",
            "[Epoch 169/200] [Batch 800/938] loss_G: 2.844266, loss_D: 0.383168\n",
            "[Epoch 169/200] [Batch 810/938] loss_G: 3.331962, loss_D: 0.179676\n",
            "[Epoch 169/200] [Batch 820/938] loss_G: 3.185585, loss_D: 0.267599\n",
            "[Epoch 169/200] [Batch 830/938] loss_G: 3.428609, loss_D: 0.238773\n",
            "[Epoch 169/200] [Batch 840/938] loss_G: 3.396416, loss_D: 0.190729\n",
            "[Epoch 169/200] [Batch 850/938] loss_G: 2.954837, loss_D: 0.167593\n",
            "[Epoch 169/200] [Batch 860/938] loss_G: 3.201113, loss_D: 0.162030\n",
            "[Epoch 169/200] [Batch 870/938] loss_G: 3.201473, loss_D: 0.211156\n",
            "[Epoch 169/200] [Batch 880/938] loss_G: 2.800062, loss_D: 0.212343\n",
            "[Epoch 169/200] [Batch 890/938] loss_G: 3.321057, loss_D: 0.186562\n",
            "[Epoch 169/200] [Batch 900/938] loss_G: 3.172544, loss_D: 0.201395\n",
            "[Epoch 169/200] [Batch 910/938] loss_G: 3.200791, loss_D: 0.164161\n",
            "[Epoch 169/200] [Batch 920/938] loss_G: 3.340211, loss_D: 0.253373\n",
            "[Epoch 169/200] [Batch 930/938] loss_G: 3.291869, loss_D: 0.294755\n",
            "[Epoch 170/200] [Batch 0/938] loss_G: 2.922746, loss_D: 0.233933\n",
            "[Epoch 170/200] [Batch 10/938] loss_G: 3.255640, loss_D: 0.211383\n",
            "[Epoch 170/200] [Batch 20/938] loss_G: 3.251829, loss_D: 0.243506\n",
            "[Epoch 170/200] [Batch 30/938] loss_G: 3.122003, loss_D: 0.182916\n",
            "[Epoch 170/200] [Batch 40/938] loss_G: 3.199462, loss_D: 0.213664\n",
            "[Epoch 170/200] [Batch 50/938] loss_G: 3.296084, loss_D: 0.271495\n",
            "[Epoch 170/200] [Batch 60/938] loss_G: 3.150062, loss_D: 0.204462\n",
            "[Epoch 170/200] [Batch 70/938] loss_G: 3.150488, loss_D: 0.288382\n",
            "[Epoch 170/200] [Batch 80/938] loss_G: 3.249637, loss_D: 0.175816\n",
            "[Epoch 170/200] [Batch 90/938] loss_G: 3.395275, loss_D: 0.196490\n",
            "[Epoch 170/200] [Batch 100/938] loss_G: 3.107101, loss_D: 0.294771\n",
            "[Epoch 170/200] [Batch 110/938] loss_G: 2.888910, loss_D: 0.202810\n",
            "[Epoch 170/200] [Batch 120/938] loss_G: 3.244666, loss_D: 0.186636\n",
            "[Epoch 170/200] [Batch 130/938] loss_G: 3.629376, loss_D: 0.210255\n",
            "[Epoch 170/200] [Batch 140/938] loss_G: 3.083829, loss_D: 0.209101\n",
            "[Epoch 170/200] [Batch 150/938] loss_G: 3.346004, loss_D: 0.193540\n",
            "[Epoch 170/200] [Batch 160/938] loss_G: 3.246244, loss_D: 0.330804\n",
            "[Epoch 170/200] [Batch 170/938] loss_G: 3.133586, loss_D: 0.237592\n",
            "[Epoch 170/200] [Batch 180/938] loss_G: 3.030828, loss_D: 0.228411\n",
            "[Epoch 170/200] [Batch 190/938] loss_G: 3.256742, loss_D: 0.214183\n",
            "[Epoch 170/200] [Batch 200/938] loss_G: 3.165587, loss_D: 0.203155\n",
            "[Epoch 170/200] [Batch 210/938] loss_G: 3.224416, loss_D: 0.148371\n",
            "[Epoch 170/200] [Batch 220/938] loss_G: 3.200121, loss_D: 0.230008\n",
            "[Epoch 170/200] [Batch 230/938] loss_G: 3.060829, loss_D: 0.244957\n",
            "[Epoch 170/200] [Batch 240/938] loss_G: 3.395890, loss_D: 0.158871\n",
            "[Epoch 170/200] [Batch 250/938] loss_G: 3.229460, loss_D: 0.163746\n",
            "[Epoch 170/200] [Batch 260/938] loss_G: 3.246894, loss_D: 0.198695\n",
            "[Epoch 170/200] [Batch 270/938] loss_G: 2.984390, loss_D: 0.238100\n",
            "[Epoch 170/200] [Batch 280/938] loss_G: 3.429496, loss_D: 0.193444\n",
            "[Epoch 170/200] [Batch 290/938] loss_G: 3.048840, loss_D: 0.274553\n",
            "[Epoch 170/200] [Batch 300/938] loss_G: 3.041769, loss_D: 0.193561\n",
            "[Epoch 170/200] [Batch 310/938] loss_G: 3.319970, loss_D: 0.176275\n",
            "[Epoch 170/200] [Batch 320/938] loss_G: 2.935172, loss_D: 0.245773\n",
            "[Epoch 170/200] [Batch 330/938] loss_G: 3.344639, loss_D: 0.184101\n",
            "[Epoch 170/200] [Batch 340/938] loss_G: 3.418112, loss_D: 0.187977\n",
            "[Epoch 170/200] [Batch 350/938] loss_G: 3.207623, loss_D: 0.155429\n",
            "[Epoch 170/200] [Batch 360/938] loss_G: 2.951600, loss_D: 0.259775\n",
            "[Epoch 170/200] [Batch 370/938] loss_G: 3.190675, loss_D: 0.160450\n",
            "[Epoch 170/200] [Batch 380/938] loss_G: 3.641750, loss_D: 0.203897\n",
            "[Epoch 170/200] [Batch 390/938] loss_G: 3.088467, loss_D: 0.258851\n",
            "[Epoch 170/200] [Batch 400/938] loss_G: 3.007294, loss_D: 0.186817\n",
            "[Epoch 170/200] [Batch 410/938] loss_G: 2.710981, loss_D: 0.206026\n",
            "[Epoch 170/200] [Batch 420/938] loss_G: 3.102266, loss_D: 0.221409\n",
            "[Epoch 170/200] [Batch 430/938] loss_G: 3.313825, loss_D: 0.176334\n",
            "[Epoch 170/200] [Batch 440/938] loss_G: 3.218098, loss_D: 0.144949\n",
            "[Epoch 170/200] [Batch 450/938] loss_G: 3.058883, loss_D: 0.153201\n",
            "[Epoch 170/200] [Batch 460/938] loss_G: 3.212172, loss_D: 0.176676\n",
            "[Epoch 170/200] [Batch 470/938] loss_G: 3.097453, loss_D: 0.215921\n",
            "[Epoch 170/200] [Batch 480/938] loss_G: 3.256199, loss_D: 0.239760\n",
            "[Epoch 170/200] [Batch 490/938] loss_G: 3.391075, loss_D: 0.184715\n",
            "[Epoch 170/200] [Batch 500/938] loss_G: 2.686670, loss_D: 0.277481\n",
            "[Epoch 170/200] [Batch 510/938] loss_G: 2.767400, loss_D: 0.166788\n",
            "[Epoch 170/200] [Batch 520/938] loss_G: 3.104727, loss_D: 0.208368\n",
            "[Epoch 170/200] [Batch 530/938] loss_G: 3.365630, loss_D: 0.230128\n",
            "[Epoch 170/200] [Batch 540/938] loss_G: 3.088054, loss_D: 0.239266\n",
            "[Epoch 170/200] [Batch 550/938] loss_G: 3.439260, loss_D: 0.183915\n",
            "[Epoch 170/200] [Batch 560/938] loss_G: 3.165051, loss_D: 0.233527\n",
            "[Epoch 170/200] [Batch 570/938] loss_G: 3.177644, loss_D: 0.236277\n",
            "[Epoch 170/200] [Batch 580/938] loss_G: 3.188321, loss_D: 0.152927\n",
            "[Epoch 170/200] [Batch 590/938] loss_G: 3.324667, loss_D: 0.162124\n",
            "[Epoch 170/200] [Batch 600/938] loss_G: 3.054738, loss_D: 0.223871\n",
            "[Epoch 170/200] [Batch 610/938] loss_G: 3.072882, loss_D: 0.203168\n",
            "[Epoch 170/200] [Batch 620/938] loss_G: 2.613037, loss_D: 0.254627\n",
            "[Epoch 170/200] [Batch 630/938] loss_G: 3.004759, loss_D: 0.224074\n",
            "[Epoch 170/200] [Batch 640/938] loss_G: 2.962900, loss_D: 0.183911\n",
            "[Epoch 170/200] [Batch 650/938] loss_G: 3.282699, loss_D: 0.168492\n",
            "[Epoch 170/200] [Batch 660/938] loss_G: 3.177062, loss_D: 0.213930\n",
            "[Epoch 170/200] [Batch 670/938] loss_G: 3.524366, loss_D: 0.182711\n",
            "[Epoch 170/200] [Batch 680/938] loss_G: 3.354320, loss_D: 0.140372\n",
            "[Epoch 170/200] [Batch 690/938] loss_G: 2.945816, loss_D: 0.221527\n",
            "[Epoch 170/200] [Batch 700/938] loss_G: 2.908826, loss_D: 0.203167\n",
            "[Epoch 170/200] [Batch 710/938] loss_G: 3.279618, loss_D: 0.185598\n",
            "[Epoch 170/200] [Batch 720/938] loss_G: 3.333927, loss_D: 0.199226\n",
            "[Epoch 170/200] [Batch 730/938] loss_G: 3.154176, loss_D: 0.185212\n",
            "[Epoch 170/200] [Batch 740/938] loss_G: 3.662818, loss_D: 0.143452\n",
            "[Epoch 170/200] [Batch 750/938] loss_G: 3.384186, loss_D: 0.197881\n",
            "[Epoch 170/200] [Batch 760/938] loss_G: 2.798306, loss_D: 0.199610\n",
            "[Epoch 170/200] [Batch 770/938] loss_G: 3.266810, loss_D: 0.237548\n",
            "[Epoch 170/200] [Batch 780/938] loss_G: 2.768065, loss_D: 0.276681\n",
            "[Epoch 170/200] [Batch 790/938] loss_G: 3.392203, loss_D: 0.227647\n",
            "[Epoch 170/200] [Batch 800/938] loss_G: 2.850251, loss_D: 0.235557\n",
            "[Epoch 170/200] [Batch 810/938] loss_G: 2.833416, loss_D: 0.240893\n",
            "[Epoch 170/200] [Batch 820/938] loss_G: 2.981356, loss_D: 0.153330\n",
            "[Epoch 170/200] [Batch 830/938] loss_G: 3.081853, loss_D: 0.195743\n",
            "[Epoch 170/200] [Batch 840/938] loss_G: 3.211014, loss_D: 0.167732\n",
            "[Epoch 170/200] [Batch 850/938] loss_G: 2.896867, loss_D: 0.149854\n",
            "[Epoch 170/200] [Batch 860/938] loss_G: 2.801431, loss_D: 0.261091\n",
            "[Epoch 170/200] [Batch 870/938] loss_G: 3.056740, loss_D: 0.161472\n",
            "[Epoch 170/200] [Batch 880/938] loss_G: 3.349178, loss_D: 0.221797\n",
            "[Epoch 170/200] [Batch 890/938] loss_G: 3.196899, loss_D: 0.277528\n",
            "[Epoch 170/200] [Batch 900/938] loss_G: 3.300185, loss_D: 0.172606\n",
            "[Epoch 170/200] [Batch 910/938] loss_G: 3.296627, loss_D: 0.231120\n",
            "[Epoch 170/200] [Batch 920/938] loss_G: 2.788688, loss_D: 0.182820\n",
            "[Epoch 170/200] [Batch 930/938] loss_G: 3.218535, loss_D: 0.264668\n",
            "[Epoch 171/200] [Batch 0/938] loss_G: 2.888136, loss_D: 0.181930\n",
            "[Epoch 171/200] [Batch 10/938] loss_G: 3.266414, loss_D: 0.159908\n",
            "[Epoch 171/200] [Batch 20/938] loss_G: 3.343535, loss_D: 0.093347\n",
            "[Epoch 171/200] [Batch 30/938] loss_G: 3.179315, loss_D: 0.241519\n",
            "[Epoch 171/200] [Batch 40/938] loss_G: 3.198316, loss_D: 0.230577\n",
            "[Epoch 171/200] [Batch 50/938] loss_G: 3.068186, loss_D: 0.117123\n",
            "[Epoch 171/200] [Batch 60/938] loss_G: 3.456863, loss_D: 0.189741\n",
            "[Epoch 171/200] [Batch 70/938] loss_G: 3.244890, loss_D: 0.166001\n",
            "[Epoch 171/200] [Batch 80/938] loss_G: 3.534061, loss_D: 0.106041\n",
            "[Epoch 171/200] [Batch 90/938] loss_G: 3.143982, loss_D: 0.200932\n",
            "[Epoch 171/200] [Batch 100/938] loss_G: 3.192906, loss_D: 0.118284\n",
            "[Epoch 171/200] [Batch 110/938] loss_G: 3.299552, loss_D: 0.200856\n",
            "[Epoch 171/200] [Batch 120/938] loss_G: 3.200722, loss_D: 0.130916\n",
            "[Epoch 171/200] [Batch 130/938] loss_G: 2.842707, loss_D: 0.297655\n",
            "[Epoch 171/200] [Batch 140/938] loss_G: 3.212275, loss_D: 0.377618\n",
            "[Epoch 171/200] [Batch 150/938] loss_G: 3.037009, loss_D: 0.224830\n",
            "[Epoch 171/200] [Batch 160/938] loss_G: 3.305787, loss_D: 0.206310\n",
            "[Epoch 171/200] [Batch 170/938] loss_G: 3.244244, loss_D: 0.165969\n",
            "[Epoch 171/200] [Batch 180/938] loss_G: 3.263713, loss_D: 0.202643\n",
            "[Epoch 171/200] [Batch 190/938] loss_G: 2.944015, loss_D: 0.175327\n",
            "[Epoch 171/200] [Batch 200/938] loss_G: 3.415866, loss_D: 0.236384\n",
            "[Epoch 171/200] [Batch 210/938] loss_G: 2.979431, loss_D: 0.236986\n",
            "[Epoch 171/200] [Batch 220/938] loss_G: 3.111186, loss_D: 0.205738\n",
            "[Epoch 171/200] [Batch 230/938] loss_G: 3.243330, loss_D: 0.127610\n",
            "[Epoch 171/200] [Batch 240/938] loss_G: 3.087632, loss_D: 0.197480\n",
            "[Epoch 171/200] [Batch 250/938] loss_G: 3.195824, loss_D: 0.262698\n",
            "[Epoch 171/200] [Batch 260/938] loss_G: 2.959363, loss_D: 0.148209\n",
            "[Epoch 171/200] [Batch 270/938] loss_G: 3.152158, loss_D: 0.267955\n",
            "[Epoch 171/200] [Batch 280/938] loss_G: 3.248686, loss_D: 0.153482\n",
            "[Epoch 171/200] [Batch 290/938] loss_G: 3.453351, loss_D: 0.228855\n",
            "[Epoch 171/200] [Batch 300/938] loss_G: 3.199179, loss_D: 0.276114\n",
            "[Epoch 171/200] [Batch 310/938] loss_G: 3.134729, loss_D: 0.311731\n",
            "[Epoch 171/200] [Batch 320/938] loss_G: 3.426651, loss_D: 0.222563\n",
            "[Epoch 171/200] [Batch 330/938] loss_G: 3.520387, loss_D: 0.188651\n",
            "[Epoch 171/200] [Batch 340/938] loss_G: 3.124299, loss_D: 0.197465\n",
            "[Epoch 171/200] [Batch 350/938] loss_G: 3.108389, loss_D: 0.142524\n",
            "[Epoch 171/200] [Batch 360/938] loss_G: 3.240296, loss_D: 0.179891\n",
            "[Epoch 171/200] [Batch 370/938] loss_G: 3.532168, loss_D: 0.201516\n",
            "[Epoch 171/200] [Batch 380/938] loss_G: 3.330023, loss_D: 0.236410\n",
            "[Epoch 171/200] [Batch 390/938] loss_G: 3.131299, loss_D: 0.191864\n",
            "[Epoch 171/200] [Batch 400/938] loss_G: 3.096936, loss_D: 0.171988\n",
            "[Epoch 171/200] [Batch 410/938] loss_G: 3.122754, loss_D: 0.114200\n",
            "[Epoch 171/200] [Batch 420/938] loss_G: 3.735403, loss_D: 0.115733\n",
            "[Epoch 171/200] [Batch 430/938] loss_G: 3.202415, loss_D: 0.193412\n",
            "[Epoch 171/200] [Batch 440/938] loss_G: 3.112090, loss_D: 0.172479\n",
            "[Epoch 171/200] [Batch 450/938] loss_G: 3.242831, loss_D: 0.250058\n",
            "[Epoch 171/200] [Batch 460/938] loss_G: 3.206203, loss_D: 0.185650\n",
            "[Epoch 171/200] [Batch 470/938] loss_G: 3.214605, loss_D: 0.119485\n",
            "[Epoch 171/200] [Batch 480/938] loss_G: 2.885628, loss_D: 0.267130\n",
            "[Epoch 171/200] [Batch 490/938] loss_G: 3.066041, loss_D: 0.247248\n",
            "[Epoch 171/200] [Batch 500/938] loss_G: 3.310723, loss_D: 0.187719\n",
            "[Epoch 171/200] [Batch 510/938] loss_G: 2.841189, loss_D: 0.191092\n",
            "[Epoch 171/200] [Batch 520/938] loss_G: 3.305388, loss_D: 0.193228\n",
            "[Epoch 171/200] [Batch 530/938] loss_G: 3.231465, loss_D: 0.203890\n",
            "[Epoch 171/200] [Batch 540/938] loss_G: 3.142207, loss_D: 0.202989\n",
            "[Epoch 171/200] [Batch 550/938] loss_G: 3.429072, loss_D: 0.157678\n",
            "[Epoch 171/200] [Batch 560/938] loss_G: 3.060767, loss_D: 0.172198\n",
            "[Epoch 171/200] [Batch 570/938] loss_G: 2.774210, loss_D: 0.255154\n",
            "[Epoch 171/200] [Batch 580/938] loss_G: 3.574489, loss_D: 0.139545\n",
            "[Epoch 171/200] [Batch 590/938] loss_G: 3.155183, loss_D: 0.205430\n",
            "[Epoch 171/200] [Batch 600/938] loss_G: 3.013499, loss_D: 0.188205\n",
            "[Epoch 171/200] [Batch 610/938] loss_G: 3.562176, loss_D: 0.191784\n",
            "[Epoch 171/200] [Batch 620/938] loss_G: 3.312031, loss_D: 0.272001\n",
            "[Epoch 171/200] [Batch 630/938] loss_G: 3.365274, loss_D: 0.211272\n",
            "[Epoch 171/200] [Batch 640/938] loss_G: 3.463130, loss_D: 0.255276\n",
            "[Epoch 171/200] [Batch 650/938] loss_G: 3.179625, loss_D: 0.337916\n",
            "[Epoch 171/200] [Batch 660/938] loss_G: 3.244356, loss_D: 0.198223\n",
            "[Epoch 171/200] [Batch 670/938] loss_G: 2.831496, loss_D: 0.316691\n",
            "[Epoch 171/200] [Batch 680/938] loss_G: 3.188053, loss_D: 0.218560\n",
            "[Epoch 171/200] [Batch 690/938] loss_G: 3.122963, loss_D: 0.110842\n",
            "[Epoch 171/200] [Batch 700/938] loss_G: 3.136585, loss_D: 0.170736\n",
            "[Epoch 171/200] [Batch 710/938] loss_G: 2.672577, loss_D: 0.189248\n",
            "[Epoch 171/200] [Batch 720/938] loss_G: 3.265087, loss_D: 0.261807\n",
            "[Epoch 171/200] [Batch 730/938] loss_G: 3.044914, loss_D: 0.142925\n",
            "[Epoch 171/200] [Batch 740/938] loss_G: 3.202456, loss_D: 0.144009\n",
            "[Epoch 171/200] [Batch 750/938] loss_G: 3.119696, loss_D: 0.181333\n",
            "[Epoch 171/200] [Batch 760/938] loss_G: 2.899193, loss_D: 0.157937\n",
            "[Epoch 171/200] [Batch 770/938] loss_G: 3.180950, loss_D: 0.284722\n",
            "[Epoch 171/200] [Batch 780/938] loss_G: 3.044908, loss_D: 0.242056\n",
            "[Epoch 171/200] [Batch 790/938] loss_G: 3.122742, loss_D: 0.288531\n",
            "[Epoch 171/200] [Batch 800/938] loss_G: 3.385229, loss_D: 0.167283\n",
            "[Epoch 171/200] [Batch 810/938] loss_G: 2.920640, loss_D: 0.354827\n",
            "[Epoch 171/200] [Batch 820/938] loss_G: 2.760515, loss_D: 0.287083\n",
            "[Epoch 171/200] [Batch 830/938] loss_G: 3.681037, loss_D: 0.190423\n",
            "[Epoch 171/200] [Batch 840/938] loss_G: 3.117069, loss_D: 0.123588\n",
            "[Epoch 171/200] [Batch 850/938] loss_G: 2.855283, loss_D: 0.195022\n",
            "[Epoch 171/200] [Batch 860/938] loss_G: 3.172027, loss_D: 0.152517\n",
            "[Epoch 171/200] [Batch 870/938] loss_G: 3.081551, loss_D: 0.237454\n",
            "[Epoch 171/200] [Batch 880/938] loss_G: 3.078767, loss_D: 0.144713\n",
            "[Epoch 171/200] [Batch 890/938] loss_G: 3.286318, loss_D: 0.244405\n",
            "[Epoch 171/200] [Batch 900/938] loss_G: 3.045044, loss_D: 0.211651\n",
            "[Epoch 171/200] [Batch 910/938] loss_G: 3.341656, loss_D: 0.126070\n",
            "[Epoch 171/200] [Batch 920/938] loss_G: 2.811949, loss_D: 0.129006\n",
            "[Epoch 171/200] [Batch 930/938] loss_G: 2.462542, loss_D: 0.323044\n",
            "[Epoch 172/200] [Batch 0/938] loss_G: 3.132416, loss_D: 0.194342\n",
            "[Epoch 172/200] [Batch 10/938] loss_G: 3.041240, loss_D: 0.163589\n",
            "[Epoch 172/200] [Batch 20/938] loss_G: 3.162944, loss_D: 0.229762\n",
            "[Epoch 172/200] [Batch 30/938] loss_G: 3.147745, loss_D: 0.170433\n",
            "[Epoch 172/200] [Batch 40/938] loss_G: 3.122440, loss_D: 0.318582\n",
            "[Epoch 172/200] [Batch 50/938] loss_G: 3.082154, loss_D: 0.232144\n",
            "[Epoch 172/200] [Batch 60/938] loss_G: 3.256499, loss_D: 0.210832\n",
            "[Epoch 172/200] [Batch 70/938] loss_G: 3.068013, loss_D: 0.263183\n",
            "[Epoch 172/200] [Batch 80/938] loss_G: 3.261601, loss_D: 0.226561\n",
            "[Epoch 172/200] [Batch 90/938] loss_G: 3.340455, loss_D: 0.126164\n",
            "[Epoch 172/200] [Batch 100/938] loss_G: 3.496884, loss_D: 0.144705\n",
            "[Epoch 172/200] [Batch 110/938] loss_G: 3.198026, loss_D: 0.230245\n",
            "[Epoch 172/200] [Batch 120/938] loss_G: 2.960588, loss_D: 0.178862\n",
            "[Epoch 172/200] [Batch 130/938] loss_G: 3.151114, loss_D: 0.247654\n",
            "[Epoch 172/200] [Batch 140/938] loss_G: 2.939373, loss_D: 0.143477\n",
            "[Epoch 172/200] [Batch 150/938] loss_G: 2.958037, loss_D: 0.222228\n",
            "[Epoch 172/200] [Batch 160/938] loss_G: 3.262605, loss_D: 0.168677\n",
            "[Epoch 172/200] [Batch 170/938] loss_G: 3.376785, loss_D: 0.212128\n",
            "[Epoch 172/200] [Batch 180/938] loss_G: 3.189864, loss_D: 0.145963\n",
            "[Epoch 172/200] [Batch 190/938] loss_G: 3.311781, loss_D: 0.136394\n",
            "[Epoch 172/200] [Batch 200/938] loss_G: 3.452144, loss_D: 0.131009\n",
            "[Epoch 172/200] [Batch 210/938] loss_G: 3.468271, loss_D: 0.294331\n",
            "[Epoch 172/200] [Batch 220/938] loss_G: 3.202573, loss_D: 0.230332\n",
            "[Epoch 172/200] [Batch 230/938] loss_G: 3.095212, loss_D: 0.203297\n",
            "[Epoch 172/200] [Batch 240/938] loss_G: 3.319422, loss_D: 0.214415\n",
            "[Epoch 172/200] [Batch 250/938] loss_G: 3.208709, loss_D: 0.205128\n",
            "[Epoch 172/200] [Batch 260/938] loss_G: 3.560842, loss_D: 0.189982\n",
            "[Epoch 172/200] [Batch 270/938] loss_G: 3.381333, loss_D: 0.268837\n",
            "[Epoch 172/200] [Batch 280/938] loss_G: 3.126556, loss_D: 0.199585\n",
            "[Epoch 172/200] [Batch 290/938] loss_G: 2.938375, loss_D: 0.212374\n",
            "[Epoch 172/200] [Batch 300/938] loss_G: 3.579247, loss_D: 0.163207\n",
            "[Epoch 172/200] [Batch 310/938] loss_G: 3.242724, loss_D: 0.277739\n",
            "[Epoch 172/200] [Batch 320/938] loss_G: 3.677584, loss_D: 0.312392\n",
            "[Epoch 172/200] [Batch 330/938] loss_G: 3.096602, loss_D: 0.153322\n",
            "[Epoch 172/200] [Batch 340/938] loss_G: 3.077158, loss_D: 0.205932\n",
            "[Epoch 172/200] [Batch 350/938] loss_G: 2.689190, loss_D: 0.274062\n",
            "[Epoch 172/200] [Batch 360/938] loss_G: 3.086466, loss_D: 0.233787\n",
            "[Epoch 172/200] [Batch 370/938] loss_G: 3.319359, loss_D: 0.116971\n",
            "[Epoch 172/200] [Batch 380/938] loss_G: 2.984416, loss_D: 0.271105\n",
            "[Epoch 172/200] [Batch 390/938] loss_G: 3.264461, loss_D: 0.186445\n",
            "[Epoch 172/200] [Batch 400/938] loss_G: 2.800575, loss_D: 0.162215\n",
            "[Epoch 172/200] [Batch 410/938] loss_G: 3.812600, loss_D: 0.115467\n",
            "[Epoch 172/200] [Batch 420/938] loss_G: 3.363972, loss_D: 0.190004\n",
            "[Epoch 172/200] [Batch 430/938] loss_G: 3.156711, loss_D: 0.178562\n",
            "[Epoch 172/200] [Batch 440/938] loss_G: 3.235317, loss_D: 0.211187\n",
            "[Epoch 172/200] [Batch 450/938] loss_G: 3.249081, loss_D: 0.159303\n",
            "[Epoch 172/200] [Batch 460/938] loss_G: 2.728625, loss_D: 0.213403\n",
            "[Epoch 172/200] [Batch 470/938] loss_G: 3.351446, loss_D: 0.164488\n",
            "[Epoch 172/200] [Batch 480/938] loss_G: 3.132219, loss_D: 0.252467\n",
            "[Epoch 172/200] [Batch 490/938] loss_G: 3.023215, loss_D: 0.168092\n",
            "[Epoch 172/200] [Batch 500/938] loss_G: 3.281131, loss_D: 0.140563\n",
            "[Epoch 172/200] [Batch 510/938] loss_G: 3.125091, loss_D: 0.303270\n",
            "[Epoch 172/200] [Batch 520/938] loss_G: 2.978881, loss_D: 0.211730\n",
            "[Epoch 172/200] [Batch 530/938] loss_G: 2.981568, loss_D: 0.189767\n",
            "[Epoch 172/200] [Batch 540/938] loss_G: 3.185344, loss_D: 0.209485\n",
            "[Epoch 172/200] [Batch 550/938] loss_G: 3.432482, loss_D: 0.142936\n",
            "[Epoch 172/200] [Batch 560/938] loss_G: 3.195912, loss_D: 0.260323\n",
            "[Epoch 172/200] [Batch 570/938] loss_G: 3.137327, loss_D: 0.204693\n",
            "[Epoch 172/200] [Batch 580/938] loss_G: 3.339259, loss_D: 0.173176\n",
            "[Epoch 172/200] [Batch 590/938] loss_G: 3.041229, loss_D: 0.194045\n",
            "[Epoch 172/200] [Batch 600/938] loss_G: 3.659560, loss_D: 0.157669\n",
            "[Epoch 172/200] [Batch 610/938] loss_G: 3.287691, loss_D: 0.311959\n",
            "[Epoch 172/200] [Batch 620/938] loss_G: 3.328953, loss_D: 0.237132\n",
            "[Epoch 172/200] [Batch 630/938] loss_G: 3.141057, loss_D: 0.217145\n",
            "[Epoch 172/200] [Batch 640/938] loss_G: 3.563085, loss_D: 0.202152\n",
            "[Epoch 172/200] [Batch 650/938] loss_G: 3.451302, loss_D: 0.203445\n",
            "[Epoch 172/200] [Batch 660/938] loss_G: 3.272500, loss_D: 0.169485\n",
            "[Epoch 172/200] [Batch 670/938] loss_G: 3.376938, loss_D: 0.163577\n",
            "[Epoch 172/200] [Batch 680/938] loss_G: 2.846867, loss_D: 0.233769\n",
            "[Epoch 172/200] [Batch 690/938] loss_G: 3.179022, loss_D: 0.145385\n",
            "[Epoch 172/200] [Batch 700/938] loss_G: 3.227904, loss_D: 0.291907\n",
            "[Epoch 172/200] [Batch 710/938] loss_G: 2.946259, loss_D: 0.116706\n",
            "[Epoch 172/200] [Batch 720/938] loss_G: 2.850844, loss_D: 0.239794\n",
            "[Epoch 172/200] [Batch 730/938] loss_G: 3.296038, loss_D: 0.138775\n",
            "[Epoch 172/200] [Batch 740/938] loss_G: 3.205959, loss_D: 0.213593\n",
            "[Epoch 172/200] [Batch 750/938] loss_G: 3.041326, loss_D: 0.186199\n",
            "[Epoch 172/200] [Batch 760/938] loss_G: 3.087234, loss_D: 0.185828\n",
            "[Epoch 172/200] [Batch 770/938] loss_G: 3.018720, loss_D: 0.132045\n",
            "[Epoch 172/200] [Batch 780/938] loss_G: 3.068677, loss_D: 0.177184\n",
            "[Epoch 172/200] [Batch 790/938] loss_G: 3.263798, loss_D: 0.203418\n",
            "[Epoch 172/200] [Batch 800/938] loss_G: 3.039741, loss_D: 0.152822\n",
            "[Epoch 172/200] [Batch 810/938] loss_G: 3.470554, loss_D: 0.262148\n",
            "[Epoch 172/200] [Batch 820/938] loss_G: 3.300778, loss_D: 0.268037\n",
            "[Epoch 172/200] [Batch 830/938] loss_G: 2.975100, loss_D: 0.209859\n",
            "[Epoch 172/200] [Batch 840/938] loss_G: 3.415117, loss_D: 0.265091\n",
            "[Epoch 172/200] [Batch 850/938] loss_G: 2.785898, loss_D: 0.254149\n",
            "[Epoch 172/200] [Batch 860/938] loss_G: 2.810399, loss_D: 0.276779\n",
            "[Epoch 172/200] [Batch 870/938] loss_G: 3.374615, loss_D: 0.296483\n",
            "[Epoch 172/200] [Batch 880/938] loss_G: 2.869971, loss_D: 0.306149\n",
            "[Epoch 172/200] [Batch 890/938] loss_G: 3.267150, loss_D: 0.141463\n",
            "[Epoch 172/200] [Batch 900/938] loss_G: 3.413611, loss_D: 0.132941\n",
            "[Epoch 172/200] [Batch 910/938] loss_G: 2.939005, loss_D: 0.184244\n",
            "[Epoch 172/200] [Batch 920/938] loss_G: 3.438991, loss_D: 0.218203\n",
            "[Epoch 172/200] [Batch 930/938] loss_G: 3.195766, loss_D: 0.161487\n",
            "[Epoch 173/200] [Batch 0/938] loss_G: 3.248092, loss_D: 0.258417\n",
            "[Epoch 173/200] [Batch 10/938] loss_G: 3.388434, loss_D: 0.249919\n",
            "[Epoch 173/200] [Batch 20/938] loss_G: 2.632794, loss_D: 0.194739\n",
            "[Epoch 173/200] [Batch 30/938] loss_G: 3.150653, loss_D: 0.166338\n",
            "[Epoch 173/200] [Batch 40/938] loss_G: 3.126455, loss_D: 0.262669\n",
            "[Epoch 173/200] [Batch 50/938] loss_G: 3.336313, loss_D: 0.180246\n",
            "[Epoch 173/200] [Batch 60/938] loss_G: 2.982421, loss_D: 0.193123\n",
            "[Epoch 173/200] [Batch 70/938] loss_G: 3.203042, loss_D: 0.314447\n",
            "[Epoch 173/200] [Batch 80/938] loss_G: 2.984811, loss_D: 0.211793\n",
            "[Epoch 173/200] [Batch 90/938] loss_G: 2.820575, loss_D: 0.219109\n",
            "[Epoch 173/200] [Batch 100/938] loss_G: 3.150275, loss_D: 0.171021\n",
            "[Epoch 173/200] [Batch 110/938] loss_G: 2.970660, loss_D: 0.207962\n",
            "[Epoch 173/200] [Batch 120/938] loss_G: 3.030009, loss_D: 0.159724\n",
            "[Epoch 173/200] [Batch 130/938] loss_G: 3.145589, loss_D: 0.155729\n",
            "[Epoch 173/200] [Batch 140/938] loss_G: 3.085674, loss_D: 0.210727\n",
            "[Epoch 173/200] [Batch 150/938] loss_G: 3.149498, loss_D: 0.149676\n",
            "[Epoch 173/200] [Batch 160/938] loss_G: 3.229636, loss_D: 0.193056\n",
            "[Epoch 173/200] [Batch 170/938] loss_G: 2.855532, loss_D: 0.255062\n",
            "[Epoch 173/200] [Batch 180/938] loss_G: 3.154728, loss_D: 0.239505\n",
            "[Epoch 173/200] [Batch 190/938] loss_G: 3.093789, loss_D: 0.170580\n",
            "[Epoch 173/200] [Batch 200/938] loss_G: 3.389067, loss_D: 0.138775\n",
            "[Epoch 173/200] [Batch 210/938] loss_G: 3.336984, loss_D: 0.267013\n",
            "[Epoch 173/200] [Batch 220/938] loss_G: 2.883964, loss_D: 0.250863\n",
            "[Epoch 173/200] [Batch 230/938] loss_G: 3.496228, loss_D: 0.138096\n",
            "[Epoch 173/200] [Batch 240/938] loss_G: 3.384389, loss_D: 0.115777\n",
            "[Epoch 173/200] [Batch 250/938] loss_G: 3.337435, loss_D: 0.182752\n",
            "[Epoch 173/200] [Batch 260/938] loss_G: 3.212111, loss_D: 0.083922\n",
            "[Epoch 173/200] [Batch 270/938] loss_G: 3.185511, loss_D: 0.236416\n",
            "[Epoch 173/200] [Batch 280/938] loss_G: 3.122044, loss_D: 0.307998\n",
            "[Epoch 173/200] [Batch 290/938] loss_G: 3.072478, loss_D: 0.203433\n",
            "[Epoch 173/200] [Batch 300/938] loss_G: 3.049705, loss_D: 0.295645\n",
            "[Epoch 173/200] [Batch 310/938] loss_G: 3.232821, loss_D: 0.282643\n",
            "[Epoch 173/200] [Batch 320/938] loss_G: 3.217657, loss_D: 0.219419\n",
            "[Epoch 173/200] [Batch 330/938] loss_G: 2.843110, loss_D: 0.279454\n",
            "[Epoch 173/200] [Batch 340/938] loss_G: 3.311336, loss_D: 0.110100\n",
            "[Epoch 173/200] [Batch 350/938] loss_G: 3.216805, loss_D: 0.204063\n",
            "[Epoch 173/200] [Batch 360/938] loss_G: 3.317678, loss_D: 0.194968\n",
            "[Epoch 173/200] [Batch 370/938] loss_G: 3.425262, loss_D: 0.135188\n",
            "[Epoch 173/200] [Batch 380/938] loss_G: 3.405696, loss_D: 0.168794\n",
            "[Epoch 173/200] [Batch 390/938] loss_G: 3.117930, loss_D: 0.316666\n",
            "[Epoch 173/200] [Batch 400/938] loss_G: 2.744797, loss_D: 0.253784\n",
            "[Epoch 173/200] [Batch 410/938] loss_G: 2.901509, loss_D: 0.207477\n",
            "[Epoch 173/200] [Batch 420/938] loss_G: 3.082016, loss_D: 0.219557\n",
            "[Epoch 173/200] [Batch 430/938] loss_G: 3.236485, loss_D: 0.214261\n",
            "[Epoch 173/200] [Batch 440/938] loss_G: 3.446584, loss_D: 0.113573\n",
            "[Epoch 173/200] [Batch 450/938] loss_G: 2.877611, loss_D: 0.208403\n",
            "[Epoch 173/200] [Batch 460/938] loss_G: 3.031866, loss_D: 0.130886\n",
            "[Epoch 173/200] [Batch 470/938] loss_G: 3.045134, loss_D: 0.233393\n",
            "[Epoch 173/200] [Batch 480/938] loss_G: 3.215112, loss_D: 0.192229\n",
            "[Epoch 173/200] [Batch 490/938] loss_G: 2.855555, loss_D: 0.259793\n",
            "[Epoch 173/200] [Batch 500/938] loss_G: 3.158010, loss_D: 0.266392\n",
            "[Epoch 173/200] [Batch 510/938] loss_G: 2.948652, loss_D: 0.274179\n",
            "[Epoch 173/200] [Batch 520/938] loss_G: 3.023247, loss_D: 0.222641\n",
            "[Epoch 173/200] [Batch 530/938] loss_G: 3.682975, loss_D: 0.235945\n",
            "[Epoch 173/200] [Batch 540/938] loss_G: 3.540126, loss_D: 0.299702\n",
            "[Epoch 173/200] [Batch 550/938] loss_G: 3.190221, loss_D: 0.158451\n",
            "[Epoch 173/200] [Batch 560/938] loss_G: 3.200558, loss_D: 0.189130\n",
            "[Epoch 173/200] [Batch 570/938] loss_G: 3.315833, loss_D: 0.293054\n",
            "[Epoch 173/200] [Batch 580/938] loss_G: 3.038706, loss_D: 0.211234\n",
            "[Epoch 173/200] [Batch 590/938] loss_G: 3.327067, loss_D: 0.303506\n",
            "[Epoch 173/200] [Batch 600/938] loss_G: 2.855059, loss_D: 0.282105\n",
            "[Epoch 173/200] [Batch 610/938] loss_G: 3.138989, loss_D: 0.222189\n",
            "[Epoch 173/200] [Batch 620/938] loss_G: 3.058896, loss_D: 0.185036\n",
            "[Epoch 173/200] [Batch 630/938] loss_G: 2.950720, loss_D: 0.288433\n",
            "[Epoch 173/200] [Batch 640/938] loss_G: 2.968311, loss_D: 0.156371\n",
            "[Epoch 173/200] [Batch 650/938] loss_G: 2.860427, loss_D: 0.164041\n",
            "[Epoch 173/200] [Batch 660/938] loss_G: 3.580034, loss_D: 0.163461\n",
            "[Epoch 173/200] [Batch 670/938] loss_G: 2.828280, loss_D: 0.384018\n",
            "[Epoch 173/200] [Batch 680/938] loss_G: 2.806412, loss_D: 0.145688\n",
            "[Epoch 173/200] [Batch 690/938] loss_G: 3.557057, loss_D: 0.187824\n",
            "[Epoch 173/200] [Batch 700/938] loss_G: 3.104329, loss_D: 0.278205\n",
            "[Epoch 173/200] [Batch 710/938] loss_G: 3.038151, loss_D: 0.252855\n",
            "[Epoch 173/200] [Batch 720/938] loss_G: 2.939974, loss_D: 0.165988\n",
            "[Epoch 173/200] [Batch 730/938] loss_G: 3.005285, loss_D: 0.218687\n",
            "[Epoch 173/200] [Batch 740/938] loss_G: 3.156174, loss_D: 0.143930\n",
            "[Epoch 173/200] [Batch 750/938] loss_G: 3.232437, loss_D: 0.252859\n",
            "[Epoch 173/200] [Batch 760/938] loss_G: 2.865453, loss_D: 0.246714\n",
            "[Epoch 173/200] [Batch 770/938] loss_G: 2.678102, loss_D: 0.191803\n",
            "[Epoch 173/200] [Batch 780/938] loss_G: 3.172833, loss_D: 0.182311\n",
            "[Epoch 173/200] [Batch 790/938] loss_G: 3.366475, loss_D: 0.149607\n",
            "[Epoch 173/200] [Batch 800/938] loss_G: 2.830391, loss_D: 0.158932\n",
            "[Epoch 173/200] [Batch 810/938] loss_G: 3.087894, loss_D: 0.179435\n",
            "[Epoch 173/200] [Batch 820/938] loss_G: 2.948414, loss_D: 0.193906\n",
            "[Epoch 173/200] [Batch 830/938] loss_G: 3.279325, loss_D: 0.182184\n",
            "[Epoch 173/200] [Batch 840/938] loss_G: 3.429464, loss_D: 0.290210\n",
            "[Epoch 173/200] [Batch 850/938] loss_G: 3.126037, loss_D: 0.191976\n",
            "[Epoch 173/200] [Batch 860/938] loss_G: 3.591246, loss_D: 0.159450\n",
            "[Epoch 173/200] [Batch 870/938] loss_G: 2.880191, loss_D: 0.168347\n",
            "[Epoch 173/200] [Batch 880/938] loss_G: 3.496010, loss_D: 0.181505\n",
            "[Epoch 173/200] [Batch 890/938] loss_G: 3.034407, loss_D: 0.166907\n",
            "[Epoch 173/200] [Batch 900/938] loss_G: 2.978965, loss_D: 0.220492\n",
            "[Epoch 173/200] [Batch 910/938] loss_G: 3.312666, loss_D: 0.219592\n",
            "[Epoch 173/200] [Batch 920/938] loss_G: 3.471111, loss_D: 0.228569\n",
            "[Epoch 173/200] [Batch 930/938] loss_G: 2.998481, loss_D: 0.223681\n",
            "[Epoch 174/200] [Batch 0/938] loss_G: 3.055111, loss_D: 0.183472\n",
            "[Epoch 174/200] [Batch 10/938] loss_G: 3.439814, loss_D: 0.228565\n",
            "[Epoch 174/200] [Batch 20/938] loss_G: 3.176273, loss_D: 0.219978\n",
            "[Epoch 174/200] [Batch 30/938] loss_G: 3.185221, loss_D: 0.251259\n",
            "[Epoch 174/200] [Batch 40/938] loss_G: 3.476130, loss_D: 0.204191\n",
            "[Epoch 174/200] [Batch 50/938] loss_G: 3.230046, loss_D: 0.196977\n",
            "[Epoch 174/200] [Batch 60/938] loss_G: 3.513643, loss_D: 0.115005\n",
            "[Epoch 174/200] [Batch 70/938] loss_G: 3.108786, loss_D: 0.237541\n",
            "[Epoch 174/200] [Batch 80/938] loss_G: 3.313486, loss_D: 0.135991\n",
            "[Epoch 174/200] [Batch 90/938] loss_G: 3.498269, loss_D: 0.190862\n",
            "[Epoch 174/200] [Batch 100/938] loss_G: 2.949706, loss_D: 0.249638\n",
            "[Epoch 174/200] [Batch 110/938] loss_G: 3.315291, loss_D: 0.189160\n",
            "[Epoch 174/200] [Batch 120/938] loss_G: 3.115248, loss_D: 0.167509\n",
            "[Epoch 174/200] [Batch 130/938] loss_G: 3.404111, loss_D: 0.202347\n",
            "[Epoch 174/200] [Batch 140/938] loss_G: 3.182676, loss_D: 0.205279\n",
            "[Epoch 174/200] [Batch 150/938] loss_G: 3.121162, loss_D: 0.267330\n",
            "[Epoch 174/200] [Batch 160/938] loss_G: 3.314734, loss_D: 0.240565\n",
            "[Epoch 174/200] [Batch 170/938] loss_G: 3.291237, loss_D: 0.220362\n",
            "[Epoch 174/200] [Batch 180/938] loss_G: 3.332200, loss_D: 0.136380\n",
            "[Epoch 174/200] [Batch 190/938] loss_G: 3.476336, loss_D: 0.259310\n",
            "[Epoch 174/200] [Batch 200/938] loss_G: 3.133923, loss_D: 0.235489\n",
            "[Epoch 174/200] [Batch 210/938] loss_G: 3.090134, loss_D: 0.232424\n",
            "[Epoch 174/200] [Batch 220/938] loss_G: 3.074531, loss_D: 0.126937\n",
            "[Epoch 174/200] [Batch 230/938] loss_G: 3.231328, loss_D: 0.282223\n",
            "[Epoch 174/200] [Batch 240/938] loss_G: 2.951823, loss_D: 0.208092\n",
            "[Epoch 174/200] [Batch 250/938] loss_G: 3.302499, loss_D: 0.208466\n",
            "[Epoch 174/200] [Batch 260/938] loss_G: 3.000758, loss_D: 0.150874\n",
            "[Epoch 174/200] [Batch 270/938] loss_G: 3.310101, loss_D: 0.216528\n",
            "[Epoch 174/200] [Batch 280/938] loss_G: 3.174763, loss_D: 0.218202\n",
            "[Epoch 174/200] [Batch 290/938] loss_G: 3.178172, loss_D: 0.230545\n",
            "[Epoch 174/200] [Batch 300/938] loss_G: 3.376801, loss_D: 0.146078\n",
            "[Epoch 174/200] [Batch 310/938] loss_G: 3.189459, loss_D: 0.247552\n",
            "[Epoch 174/200] [Batch 320/938] loss_G: 3.023690, loss_D: 0.210646\n",
            "[Epoch 174/200] [Batch 330/938] loss_G: 3.217487, loss_D: 0.170216\n",
            "[Epoch 174/200] [Batch 340/938] loss_G: 3.237147, loss_D: 0.234619\n",
            "[Epoch 174/200] [Batch 350/938] loss_G: 3.047300, loss_D: 0.246258\n",
            "[Epoch 174/200] [Batch 360/938] loss_G: 3.044867, loss_D: 0.249953\n",
            "[Epoch 174/200] [Batch 370/938] loss_G: 3.269351, loss_D: 0.170128\n",
            "[Epoch 174/200] [Batch 380/938] loss_G: 3.258219, loss_D: 0.272647\n",
            "[Epoch 174/200] [Batch 390/938] loss_G: 3.046819, loss_D: 0.133862\n",
            "[Epoch 174/200] [Batch 400/938] loss_G: 3.659150, loss_D: 0.225837\n",
            "[Epoch 174/200] [Batch 410/938] loss_G: 3.184334, loss_D: 0.244155\n",
            "[Epoch 174/200] [Batch 420/938] loss_G: 3.026599, loss_D: 0.173335\n",
            "[Epoch 174/200] [Batch 430/938] loss_G: 3.231335, loss_D: 0.287765\n",
            "[Epoch 174/200] [Batch 440/938] loss_G: 3.196343, loss_D: 0.190131\n",
            "[Epoch 174/200] [Batch 450/938] loss_G: 3.467024, loss_D: 0.147540\n",
            "[Epoch 174/200] [Batch 460/938] loss_G: 3.356647, loss_D: 0.224855\n",
            "[Epoch 174/200] [Batch 470/938] loss_G: 3.019973, loss_D: 0.221275\n",
            "[Epoch 174/200] [Batch 480/938] loss_G: 3.118764, loss_D: 0.212950\n",
            "[Epoch 174/200] [Batch 490/938] loss_G: 3.124255, loss_D: 0.163285\n",
            "[Epoch 174/200] [Batch 500/938] loss_G: 2.752764, loss_D: 0.255462\n",
            "[Epoch 174/200] [Batch 510/938] loss_G: 2.799029, loss_D: 0.253873\n",
            "[Epoch 174/200] [Batch 520/938] loss_G: 3.239861, loss_D: 0.237600\n",
            "[Epoch 174/200] [Batch 530/938] loss_G: 3.334503, loss_D: 0.253788\n",
            "[Epoch 174/200] [Batch 540/938] loss_G: 2.791198, loss_D: 0.185494\n",
            "[Epoch 174/200] [Batch 550/938] loss_G: 2.879717, loss_D: 0.155748\n",
            "[Epoch 174/200] [Batch 560/938] loss_G: 2.981380, loss_D: 0.203138\n",
            "[Epoch 174/200] [Batch 570/938] loss_G: 2.879620, loss_D: 0.215697\n",
            "[Epoch 174/200] [Batch 580/938] loss_G: 3.086689, loss_D: 0.227609\n",
            "[Epoch 174/200] [Batch 590/938] loss_G: 2.822285, loss_D: 0.270263\n",
            "[Epoch 174/200] [Batch 600/938] loss_G: 3.477211, loss_D: 0.145784\n",
            "[Epoch 174/200] [Batch 610/938] loss_G: 3.228441, loss_D: 0.206375\n",
            "[Epoch 174/200] [Batch 620/938] loss_G: 2.873086, loss_D: 0.131525\n",
            "[Epoch 174/200] [Batch 630/938] loss_G: 3.273829, loss_D: 0.191343\n",
            "[Epoch 174/200] [Batch 640/938] loss_G: 3.184684, loss_D: 0.171849\n",
            "[Epoch 174/200] [Batch 650/938] loss_G: 3.205210, loss_D: 0.193990\n",
            "[Epoch 174/200] [Batch 660/938] loss_G: 3.043719, loss_D: 0.205610\n",
            "[Epoch 174/200] [Batch 670/938] loss_G: 3.104118, loss_D: 0.246516\n",
            "[Epoch 174/200] [Batch 680/938] loss_G: 3.181461, loss_D: 0.193152\n",
            "[Epoch 174/200] [Batch 690/938] loss_G: 3.391671, loss_D: 0.199691\n",
            "[Epoch 174/200] [Batch 700/938] loss_G: 3.634120, loss_D: 0.189512\n",
            "[Epoch 174/200] [Batch 710/938] loss_G: 3.138001, loss_D: 0.267032\n",
            "[Epoch 174/200] [Batch 720/938] loss_G: 3.015558, loss_D: 0.117209\n",
            "[Epoch 174/200] [Batch 730/938] loss_G: 3.210563, loss_D: 0.189166\n",
            "[Epoch 174/200] [Batch 740/938] loss_G: 2.888360, loss_D: 0.229111\n",
            "[Epoch 174/200] [Batch 750/938] loss_G: 3.382429, loss_D: 0.275162\n",
            "[Epoch 174/200] [Batch 760/938] loss_G: 3.239195, loss_D: 0.286375\n",
            "[Epoch 174/200] [Batch 770/938] loss_G: 3.270619, loss_D: 0.184409\n",
            "[Epoch 174/200] [Batch 780/938] loss_G: 3.363877, loss_D: 0.161709\n",
            "[Epoch 174/200] [Batch 790/938] loss_G: 3.068459, loss_D: 0.210959\n",
            "[Epoch 174/200] [Batch 800/938] loss_G: 3.439926, loss_D: 0.134095\n",
            "[Epoch 174/200] [Batch 810/938] loss_G: 2.905332, loss_D: 0.242574\n",
            "[Epoch 174/200] [Batch 820/938] loss_G: 3.069638, loss_D: 0.201477\n",
            "[Epoch 174/200] [Batch 830/938] loss_G: 2.988767, loss_D: 0.262038\n",
            "[Epoch 174/200] [Batch 840/938] loss_G: 3.075352, loss_D: 0.230976\n",
            "[Epoch 174/200] [Batch 850/938] loss_G: 3.194003, loss_D: 0.219792\n",
            "[Epoch 174/200] [Batch 860/938] loss_G: 3.636448, loss_D: 0.196234\n",
            "[Epoch 174/200] [Batch 870/938] loss_G: 3.570313, loss_D: 0.267971\n",
            "[Epoch 174/200] [Batch 880/938] loss_G: 3.194856, loss_D: 0.131685\n",
            "[Epoch 174/200] [Batch 890/938] loss_G: 3.504644, loss_D: 0.198310\n",
            "[Epoch 174/200] [Batch 900/938] loss_G: 3.302753, loss_D: 0.280160\n",
            "[Epoch 174/200] [Batch 910/938] loss_G: 3.448751, loss_D: 0.142613\n",
            "[Epoch 174/200] [Batch 920/938] loss_G: 2.971087, loss_D: 0.222209\n",
            "[Epoch 174/200] [Batch 930/938] loss_G: 3.204869, loss_D: 0.167931\n",
            "[Epoch 175/200] [Batch 0/938] loss_G: 3.088277, loss_D: 0.249860\n",
            "[Epoch 175/200] [Batch 10/938] loss_G: 3.058366, loss_D: 0.238120\n",
            "[Epoch 175/200] [Batch 20/938] loss_G: 3.531445, loss_D: 0.171561\n",
            "[Epoch 175/200] [Batch 30/938] loss_G: 3.226641, loss_D: 0.291856\n",
            "[Epoch 175/200] [Batch 40/938] loss_G: 3.162077, loss_D: 0.253706\n",
            "[Epoch 175/200] [Batch 50/938] loss_G: 3.231627, loss_D: 0.193069\n",
            "[Epoch 175/200] [Batch 60/938] loss_G: 3.363084, loss_D: 0.153322\n",
            "[Epoch 175/200] [Batch 70/938] loss_G: 3.361834, loss_D: 0.156857\n",
            "[Epoch 175/200] [Batch 80/938] loss_G: 3.348539, loss_D: 0.207482\n",
            "[Epoch 175/200] [Batch 90/938] loss_G: 3.501841, loss_D: 0.166382\n",
            "[Epoch 175/200] [Batch 100/938] loss_G: 3.194911, loss_D: 0.179492\n",
            "[Epoch 175/200] [Batch 110/938] loss_G: 3.350198, loss_D: 0.108637\n",
            "[Epoch 175/200] [Batch 120/938] loss_G: 3.026329, loss_D: 0.183966\n",
            "[Epoch 175/200] [Batch 130/938] loss_G: 2.960612, loss_D: 0.224693\n",
            "[Epoch 175/200] [Batch 140/938] loss_G: 3.411578, loss_D: 0.136105\n",
            "[Epoch 175/200] [Batch 150/938] loss_G: 3.256450, loss_D: 0.155270\n",
            "[Epoch 175/200] [Batch 160/938] loss_G: 3.228829, loss_D: 0.203082\n",
            "[Epoch 175/200] [Batch 170/938] loss_G: 3.192636, loss_D: 0.169509\n",
            "[Epoch 175/200] [Batch 180/938] loss_G: 3.406342, loss_D: 0.158276\n",
            "[Epoch 175/200] [Batch 190/938] loss_G: 3.266718, loss_D: 0.182368\n",
            "[Epoch 175/200] [Batch 200/938] loss_G: 3.161454, loss_D: 0.195102\n",
            "[Epoch 175/200] [Batch 210/938] loss_G: 3.136118, loss_D: 0.183794\n",
            "[Epoch 175/200] [Batch 220/938] loss_G: 3.072325, loss_D: 0.206354\n",
            "[Epoch 175/200] [Batch 230/938] loss_G: 3.070829, loss_D: 0.277147\n",
            "[Epoch 175/200] [Batch 240/938] loss_G: 3.180031, loss_D: 0.137743\n",
            "[Epoch 175/200] [Batch 250/938] loss_G: 3.846748, loss_D: 0.184635\n",
            "[Epoch 175/200] [Batch 260/938] loss_G: 3.181466, loss_D: 0.215142\n",
            "[Epoch 175/200] [Batch 270/938] loss_G: 3.456845, loss_D: 0.223122\n",
            "[Epoch 175/200] [Batch 280/938] loss_G: 3.248290, loss_D: 0.154301\n",
            "[Epoch 175/200] [Batch 290/938] loss_G: 2.374057, loss_D: 0.152674\n",
            "[Epoch 175/200] [Batch 300/938] loss_G: 3.282398, loss_D: 0.227751\n",
            "[Epoch 175/200] [Batch 310/938] loss_G: 2.936919, loss_D: 0.208882\n",
            "[Epoch 175/200] [Batch 320/938] loss_G: 3.381677, loss_D: 0.181699\n",
            "[Epoch 175/200] [Batch 330/938] loss_G: 2.853103, loss_D: 0.255348\n",
            "[Epoch 175/200] [Batch 340/938] loss_G: 2.879153, loss_D: 0.177432\n",
            "[Epoch 175/200] [Batch 350/938] loss_G: 3.003461, loss_D: 0.235898\n",
            "[Epoch 175/200] [Batch 360/938] loss_G: 3.689513, loss_D: 0.162240\n",
            "[Epoch 175/200] [Batch 370/938] loss_G: 3.299459, loss_D: 0.194824\n",
            "[Epoch 175/200] [Batch 380/938] loss_G: 3.117343, loss_D: 0.142188\n",
            "[Epoch 175/200] [Batch 390/938] loss_G: 3.404512, loss_D: 0.300834\n",
            "[Epoch 175/200] [Batch 400/938] loss_G: 3.214552, loss_D: 0.221607\n",
            "[Epoch 175/200] [Batch 410/938] loss_G: 2.749381, loss_D: 0.259643\n",
            "[Epoch 175/200] [Batch 420/938] loss_G: 2.986158, loss_D: 0.197177\n",
            "[Epoch 175/200] [Batch 430/938] loss_G: 2.921911, loss_D: 0.232165\n",
            "[Epoch 175/200] [Batch 440/938] loss_G: 3.692352, loss_D: 0.226463\n",
            "[Epoch 175/200] [Batch 450/938] loss_G: 2.899816, loss_D: 0.157119\n",
            "[Epoch 175/200] [Batch 460/938] loss_G: 3.074568, loss_D: 0.265775\n",
            "[Epoch 175/200] [Batch 470/938] loss_G: 3.772141, loss_D: 0.208920\n",
            "[Epoch 175/200] [Batch 480/938] loss_G: 2.999933, loss_D: 0.148923\n",
            "[Epoch 175/200] [Batch 490/938] loss_G: 2.884186, loss_D: 0.298130\n",
            "[Epoch 175/200] [Batch 500/938] loss_G: 3.161283, loss_D: 0.160036\n",
            "[Epoch 175/200] [Batch 510/938] loss_G: 2.958642, loss_D: 0.222676\n",
            "[Epoch 175/200] [Batch 520/938] loss_G: 3.197428, loss_D: 0.169117\n",
            "[Epoch 175/200] [Batch 530/938] loss_G: 2.928578, loss_D: 0.196765\n",
            "[Epoch 175/200] [Batch 540/938] loss_G: 3.085580, loss_D: 0.141188\n",
            "[Epoch 175/200] [Batch 550/938] loss_G: 3.610133, loss_D: 0.194025\n",
            "[Epoch 175/200] [Batch 560/938] loss_G: 3.298360, loss_D: 0.194657\n",
            "[Epoch 175/200] [Batch 570/938] loss_G: 3.092262, loss_D: 0.187985\n",
            "[Epoch 175/200] [Batch 580/938] loss_G: 3.139380, loss_D: 0.195845\n",
            "[Epoch 175/200] [Batch 590/938] loss_G: 3.319193, loss_D: 0.215248\n",
            "[Epoch 175/200] [Batch 600/938] loss_G: 3.362296, loss_D: 0.183530\n",
            "[Epoch 175/200] [Batch 610/938] loss_G: 3.390157, loss_D: 0.229591\n",
            "[Epoch 175/200] [Batch 620/938] loss_G: 3.068783, loss_D: 0.181451\n",
            "[Epoch 175/200] [Batch 630/938] loss_G: 2.769732, loss_D: 0.157496\n",
            "[Epoch 175/200] [Batch 640/938] loss_G: 3.295342, loss_D: 0.255352\n",
            "[Epoch 175/200] [Batch 650/938] loss_G: 3.446849, loss_D: 0.128281\n",
            "[Epoch 175/200] [Batch 660/938] loss_G: 3.185869, loss_D: 0.213594\n",
            "[Epoch 175/200] [Batch 670/938] loss_G: 3.276491, loss_D: 0.271595\n",
            "[Epoch 175/200] [Batch 680/938] loss_G: 3.462207, loss_D: 0.180026\n",
            "[Epoch 175/200] [Batch 690/938] loss_G: 3.319807, loss_D: 0.179930\n",
            "[Epoch 175/200] [Batch 700/938] loss_G: 3.095550, loss_D: 0.196998\n",
            "[Epoch 175/200] [Batch 710/938] loss_G: 3.351748, loss_D: 0.192377\n",
            "[Epoch 175/200] [Batch 720/938] loss_G: 2.939694, loss_D: 0.253989\n",
            "[Epoch 175/200] [Batch 730/938] loss_G: 3.219140, loss_D: 0.328576\n",
            "[Epoch 175/200] [Batch 740/938] loss_G: 3.490965, loss_D: 0.130114\n",
            "[Epoch 175/200] [Batch 750/938] loss_G: 3.813974, loss_D: 0.280698\n",
            "[Epoch 175/200] [Batch 760/938] loss_G: 3.156234, loss_D: 0.227270\n",
            "[Epoch 175/200] [Batch 770/938] loss_G: 2.627476, loss_D: 0.198608\n",
            "[Epoch 175/200] [Batch 780/938] loss_G: 3.238634, loss_D: 0.308318\n",
            "[Epoch 175/200] [Batch 790/938] loss_G: 2.693888, loss_D: 0.199580\n",
            "[Epoch 175/200] [Batch 800/938] loss_G: 2.830404, loss_D: 0.342098\n",
            "[Epoch 175/200] [Batch 810/938] loss_G: 3.026984, loss_D: 0.241264\n",
            "[Epoch 175/200] [Batch 820/938] loss_G: 2.610360, loss_D: 0.157332\n",
            "[Epoch 175/200] [Batch 830/938] loss_G: 3.131579, loss_D: 0.178067\n",
            "[Epoch 175/200] [Batch 840/938] loss_G: 3.384474, loss_D: 0.142738\n",
            "[Epoch 175/200] [Batch 850/938] loss_G: 3.370963, loss_D: 0.199880\n",
            "[Epoch 175/200] [Batch 860/938] loss_G: 3.421479, loss_D: 0.192902\n",
            "[Epoch 175/200] [Batch 870/938] loss_G: 3.022860, loss_D: 0.193165\n",
            "[Epoch 175/200] [Batch 880/938] loss_G: 3.123235, loss_D: 0.234766\n",
            "[Epoch 175/200] [Batch 890/938] loss_G: 3.304710, loss_D: 0.136515\n",
            "[Epoch 175/200] [Batch 900/938] loss_G: 3.100165, loss_D: 0.244016\n",
            "[Epoch 175/200] [Batch 910/938] loss_G: 2.886446, loss_D: 0.221571\n",
            "[Epoch 175/200] [Batch 920/938] loss_G: 3.235826, loss_D: 0.241040\n",
            "[Epoch 175/200] [Batch 930/938] loss_G: 3.152845, loss_D: 0.145484\n",
            "[Epoch 176/200] [Batch 0/938] loss_G: 3.342592, loss_D: 0.255294\n",
            "[Epoch 176/200] [Batch 10/938] loss_G: 2.979418, loss_D: 0.125573\n",
            "[Epoch 176/200] [Batch 20/938] loss_G: 2.849452, loss_D: 0.286767\n",
            "[Epoch 176/200] [Batch 30/938] loss_G: 2.990614, loss_D: 0.242301\n",
            "[Epoch 176/200] [Batch 40/938] loss_G: 3.167014, loss_D: 0.164969\n",
            "[Epoch 176/200] [Batch 50/938] loss_G: 3.164284, loss_D: 0.214501\n",
            "[Epoch 176/200] [Batch 60/938] loss_G: 3.153126, loss_D: 0.325862\n",
            "[Epoch 176/200] [Batch 70/938] loss_G: 3.709036, loss_D: 0.117393\n",
            "[Epoch 176/200] [Batch 80/938] loss_G: 3.329768, loss_D: 0.129900\n",
            "[Epoch 176/200] [Batch 90/938] loss_G: 3.164578, loss_D: 0.272468\n",
            "[Epoch 176/200] [Batch 100/938] loss_G: 3.118905, loss_D: 0.170656\n",
            "[Epoch 176/200] [Batch 110/938] loss_G: 2.940666, loss_D: 0.226435\n",
            "[Epoch 176/200] [Batch 120/938] loss_G: 3.215937, loss_D: 0.181472\n",
            "[Epoch 176/200] [Batch 130/938] loss_G: 3.051192, loss_D: 0.220171\n",
            "[Epoch 176/200] [Batch 140/938] loss_G: 3.510290, loss_D: 0.193646\n",
            "[Epoch 176/200] [Batch 150/938] loss_G: 3.369550, loss_D: 0.244605\n",
            "[Epoch 176/200] [Batch 160/938] loss_G: 3.074674, loss_D: 0.096579\n",
            "[Epoch 176/200] [Batch 170/938] loss_G: 3.254957, loss_D: 0.215798\n",
            "[Epoch 176/200] [Batch 180/938] loss_G: 3.487955, loss_D: 0.132714\n",
            "[Epoch 176/200] [Batch 190/938] loss_G: 3.358431, loss_D: 0.190584\n",
            "[Epoch 176/200] [Batch 200/938] loss_G: 3.043347, loss_D: 0.242787\n",
            "[Epoch 176/200] [Batch 210/938] loss_G: 3.325504, loss_D: 0.204347\n",
            "[Epoch 176/200] [Batch 220/938] loss_G: 3.195205, loss_D: 0.223255\n",
            "[Epoch 176/200] [Batch 230/938] loss_G: 2.803173, loss_D: 0.234309\n",
            "[Epoch 176/200] [Batch 240/938] loss_G: 2.703502, loss_D: 0.256736\n",
            "[Epoch 176/200] [Batch 250/938] loss_G: 3.285478, loss_D: 0.182305\n",
            "[Epoch 176/200] [Batch 260/938] loss_G: 3.081601, loss_D: 0.265873\n",
            "[Epoch 176/200] [Batch 270/938] loss_G: 3.512223, loss_D: 0.166180\n",
            "[Epoch 176/200] [Batch 280/938] loss_G: 3.153217, loss_D: 0.157683\n",
            "[Epoch 176/200] [Batch 290/938] loss_G: 3.148654, loss_D: 0.095523\n",
            "[Epoch 176/200] [Batch 300/938] loss_G: 3.307147, loss_D: 0.122996\n",
            "[Epoch 176/200] [Batch 310/938] loss_G: 2.556252, loss_D: 0.176447\n",
            "[Epoch 176/200] [Batch 320/938] loss_G: 2.732247, loss_D: 0.282340\n",
            "[Epoch 176/200] [Batch 330/938] loss_G: 3.152955, loss_D: 0.202373\n",
            "[Epoch 176/200] [Batch 340/938] loss_G: 3.121176, loss_D: 0.232723\n",
            "[Epoch 176/200] [Batch 350/938] loss_G: 3.390191, loss_D: 0.203353\n",
            "[Epoch 176/200] [Batch 360/938] loss_G: 3.108599, loss_D: 0.184772\n",
            "[Epoch 176/200] [Batch 370/938] loss_G: 3.385337, loss_D: 0.105874\n",
            "[Epoch 176/200] [Batch 380/938] loss_G: 3.589873, loss_D: 0.198757\n",
            "[Epoch 176/200] [Batch 390/938] loss_G: 3.302627, loss_D: 0.205090\n",
            "[Epoch 176/200] [Batch 400/938] loss_G: 2.978601, loss_D: 0.311972\n",
            "[Epoch 176/200] [Batch 410/938] loss_G: 3.212733, loss_D: 0.163127\n",
            "[Epoch 176/200] [Batch 420/938] loss_G: 2.904456, loss_D: 0.175565\n",
            "[Epoch 176/200] [Batch 430/938] loss_G: 3.296588, loss_D: 0.209343\n",
            "[Epoch 176/200] [Batch 440/938] loss_G: 3.339059, loss_D: 0.217744\n",
            "[Epoch 176/200] [Batch 450/938] loss_G: 2.948836, loss_D: 0.206310\n",
            "[Epoch 176/200] [Batch 460/938] loss_G: 3.098444, loss_D: 0.139384\n",
            "[Epoch 176/200] [Batch 470/938] loss_G: 3.140128, loss_D: 0.237253\n",
            "[Epoch 176/200] [Batch 480/938] loss_G: 3.194277, loss_D: 0.259326\n",
            "[Epoch 176/200] [Batch 490/938] loss_G: 3.371570, loss_D: 0.187045\n",
            "[Epoch 176/200] [Batch 500/938] loss_G: 3.265918, loss_D: 0.178784\n",
            "[Epoch 176/200] [Batch 510/938] loss_G: 2.865247, loss_D: 0.185145\n",
            "[Epoch 176/200] [Batch 520/938] loss_G: 3.381251, loss_D: 0.241826\n",
            "[Epoch 176/200] [Batch 530/938] loss_G: 2.889489, loss_D: 0.215082\n",
            "[Epoch 176/200] [Batch 540/938] loss_G: 3.316698, loss_D: 0.114608\n",
            "[Epoch 176/200] [Batch 550/938] loss_G: 3.203196, loss_D: 0.133019\n",
            "[Epoch 176/200] [Batch 560/938] loss_G: 3.990545, loss_D: 0.085772\n",
            "[Epoch 176/200] [Batch 570/938] loss_G: 3.228269, loss_D: 0.165458\n",
            "[Epoch 176/200] [Batch 580/938] loss_G: 2.863003, loss_D: 0.207318\n",
            "[Epoch 176/200] [Batch 590/938] loss_G: 3.473155, loss_D: 0.212888\n",
            "[Epoch 176/200] [Batch 600/938] loss_G: 3.222016, loss_D: 0.180858\n",
            "[Epoch 176/200] [Batch 610/938] loss_G: 3.159992, loss_D: 0.195608\n",
            "[Epoch 176/200] [Batch 620/938] loss_G: 2.878789, loss_D: 0.270655\n",
            "[Epoch 176/200] [Batch 630/938] loss_G: 3.657019, loss_D: 0.151971\n",
            "[Epoch 176/200] [Batch 640/938] loss_G: 3.367017, loss_D: 0.215973\n",
            "[Epoch 176/200] [Batch 650/938] loss_G: 3.084598, loss_D: 0.186605\n",
            "[Epoch 176/200] [Batch 660/938] loss_G: 3.140210, loss_D: 0.152686\n",
            "[Epoch 176/200] [Batch 670/938] loss_G: 3.024300, loss_D: 0.202474\n",
            "[Epoch 176/200] [Batch 680/938] loss_G: 2.928102, loss_D: 0.197081\n",
            "[Epoch 176/200] [Batch 690/938] loss_G: 3.382084, loss_D: 0.211234\n",
            "[Epoch 176/200] [Batch 700/938] loss_G: 3.249634, loss_D: 0.218489\n",
            "[Epoch 176/200] [Batch 710/938] loss_G: 3.048967, loss_D: 0.135228\n",
            "[Epoch 176/200] [Batch 720/938] loss_G: 3.186461, loss_D: 0.219015\n",
            "[Epoch 176/200] [Batch 730/938] loss_G: 3.331861, loss_D: 0.202315\n",
            "[Epoch 176/200] [Batch 740/938] loss_G: 3.403551, loss_D: 0.251221\n",
            "[Epoch 176/200] [Batch 750/938] loss_G: 3.012602, loss_D: 0.260507\n",
            "[Epoch 176/200] [Batch 760/938] loss_G: 3.204337, loss_D: 0.186342\n",
            "[Epoch 176/200] [Batch 770/938] loss_G: 3.479467, loss_D: 0.196227\n",
            "[Epoch 176/200] [Batch 780/938] loss_G: 3.418271, loss_D: 0.242549\n",
            "[Epoch 176/200] [Batch 790/938] loss_G: 2.916312, loss_D: 0.151957\n",
            "[Epoch 176/200] [Batch 800/938] loss_G: 3.378134, loss_D: 0.154030\n",
            "[Epoch 176/200] [Batch 810/938] loss_G: 3.474415, loss_D: 0.276340\n",
            "[Epoch 176/200] [Batch 820/938] loss_G: 3.055524, loss_D: 0.364201\n",
            "[Epoch 176/200] [Batch 830/938] loss_G: 3.279041, loss_D: 0.185103\n",
            "[Epoch 176/200] [Batch 840/938] loss_G: 3.286895, loss_D: 0.202554\n",
            "[Epoch 176/200] [Batch 850/938] loss_G: 3.373629, loss_D: 0.175285\n",
            "[Epoch 176/200] [Batch 860/938] loss_G: 3.003045, loss_D: 0.282111\n",
            "[Epoch 176/200] [Batch 870/938] loss_G: 3.366149, loss_D: 0.163048\n",
            "[Epoch 176/200] [Batch 880/938] loss_G: 3.373291, loss_D: 0.239614\n",
            "[Epoch 176/200] [Batch 890/938] loss_G: 3.108603, loss_D: 0.273843\n",
            "[Epoch 176/200] [Batch 900/938] loss_G: 3.433569, loss_D: 0.211025\n",
            "[Epoch 176/200] [Batch 910/938] loss_G: 3.260976, loss_D: 0.189256\n",
            "[Epoch 176/200] [Batch 920/938] loss_G: 3.513625, loss_D: 0.136880\n",
            "[Epoch 176/200] [Batch 930/938] loss_G: 3.208976, loss_D: 0.202085\n",
            "[Epoch 177/200] [Batch 0/938] loss_G: 2.884447, loss_D: 0.173892\n",
            "[Epoch 177/200] [Batch 10/938] loss_G: 3.006334, loss_D: 0.163256\n",
            "[Epoch 177/200] [Batch 20/938] loss_G: 3.203124, loss_D: 0.192766\n",
            "[Epoch 177/200] [Batch 30/938] loss_G: 3.125053, loss_D: 0.220595\n",
            "[Epoch 177/200] [Batch 40/938] loss_G: 3.170732, loss_D: 0.248149\n",
            "[Epoch 177/200] [Batch 50/938] loss_G: 3.146186, loss_D: 0.246114\n",
            "[Epoch 177/200] [Batch 60/938] loss_G: 3.393370, loss_D: 0.253922\n",
            "[Epoch 177/200] [Batch 70/938] loss_G: 3.439352, loss_D: 0.222633\n",
            "[Epoch 177/200] [Batch 80/938] loss_G: 3.380871, loss_D: 0.151429\n",
            "[Epoch 177/200] [Batch 90/938] loss_G: 3.268796, loss_D: 0.208460\n",
            "[Epoch 177/200] [Batch 100/938] loss_G: 3.015842, loss_D: 0.186153\n",
            "[Epoch 177/200] [Batch 110/938] loss_G: 3.097990, loss_D: 0.211932\n",
            "[Epoch 177/200] [Batch 120/938] loss_G: 3.115930, loss_D: 0.270318\n",
            "[Epoch 177/200] [Batch 130/938] loss_G: 3.067189, loss_D: 0.251138\n",
            "[Epoch 177/200] [Batch 140/938] loss_G: 3.537682, loss_D: 0.199196\n",
            "[Epoch 177/200] [Batch 150/938] loss_G: 3.089121, loss_D: 0.334363\n",
            "[Epoch 177/200] [Batch 160/938] loss_G: 3.267927, loss_D: 0.190932\n",
            "[Epoch 177/200] [Batch 170/938] loss_G: 2.961444, loss_D: 0.314215\n",
            "[Epoch 177/200] [Batch 180/938] loss_G: 3.149407, loss_D: 0.274804\n",
            "[Epoch 177/200] [Batch 190/938] loss_G: 3.432580, loss_D: 0.242562\n",
            "[Epoch 177/200] [Batch 200/938] loss_G: 3.293815, loss_D: 0.199786\n",
            "[Epoch 177/200] [Batch 210/938] loss_G: 2.710069, loss_D: 0.229991\n",
            "[Epoch 177/200] [Batch 220/938] loss_G: 3.457843, loss_D: 0.214374\n",
            "[Epoch 177/200] [Batch 230/938] loss_G: 3.456352, loss_D: 0.218620\n",
            "[Epoch 177/200] [Batch 240/938] loss_G: 3.222001, loss_D: 0.181814\n",
            "[Epoch 177/200] [Batch 250/938] loss_G: 3.762935, loss_D: 0.152692\n",
            "[Epoch 177/200] [Batch 260/938] loss_G: 3.065097, loss_D: 0.189429\n",
            "[Epoch 177/200] [Batch 270/938] loss_G: 3.082850, loss_D: 0.245145\n",
            "[Epoch 177/200] [Batch 280/938] loss_G: 3.008097, loss_D: 0.177781\n",
            "[Epoch 177/200] [Batch 290/938] loss_G: 2.836722, loss_D: 0.133725\n",
            "[Epoch 177/200] [Batch 300/938] loss_G: 3.169275, loss_D: 0.135087\n",
            "[Epoch 177/200] [Batch 310/938] loss_G: 3.100413, loss_D: 0.155711\n",
            "[Epoch 177/200] [Batch 320/938] loss_G: 3.399656, loss_D: 0.181149\n",
            "[Epoch 177/200] [Batch 330/938] loss_G: 3.342710, loss_D: 0.173878\n",
            "[Epoch 177/200] [Batch 340/938] loss_G: 2.934947, loss_D: 0.204375\n",
            "[Epoch 177/200] [Batch 350/938] loss_G: 2.716824, loss_D: 0.217088\n",
            "[Epoch 177/200] [Batch 360/938] loss_G: 3.331636, loss_D: 0.253712\n",
            "[Epoch 177/200] [Batch 370/938] loss_G: 3.046222, loss_D: 0.223075\n",
            "[Epoch 177/200] [Batch 380/938] loss_G: 2.963963, loss_D: 0.221725\n",
            "[Epoch 177/200] [Batch 390/938] loss_G: 3.373173, loss_D: 0.204723\n",
            "[Epoch 177/200] [Batch 400/938] loss_G: 3.026324, loss_D: 0.167755\n",
            "[Epoch 177/200] [Batch 410/938] loss_G: 3.161679, loss_D: 0.175112\n",
            "[Epoch 177/200] [Batch 420/938] loss_G: 2.940758, loss_D: 0.211572\n",
            "[Epoch 177/200] [Batch 430/938] loss_G: 3.226475, loss_D: 0.161384\n",
            "[Epoch 177/200] [Batch 440/938] loss_G: 3.584207, loss_D: 0.293435\n",
            "[Epoch 177/200] [Batch 450/938] loss_G: 2.919136, loss_D: 0.258463\n",
            "[Epoch 177/200] [Batch 460/938] loss_G: 2.707567, loss_D: 0.204774\n",
            "[Epoch 177/200] [Batch 470/938] loss_G: 3.392329, loss_D: 0.354329\n",
            "[Epoch 177/200] [Batch 480/938] loss_G: 3.137477, loss_D: 0.214692\n",
            "[Epoch 177/200] [Batch 490/938] loss_G: 3.129552, loss_D: 0.200804\n",
            "[Epoch 177/200] [Batch 500/938] loss_G: 2.828250, loss_D: 0.257711\n",
            "[Epoch 177/200] [Batch 510/938] loss_G: 3.179429, loss_D: 0.149825\n",
            "[Epoch 177/200] [Batch 520/938] loss_G: 3.054884, loss_D: 0.153534\n",
            "[Epoch 177/200] [Batch 530/938] loss_G: 3.142213, loss_D: 0.225752\n",
            "[Epoch 177/200] [Batch 540/938] loss_G: 3.163891, loss_D: 0.209346\n",
            "[Epoch 177/200] [Batch 550/938] loss_G: 2.980659, loss_D: 0.247814\n",
            "[Epoch 177/200] [Batch 560/938] loss_G: 3.550149, loss_D: 0.206889\n",
            "[Epoch 177/200] [Batch 570/938] loss_G: 2.796722, loss_D: 0.180480\n",
            "[Epoch 177/200] [Batch 580/938] loss_G: 2.619001, loss_D: 0.200326\n",
            "[Epoch 177/200] [Batch 590/938] loss_G: 3.095414, loss_D: 0.220962\n",
            "[Epoch 177/200] [Batch 600/938] loss_G: 2.845942, loss_D: 0.235224\n",
            "[Epoch 177/200] [Batch 610/938] loss_G: 3.206672, loss_D: 0.330565\n",
            "[Epoch 177/200] [Batch 620/938] loss_G: 3.167733, loss_D: 0.138802\n",
            "[Epoch 177/200] [Batch 630/938] loss_G: 3.034506, loss_D: 0.211100\n",
            "[Epoch 177/200] [Batch 640/938] loss_G: 2.826695, loss_D: 0.195722\n",
            "[Epoch 177/200] [Batch 650/938] loss_G: 3.299242, loss_D: 0.157615\n",
            "[Epoch 177/200] [Batch 660/938] loss_G: 3.260235, loss_D: 0.233876\n",
            "[Epoch 177/200] [Batch 670/938] loss_G: 2.965303, loss_D: 0.207141\n",
            "[Epoch 177/200] [Batch 680/938] loss_G: 3.108559, loss_D: 0.256881\n",
            "[Epoch 177/200] [Batch 690/938] loss_G: 3.236534, loss_D: 0.133011\n",
            "[Epoch 177/200] [Batch 700/938] loss_G: 3.098233, loss_D: 0.238384\n",
            "[Epoch 177/200] [Batch 710/938] loss_G: 2.983509, loss_D: 0.211572\n",
            "[Epoch 177/200] [Batch 720/938] loss_G: 2.783829, loss_D: 0.276776\n",
            "[Epoch 177/200] [Batch 730/938] loss_G: 2.596909, loss_D: 0.164637\n",
            "[Epoch 177/200] [Batch 740/938] loss_G: 2.756084, loss_D: 0.315657\n",
            "[Epoch 177/200] [Batch 750/938] loss_G: 3.607935, loss_D: 0.207616\n",
            "[Epoch 177/200] [Batch 760/938] loss_G: 2.936965, loss_D: 0.181127\n",
            "[Epoch 177/200] [Batch 770/938] loss_G: 3.220173, loss_D: 0.191407\n",
            "[Epoch 177/200] [Batch 780/938] loss_G: 3.068730, loss_D: 0.154596\n",
            "[Epoch 177/200] [Batch 790/938] loss_G: 3.642554, loss_D: 0.161317\n",
            "[Epoch 177/200] [Batch 800/938] loss_G: 3.148007, loss_D: 0.204230\n",
            "[Epoch 177/200] [Batch 810/938] loss_G: 3.195064, loss_D: 0.219635\n",
            "[Epoch 177/200] [Batch 820/938] loss_G: 3.324409, loss_D: 0.154921\n",
            "[Epoch 177/200] [Batch 830/938] loss_G: 3.219514, loss_D: 0.298123\n",
            "[Epoch 177/200] [Batch 840/938] loss_G: 3.298920, loss_D: 0.225123\n",
            "[Epoch 177/200] [Batch 850/938] loss_G: 3.161740, loss_D: 0.235457\n",
            "[Epoch 177/200] [Batch 860/938] loss_G: 3.054981, loss_D: 0.201255\n",
            "[Epoch 177/200] [Batch 870/938] loss_G: 3.248498, loss_D: 0.119977\n",
            "[Epoch 177/200] [Batch 880/938] loss_G: 2.946611, loss_D: 0.223770\n",
            "[Epoch 177/200] [Batch 890/938] loss_G: 3.152527, loss_D: 0.219372\n",
            "[Epoch 177/200] [Batch 900/938] loss_G: 2.658278, loss_D: 0.230160\n",
            "[Epoch 177/200] [Batch 910/938] loss_G: 3.010236, loss_D: 0.117689\n",
            "[Epoch 177/200] [Batch 920/938] loss_G: 3.111746, loss_D: 0.228365\n",
            "[Epoch 177/200] [Batch 930/938] loss_G: 3.253588, loss_D: 0.132949\n",
            "[Epoch 178/200] [Batch 0/938] loss_G: 3.001420, loss_D: 0.215064\n",
            "[Epoch 178/200] [Batch 10/938] loss_G: 3.073727, loss_D: 0.168041\n",
            "[Epoch 178/200] [Batch 20/938] loss_G: 3.280748, loss_D: 0.193785\n",
            "[Epoch 178/200] [Batch 30/938] loss_G: 2.962858, loss_D: 0.113581\n",
            "[Epoch 178/200] [Batch 40/938] loss_G: 3.039239, loss_D: 0.235149\n",
            "[Epoch 178/200] [Batch 50/938] loss_G: 3.551751, loss_D: 0.183988\n",
            "[Epoch 178/200] [Batch 60/938] loss_G: 3.102520, loss_D: 0.254650\n",
            "[Epoch 178/200] [Batch 70/938] loss_G: 2.948917, loss_D: 0.247549\n",
            "[Epoch 178/200] [Batch 80/938] loss_G: 3.191664, loss_D: 0.212174\n",
            "[Epoch 178/200] [Batch 90/938] loss_G: 3.421206, loss_D: 0.188978\n",
            "[Epoch 178/200] [Batch 100/938] loss_G: 3.323085, loss_D: 0.169984\n",
            "[Epoch 178/200] [Batch 110/938] loss_G: 3.230098, loss_D: 0.201360\n",
            "[Epoch 178/200] [Batch 120/938] loss_G: 3.053367, loss_D: 0.218991\n",
            "[Epoch 178/200] [Batch 130/938] loss_G: 3.326999, loss_D: 0.217481\n",
            "[Epoch 178/200] [Batch 140/938] loss_G: 2.878986, loss_D: 0.141120\n",
            "[Epoch 178/200] [Batch 150/938] loss_G: 2.934999, loss_D: 0.210831\n",
            "[Epoch 178/200] [Batch 160/938] loss_G: 3.128347, loss_D: 0.163509\n",
            "[Epoch 178/200] [Batch 170/938] loss_G: 3.158905, loss_D: 0.219296\n",
            "[Epoch 178/200] [Batch 180/938] loss_G: 3.375804, loss_D: 0.296606\n",
            "[Epoch 178/200] [Batch 190/938] loss_G: 3.388413, loss_D: 0.141591\n",
            "[Epoch 178/200] [Batch 200/938] loss_G: 2.810255, loss_D: 0.149815\n",
            "[Epoch 178/200] [Batch 210/938] loss_G: 2.669581, loss_D: 0.213341\n",
            "[Epoch 178/200] [Batch 220/938] loss_G: 3.439510, loss_D: 0.200998\n",
            "[Epoch 178/200] [Batch 230/938] loss_G: 2.934988, loss_D: 0.202988\n",
            "[Epoch 178/200] [Batch 240/938] loss_G: 3.486077, loss_D: 0.180382\n",
            "[Epoch 178/200] [Batch 250/938] loss_G: 2.864048, loss_D: 0.146560\n",
            "[Epoch 178/200] [Batch 260/938] loss_G: 3.680460, loss_D: 0.179108\n",
            "[Epoch 178/200] [Batch 270/938] loss_G: 3.080788, loss_D: 0.271418\n",
            "[Epoch 178/200] [Batch 280/938] loss_G: 2.971162, loss_D: 0.239361\n",
            "[Epoch 178/200] [Batch 290/938] loss_G: 2.949886, loss_D: 0.215137\n",
            "[Epoch 178/200] [Batch 300/938] loss_G: 3.186598, loss_D: 0.173143\n",
            "[Epoch 178/200] [Batch 310/938] loss_G: 3.018021, loss_D: 0.177432\n",
            "[Epoch 178/200] [Batch 320/938] loss_G: 3.111201, loss_D: 0.182368\n",
            "[Epoch 178/200] [Batch 330/938] loss_G: 3.395107, loss_D: 0.216084\n",
            "[Epoch 178/200] [Batch 340/938] loss_G: 2.976050, loss_D: 0.159438\n",
            "[Epoch 178/200] [Batch 350/938] loss_G: 3.330453, loss_D: 0.216371\n",
            "[Epoch 178/200] [Batch 360/938] loss_G: 3.520088, loss_D: 0.177110\n",
            "[Epoch 178/200] [Batch 370/938] loss_G: 3.098897, loss_D: 0.180361\n",
            "[Epoch 178/200] [Batch 380/938] loss_G: 3.140628, loss_D: 0.222164\n",
            "[Epoch 178/200] [Batch 390/938] loss_G: 3.609527, loss_D: 0.254231\n",
            "[Epoch 178/200] [Batch 400/938] loss_G: 3.243681, loss_D: 0.178719\n",
            "[Epoch 178/200] [Batch 410/938] loss_G: 3.026320, loss_D: 0.212989\n",
            "[Epoch 178/200] [Batch 420/938] loss_G: 3.448269, loss_D: 0.203290\n",
            "[Epoch 178/200] [Batch 430/938] loss_G: 3.049526, loss_D: 0.169561\n",
            "[Epoch 178/200] [Batch 440/938] loss_G: 3.157188, loss_D: 0.204137\n",
            "[Epoch 178/200] [Batch 450/938] loss_G: 3.474010, loss_D: 0.179900\n",
            "[Epoch 178/200] [Batch 460/938] loss_G: 2.910605, loss_D: 0.238952\n",
            "[Epoch 178/200] [Batch 470/938] loss_G: 3.113003, loss_D: 0.294856\n",
            "[Epoch 178/200] [Batch 480/938] loss_G: 3.175287, loss_D: 0.129050\n",
            "[Epoch 178/200] [Batch 490/938] loss_G: 2.632793, loss_D: 0.229907\n",
            "[Epoch 178/200] [Batch 500/938] loss_G: 3.196088, loss_D: 0.195020\n",
            "[Epoch 178/200] [Batch 510/938] loss_G: 3.504217, loss_D: 0.139503\n",
            "[Epoch 178/200] [Batch 520/938] loss_G: 2.942724, loss_D: 0.317795\n",
            "[Epoch 178/200] [Batch 530/938] loss_G: 3.344630, loss_D: 0.116000\n",
            "[Epoch 178/200] [Batch 540/938] loss_G: 3.257160, loss_D: 0.147499\n",
            "[Epoch 178/200] [Batch 550/938] loss_G: 3.148147, loss_D: 0.249404\n",
            "[Epoch 178/200] [Batch 560/938] loss_G: 3.244743, loss_D: 0.236250\n",
            "[Epoch 178/200] [Batch 570/938] loss_G: 3.247968, loss_D: 0.234208\n",
            "[Epoch 178/200] [Batch 580/938] loss_G: 3.492100, loss_D: 0.172595\n",
            "[Epoch 178/200] [Batch 590/938] loss_G: 3.168038, loss_D: 0.310120\n",
            "[Epoch 178/200] [Batch 600/938] loss_G: 2.797911, loss_D: 0.222462\n",
            "[Epoch 178/200] [Batch 610/938] loss_G: 3.206038, loss_D: 0.141746\n",
            "[Epoch 178/200] [Batch 620/938] loss_G: 3.212072, loss_D: 0.308542\n",
            "[Epoch 178/200] [Batch 630/938] loss_G: 2.786832, loss_D: 0.212051\n",
            "[Epoch 178/200] [Batch 640/938] loss_G: 3.111431, loss_D: 0.158203\n",
            "[Epoch 178/200] [Batch 650/938] loss_G: 2.979713, loss_D: 0.151064\n",
            "[Epoch 178/200] [Batch 660/938] loss_G: 2.768502, loss_D: 0.227150\n",
            "[Epoch 178/200] [Batch 670/938] loss_G: 3.339306, loss_D: 0.222698\n",
            "[Epoch 178/200] [Batch 680/938] loss_G: 2.722617, loss_D: 0.223809\n",
            "[Epoch 178/200] [Batch 690/938] loss_G: 2.999128, loss_D: 0.235832\n",
            "[Epoch 178/200] [Batch 700/938] loss_G: 3.016542, loss_D: 0.150565\n",
            "[Epoch 178/200] [Batch 710/938] loss_G: 3.350537, loss_D: 0.156673\n",
            "[Epoch 178/200] [Batch 720/938] loss_G: 3.714823, loss_D: 0.109540\n",
            "[Epoch 178/200] [Batch 730/938] loss_G: 3.051605, loss_D: 0.171334\n",
            "[Epoch 178/200] [Batch 740/938] loss_G: 3.236653, loss_D: 0.128900\n",
            "[Epoch 178/200] [Batch 750/938] loss_G: 3.345831, loss_D: 0.137683\n",
            "[Epoch 178/200] [Batch 760/938] loss_G: 2.922848, loss_D: 0.221890\n",
            "[Epoch 178/200] [Batch 770/938] loss_G: 3.199855, loss_D: 0.385679\n",
            "[Epoch 178/200] [Batch 780/938] loss_G: 2.950109, loss_D: 0.172952\n",
            "[Epoch 178/200] [Batch 790/938] loss_G: 3.559871, loss_D: 0.166046\n",
            "[Epoch 178/200] [Batch 800/938] loss_G: 3.211481, loss_D: 0.209501\n",
            "[Epoch 178/200] [Batch 810/938] loss_G: 3.243928, loss_D: 0.147222\n",
            "[Epoch 178/200] [Batch 820/938] loss_G: 3.505993, loss_D: 0.166222\n",
            "[Epoch 178/200] [Batch 830/938] loss_G: 3.346651, loss_D: 0.193958\n",
            "[Epoch 178/200] [Batch 840/938] loss_G: 3.328205, loss_D: 0.162435\n",
            "[Epoch 178/200] [Batch 850/938] loss_G: 3.276923, loss_D: 0.149579\n",
            "[Epoch 178/200] [Batch 860/938] loss_G: 2.846546, loss_D: 0.225028\n",
            "[Epoch 178/200] [Batch 870/938] loss_G: 3.242790, loss_D: 0.304636\n",
            "[Epoch 178/200] [Batch 880/938] loss_G: 3.154962, loss_D: 0.200675\n",
            "[Epoch 178/200] [Batch 890/938] loss_G: 3.262348, loss_D: 0.305436\n",
            "[Epoch 178/200] [Batch 900/938] loss_G: 3.112988, loss_D: 0.313125\n",
            "[Epoch 178/200] [Batch 910/938] loss_G: 3.456951, loss_D: 0.126347\n",
            "[Epoch 178/200] [Batch 920/938] loss_G: 3.047921, loss_D: 0.186116\n",
            "[Epoch 178/200] [Batch 930/938] loss_G: 3.084432, loss_D: 0.229547\n",
            "[Epoch 179/200] [Batch 0/938] loss_G: 3.307020, loss_D: 0.106027\n",
            "[Epoch 179/200] [Batch 10/938] loss_G: 3.251444, loss_D: 0.187975\n",
            "[Epoch 179/200] [Batch 20/938] loss_G: 3.182978, loss_D: 0.278112\n",
            "[Epoch 179/200] [Batch 30/938] loss_G: 3.521072, loss_D: 0.140817\n",
            "[Epoch 179/200] [Batch 40/938] loss_G: 2.730187, loss_D: 0.234324\n",
            "[Epoch 179/200] [Batch 50/938] loss_G: 3.238657, loss_D: 0.189849\n",
            "[Epoch 179/200] [Batch 60/938] loss_G: 3.193670, loss_D: 0.186922\n",
            "[Epoch 179/200] [Batch 70/938] loss_G: 3.031563, loss_D: 0.231023\n",
            "[Epoch 179/200] [Batch 80/938] loss_G: 2.704513, loss_D: 0.197419\n",
            "[Epoch 179/200] [Batch 90/938] loss_G: 3.236868, loss_D: 0.158437\n",
            "[Epoch 179/200] [Batch 100/938] loss_G: 3.472796, loss_D: 0.176867\n",
            "[Epoch 179/200] [Batch 110/938] loss_G: 3.280344, loss_D: 0.215177\n",
            "[Epoch 179/200] [Batch 120/938] loss_G: 3.079984, loss_D: 0.213279\n",
            "[Epoch 179/200] [Batch 130/938] loss_G: 3.179245, loss_D: 0.202926\n",
            "[Epoch 179/200] [Batch 140/938] loss_G: 3.198508, loss_D: 0.107947\n",
            "[Epoch 179/200] [Batch 150/938] loss_G: 3.212315, loss_D: 0.226464\n",
            "[Epoch 179/200] [Batch 160/938] loss_G: 3.166074, loss_D: 0.341473\n",
            "[Epoch 179/200] [Batch 170/938] loss_G: 3.214153, loss_D: 0.197900\n",
            "[Epoch 179/200] [Batch 180/938] loss_G: 3.035528, loss_D: 0.157520\n",
            "[Epoch 179/200] [Batch 190/938] loss_G: 3.168915, loss_D: 0.208565\n",
            "[Epoch 179/200] [Batch 200/938] loss_G: 3.172024, loss_D: 0.105264\n",
            "[Epoch 179/200] [Batch 210/938] loss_G: 3.192409, loss_D: 0.205790\n",
            "[Epoch 179/200] [Batch 220/938] loss_G: 3.257252, loss_D: 0.215002\n",
            "[Epoch 179/200] [Batch 230/938] loss_G: 3.099022, loss_D: 0.189757\n",
            "[Epoch 179/200] [Batch 240/938] loss_G: 3.467730, loss_D: 0.166499\n",
            "[Epoch 179/200] [Batch 250/938] loss_G: 3.526335, loss_D: 0.187681\n",
            "[Epoch 179/200] [Batch 260/938] loss_G: 2.946027, loss_D: 0.170733\n",
            "[Epoch 179/200] [Batch 270/938] loss_G: 3.020748, loss_D: 0.185136\n",
            "[Epoch 179/200] [Batch 280/938] loss_G: 3.018436, loss_D: 0.187368\n",
            "[Epoch 179/200] [Batch 290/938] loss_G: 3.050256, loss_D: 0.205403\n",
            "[Epoch 179/200] [Batch 300/938] loss_G: 3.403402, loss_D: 0.336434\n",
            "[Epoch 179/200] [Batch 310/938] loss_G: 2.760092, loss_D: 0.182600\n",
            "[Epoch 179/200] [Batch 320/938] loss_G: 3.273463, loss_D: 0.180778\n",
            "[Epoch 179/200] [Batch 330/938] loss_G: 3.087125, loss_D: 0.245957\n",
            "[Epoch 179/200] [Batch 340/938] loss_G: 3.125617, loss_D: 0.154674\n",
            "[Epoch 179/200] [Batch 350/938] loss_G: 2.855411, loss_D: 0.257142\n",
            "[Epoch 179/200] [Batch 360/938] loss_G: 3.468250, loss_D: 0.226567\n",
            "[Epoch 179/200] [Batch 370/938] loss_G: 3.330028, loss_D: 0.229333\n",
            "[Epoch 179/200] [Batch 380/938] loss_G: 2.977726, loss_D: 0.361687\n",
            "[Epoch 179/200] [Batch 390/938] loss_G: 3.518939, loss_D: 0.145458\n",
            "[Epoch 179/200] [Batch 400/938] loss_G: 3.237174, loss_D: 0.203144\n",
            "[Epoch 179/200] [Batch 410/938] loss_G: 3.213364, loss_D: 0.297361\n",
            "[Epoch 179/200] [Batch 420/938] loss_G: 3.022313, loss_D: 0.192495\n",
            "[Epoch 179/200] [Batch 430/938] loss_G: 2.981085, loss_D: 0.284432\n",
            "[Epoch 179/200] [Batch 440/938] loss_G: 3.070911, loss_D: 0.188018\n",
            "[Epoch 179/200] [Batch 450/938] loss_G: 3.116384, loss_D: 0.222892\n",
            "[Epoch 179/200] [Batch 460/938] loss_G: 2.840367, loss_D: 0.302349\n",
            "[Epoch 179/200] [Batch 470/938] loss_G: 3.106769, loss_D: 0.165824\n",
            "[Epoch 179/200] [Batch 480/938] loss_G: 3.252352, loss_D: 0.176904\n",
            "[Epoch 179/200] [Batch 490/938] loss_G: 3.572725, loss_D: 0.132293\n",
            "[Epoch 179/200] [Batch 500/938] loss_G: 3.462292, loss_D: 0.136855\n",
            "[Epoch 179/200] [Batch 510/938] loss_G: 3.140769, loss_D: 0.224749\n",
            "[Epoch 179/200] [Batch 520/938] loss_G: 3.235683, loss_D: 0.155983\n",
            "[Epoch 179/200] [Batch 530/938] loss_G: 3.504929, loss_D: 0.198647\n",
            "[Epoch 179/200] [Batch 540/938] loss_G: 2.835898, loss_D: 0.231437\n",
            "[Epoch 179/200] [Batch 550/938] loss_G: 3.476469, loss_D: 0.195838\n",
            "[Epoch 179/200] [Batch 560/938] loss_G: 3.091805, loss_D: 0.173392\n",
            "[Epoch 179/200] [Batch 570/938] loss_G: 3.628263, loss_D: 0.234803\n",
            "[Epoch 179/200] [Batch 580/938] loss_G: 3.523410, loss_D: 0.169974\n",
            "[Epoch 179/200] [Batch 590/938] loss_G: 3.735192, loss_D: 0.124004\n",
            "[Epoch 179/200] [Batch 600/938] loss_G: 3.292210, loss_D: 0.150979\n",
            "[Epoch 179/200] [Batch 610/938] loss_G: 3.112145, loss_D: 0.194803\n",
            "[Epoch 179/200] [Batch 620/938] loss_G: 3.603542, loss_D: 0.293263\n",
            "[Epoch 179/200] [Batch 630/938] loss_G: 3.596961, loss_D: 0.227344\n",
            "[Epoch 179/200] [Batch 640/938] loss_G: 3.214170, loss_D: 0.212438\n",
            "[Epoch 179/200] [Batch 650/938] loss_G: 3.242889, loss_D: 0.202178\n",
            "[Epoch 179/200] [Batch 660/938] loss_G: 2.989917, loss_D: 0.186879\n",
            "[Epoch 179/200] [Batch 670/938] loss_G: 3.561291, loss_D: 0.175101\n",
            "[Epoch 179/200] [Batch 680/938] loss_G: 3.265728, loss_D: 0.208606\n",
            "[Epoch 179/200] [Batch 690/938] loss_G: 3.091335, loss_D: 0.213617\n",
            "[Epoch 179/200] [Batch 700/938] loss_G: 3.150707, loss_D: 0.180232\n",
            "[Epoch 179/200] [Batch 710/938] loss_G: 3.532088, loss_D: 0.172265\n",
            "[Epoch 179/200] [Batch 720/938] loss_G: 2.982520, loss_D: 0.214049\n",
            "[Epoch 179/200] [Batch 730/938] loss_G: 3.124549, loss_D: 0.133300\n",
            "[Epoch 179/200] [Batch 740/938] loss_G: 3.358768, loss_D: 0.154777\n",
            "[Epoch 179/200] [Batch 750/938] loss_G: 3.321580, loss_D: 0.209859\n",
            "[Epoch 179/200] [Batch 760/938] loss_G: 3.226561, loss_D: 0.218737\n",
            "[Epoch 179/200] [Batch 770/938] loss_G: 2.705131, loss_D: 0.190934\n",
            "[Epoch 179/200] [Batch 780/938] loss_G: 3.377261, loss_D: 0.203495\n",
            "[Epoch 179/200] [Batch 790/938] loss_G: 3.531082, loss_D: 0.213573\n",
            "[Epoch 179/200] [Batch 800/938] loss_G: 3.000303, loss_D: 0.192718\n",
            "[Epoch 179/200] [Batch 810/938] loss_G: 3.375697, loss_D: 0.112561\n",
            "[Epoch 179/200] [Batch 820/938] loss_G: 3.179063, loss_D: 0.185417\n",
            "[Epoch 179/200] [Batch 830/938] loss_G: 3.127918, loss_D: 0.132156\n",
            "[Epoch 179/200] [Batch 840/938] loss_G: 3.285348, loss_D: 0.139408\n",
            "[Epoch 179/200] [Batch 850/938] loss_G: 3.524543, loss_D: 0.164281\n",
            "[Epoch 179/200] [Batch 860/938] loss_G: 2.623307, loss_D: 0.197004\n",
            "[Epoch 179/200] [Batch 870/938] loss_G: 3.284982, loss_D: 0.130879\n",
            "[Epoch 179/200] [Batch 880/938] loss_G: 2.829556, loss_D: 0.312848\n",
            "[Epoch 179/200] [Batch 890/938] loss_G: 3.054111, loss_D: 0.188400\n",
            "[Epoch 179/200] [Batch 900/938] loss_G: 2.998886, loss_D: 0.174202\n",
            "[Epoch 179/200] [Batch 910/938] loss_G: 2.943273, loss_D: 0.224806\n",
            "[Epoch 179/200] [Batch 920/938] loss_G: 3.244259, loss_D: 0.152518\n",
            "[Epoch 179/200] [Batch 930/938] loss_G: 3.208183, loss_D: 0.159435\n",
            "[Epoch 180/200] [Batch 0/938] loss_G: 3.033737, loss_D: 0.211584\n",
            "[Epoch 180/200] [Batch 10/938] loss_G: 3.186767, loss_D: 0.122533\n",
            "[Epoch 180/200] [Batch 20/938] loss_G: 3.112881, loss_D: 0.267659\n",
            "[Epoch 180/200] [Batch 30/938] loss_G: 3.113283, loss_D: 0.225050\n",
            "[Epoch 180/200] [Batch 40/938] loss_G: 3.166493, loss_D: 0.285071\n",
            "[Epoch 180/200] [Batch 50/938] loss_G: 3.179341, loss_D: 0.240636\n",
            "[Epoch 180/200] [Batch 60/938] loss_G: 3.155017, loss_D: 0.147785\n",
            "[Epoch 180/200] [Batch 70/938] loss_G: 3.343254, loss_D: 0.286221\n",
            "[Epoch 180/200] [Batch 80/938] loss_G: 3.072051, loss_D: 0.199272\n",
            "[Epoch 180/200] [Batch 90/938] loss_G: 2.959448, loss_D: 0.303165\n",
            "[Epoch 180/200] [Batch 100/938] loss_G: 2.930008, loss_D: 0.268030\n",
            "[Epoch 180/200] [Batch 110/938] loss_G: 2.750716, loss_D: 0.189496\n",
            "[Epoch 180/200] [Batch 120/938] loss_G: 3.134859, loss_D: 0.200050\n",
            "[Epoch 180/200] [Batch 130/938] loss_G: 3.017671, loss_D: 0.208130\n",
            "[Epoch 180/200] [Batch 140/938] loss_G: 2.963381, loss_D: 0.290291\n",
            "[Epoch 180/200] [Batch 150/938] loss_G: 3.042436, loss_D: 0.266469\n",
            "[Epoch 180/200] [Batch 160/938] loss_G: 3.041042, loss_D: 0.175756\n",
            "[Epoch 180/200] [Batch 170/938] loss_G: 2.914514, loss_D: 0.277953\n",
            "[Epoch 180/200] [Batch 180/938] loss_G: 3.654430, loss_D: 0.211676\n",
            "[Epoch 180/200] [Batch 190/938] loss_G: 3.318532, loss_D: 0.193161\n",
            "[Epoch 180/200] [Batch 200/938] loss_G: 2.990241, loss_D: 0.304199\n",
            "[Epoch 180/200] [Batch 210/938] loss_G: 3.200570, loss_D: 0.135157\n",
            "[Epoch 180/200] [Batch 220/938] loss_G: 2.994333, loss_D: 0.216183\n",
            "[Epoch 180/200] [Batch 230/938] loss_G: 3.447788, loss_D: 0.149067\n",
            "[Epoch 180/200] [Batch 240/938] loss_G: 3.180809, loss_D: 0.296200\n",
            "[Epoch 180/200] [Batch 250/938] loss_G: 3.513624, loss_D: 0.144809\n",
            "[Epoch 180/200] [Batch 260/938] loss_G: 3.107853, loss_D: 0.267140\n",
            "[Epoch 180/200] [Batch 270/938] loss_G: 3.281292, loss_D: 0.191514\n",
            "[Epoch 180/200] [Batch 280/938] loss_G: 3.057406, loss_D: 0.234784\n",
            "[Epoch 180/200] [Batch 290/938] loss_G: 3.489840, loss_D: 0.129177\n",
            "[Epoch 180/200] [Batch 300/938] loss_G: 3.446817, loss_D: 0.200098\n",
            "[Epoch 180/200] [Batch 310/938] loss_G: 2.687442, loss_D: 0.285749\n",
            "[Epoch 180/200] [Batch 320/938] loss_G: 3.062942, loss_D: 0.178409\n",
            "[Epoch 180/200] [Batch 330/938] loss_G: 3.194701, loss_D: 0.205419\n",
            "[Epoch 180/200] [Batch 340/938] loss_G: 3.470914, loss_D: 0.262105\n",
            "[Epoch 180/200] [Batch 350/938] loss_G: 2.947173, loss_D: 0.157361\n",
            "[Epoch 180/200] [Batch 360/938] loss_G: 3.234612, loss_D: 0.151981\n",
            "[Epoch 180/200] [Batch 370/938] loss_G: 2.969895, loss_D: 0.257632\n",
            "[Epoch 180/200] [Batch 380/938] loss_G: 3.102091, loss_D: 0.217333\n",
            "[Epoch 180/200] [Batch 390/938] loss_G: 2.829769, loss_D: 0.188299\n",
            "[Epoch 180/200] [Batch 400/938] loss_G: 3.160481, loss_D: 0.161810\n",
            "[Epoch 180/200] [Batch 410/938] loss_G: 3.008825, loss_D: 0.231362\n",
            "[Epoch 180/200] [Batch 420/938] loss_G: 3.437438, loss_D: 0.158223\n",
            "[Epoch 180/200] [Batch 430/938] loss_G: 3.007031, loss_D: 0.219557\n",
            "[Epoch 180/200] [Batch 440/938] loss_G: 3.328147, loss_D: 0.173947\n",
            "[Epoch 180/200] [Batch 450/938] loss_G: 3.449924, loss_D: 0.156949\n",
            "[Epoch 180/200] [Batch 460/938] loss_G: 3.466438, loss_D: 0.217466\n",
            "[Epoch 180/200] [Batch 470/938] loss_G: 3.224844, loss_D: 0.191602\n",
            "[Epoch 180/200] [Batch 480/938] loss_G: 3.432334, loss_D: 0.180828\n",
            "[Epoch 180/200] [Batch 490/938] loss_G: 3.408298, loss_D: 0.193651\n",
            "[Epoch 180/200] [Batch 500/938] loss_G: 2.974021, loss_D: 0.161524\n",
            "[Epoch 180/200] [Batch 510/938] loss_G: 2.850657, loss_D: 0.204733\n",
            "[Epoch 180/200] [Batch 520/938] loss_G: 3.139230, loss_D: 0.107604\n",
            "[Epoch 180/200] [Batch 530/938] loss_G: 3.001975, loss_D: 0.230679\n",
            "[Epoch 180/200] [Batch 540/938] loss_G: 2.923475, loss_D: 0.150828\n",
            "[Epoch 180/200] [Batch 550/938] loss_G: 3.301575, loss_D: 0.151762\n",
            "[Epoch 180/200] [Batch 560/938] loss_G: 3.282118, loss_D: 0.178481\n",
            "[Epoch 180/200] [Batch 570/938] loss_G: 3.331266, loss_D: 0.209954\n",
            "[Epoch 180/200] [Batch 580/938] loss_G: 3.031024, loss_D: 0.177449\n",
            "[Epoch 180/200] [Batch 590/938] loss_G: 3.344284, loss_D: 0.216853\n",
            "[Epoch 180/200] [Batch 600/938] loss_G: 3.132432, loss_D: 0.186657\n",
            "[Epoch 180/200] [Batch 610/938] loss_G: 3.253240, loss_D: 0.222062\n",
            "[Epoch 180/200] [Batch 620/938] loss_G: 3.174938, loss_D: 0.158469\n",
            "[Epoch 180/200] [Batch 630/938] loss_G: 2.711976, loss_D: 0.196721\n",
            "[Epoch 180/200] [Batch 640/938] loss_G: 3.336895, loss_D: 0.206083\n",
            "[Epoch 180/200] [Batch 650/938] loss_G: 3.487391, loss_D: 0.158266\n",
            "[Epoch 180/200] [Batch 660/938] loss_G: 3.158963, loss_D: 0.119303\n",
            "[Epoch 180/200] [Batch 670/938] loss_G: 3.252875, loss_D: 0.179562\n",
            "[Epoch 180/200] [Batch 680/938] loss_G: 2.788347, loss_D: 0.227127\n",
            "[Epoch 180/200] [Batch 690/938] loss_G: 2.972469, loss_D: 0.190055\n",
            "[Epoch 180/200] [Batch 700/938] loss_G: 3.190121, loss_D: 0.198794\n",
            "[Epoch 180/200] [Batch 710/938] loss_G: 3.347283, loss_D: 0.221854\n",
            "[Epoch 180/200] [Batch 720/938] loss_G: 3.605994, loss_D: 0.163033\n",
            "[Epoch 180/200] [Batch 730/938] loss_G: 3.242063, loss_D: 0.280048\n",
            "[Epoch 180/200] [Batch 740/938] loss_G: 2.707626, loss_D: 0.181809\n",
            "[Epoch 180/200] [Batch 750/938] loss_G: 3.439045, loss_D: 0.162830\n",
            "[Epoch 180/200] [Batch 760/938] loss_G: 2.386528, loss_D: 0.287874\n",
            "[Epoch 180/200] [Batch 770/938] loss_G: 3.093010, loss_D: 0.157869\n",
            "[Epoch 180/200] [Batch 780/938] loss_G: 3.065780, loss_D: 0.276358\n",
            "[Epoch 180/200] [Batch 790/938] loss_G: 3.571589, loss_D: 0.163624\n",
            "[Epoch 180/200] [Batch 800/938] loss_G: 3.565989, loss_D: 0.144749\n",
            "[Epoch 180/200] [Batch 810/938] loss_G: 3.312424, loss_D: 0.306934\n",
            "[Epoch 180/200] [Batch 820/938] loss_G: 2.959347, loss_D: 0.192156\n",
            "[Epoch 180/200] [Batch 830/938] loss_G: 3.293010, loss_D: 0.176273\n",
            "[Epoch 180/200] [Batch 840/938] loss_G: 2.818417, loss_D: 0.189582\n",
            "[Epoch 180/200] [Batch 850/938] loss_G: 2.734270, loss_D: 0.291837\n",
            "[Epoch 180/200] [Batch 860/938] loss_G: 3.084656, loss_D: 0.177480\n",
            "[Epoch 180/200] [Batch 870/938] loss_G: 3.489928, loss_D: 0.174281\n",
            "[Epoch 180/200] [Batch 880/938] loss_G: 3.289055, loss_D: 0.185042\n",
            "[Epoch 180/200] [Batch 890/938] loss_G: 3.173591, loss_D: 0.262484\n",
            "[Epoch 180/200] [Batch 900/938] loss_G: 3.267236, loss_D: 0.168214\n",
            "[Epoch 180/200] [Batch 910/938] loss_G: 3.106661, loss_D: 0.175904\n",
            "[Epoch 180/200] [Batch 920/938] loss_G: 3.226455, loss_D: 0.216211\n",
            "[Epoch 180/200] [Batch 930/938] loss_G: 2.957026, loss_D: 0.252493\n",
            "[Epoch 181/200] [Batch 0/938] loss_G: 3.306332, loss_D: 0.193934\n",
            "[Epoch 181/200] [Batch 10/938] loss_G: 3.051239, loss_D: 0.289975\n",
            "[Epoch 181/200] [Batch 20/938] loss_G: 2.918978, loss_D: 0.120811\n",
            "[Epoch 181/200] [Batch 30/938] loss_G: 2.920224, loss_D: 0.263533\n",
            "[Epoch 181/200] [Batch 40/938] loss_G: 3.139552, loss_D: 0.202493\n",
            "[Epoch 181/200] [Batch 50/938] loss_G: 3.180300, loss_D: 0.280469\n",
            "[Epoch 181/200] [Batch 60/938] loss_G: 3.075747, loss_D: 0.160897\n",
            "[Epoch 181/200] [Batch 70/938] loss_G: 3.022455, loss_D: 0.226415\n",
            "[Epoch 181/200] [Batch 80/938] loss_G: 3.062715, loss_D: 0.221787\n",
            "[Epoch 181/200] [Batch 90/938] loss_G: 3.265842, loss_D: 0.175838\n",
            "[Epoch 181/200] [Batch 100/938] loss_G: 2.928105, loss_D: 0.190105\n",
            "[Epoch 181/200] [Batch 110/938] loss_G: 3.295787, loss_D: 0.179725\n",
            "[Epoch 181/200] [Batch 120/938] loss_G: 3.075572, loss_D: 0.167072\n",
            "[Epoch 181/200] [Batch 130/938] loss_G: 3.243864, loss_D: 0.175611\n",
            "[Epoch 181/200] [Batch 140/938] loss_G: 3.324977, loss_D: 0.209437\n",
            "[Epoch 181/200] [Batch 150/938] loss_G: 3.429471, loss_D: 0.151004\n",
            "[Epoch 181/200] [Batch 160/938] loss_G: 3.067144, loss_D: 0.201010\n",
            "[Epoch 181/200] [Batch 170/938] loss_G: 3.167528, loss_D: 0.252350\n",
            "[Epoch 181/200] [Batch 180/938] loss_G: 3.550489, loss_D: 0.229122\n",
            "[Epoch 181/200] [Batch 190/938] loss_G: 3.395776, loss_D: 0.202701\n",
            "[Epoch 181/200] [Batch 200/938] loss_G: 2.768135, loss_D: 0.163917\n",
            "[Epoch 181/200] [Batch 210/938] loss_G: 4.035267, loss_D: 0.194526\n",
            "[Epoch 181/200] [Batch 220/938] loss_G: 3.097479, loss_D: 0.104267\n",
            "[Epoch 181/200] [Batch 230/938] loss_G: 3.132290, loss_D: 0.160214\n",
            "[Epoch 181/200] [Batch 240/938] loss_G: 3.020008, loss_D: 0.157395\n",
            "[Epoch 181/200] [Batch 250/938] loss_G: 3.366918, loss_D: 0.169791\n",
            "[Epoch 181/200] [Batch 260/938] loss_G: 2.908637, loss_D: 0.166571\n",
            "[Epoch 181/200] [Batch 270/938] loss_G: 3.109136, loss_D: 0.252327\n",
            "[Epoch 181/200] [Batch 280/938] loss_G: 3.223191, loss_D: 0.197303\n",
            "[Epoch 181/200] [Batch 290/938] loss_G: 3.374622, loss_D: 0.109511\n",
            "[Epoch 181/200] [Batch 300/938] loss_G: 2.748426, loss_D: 0.188463\n",
            "[Epoch 181/200] [Batch 310/938] loss_G: 3.329588, loss_D: 0.153505\n",
            "[Epoch 181/200] [Batch 320/938] loss_G: 3.110972, loss_D: 0.218569\n",
            "[Epoch 181/200] [Batch 330/938] loss_G: 3.056968, loss_D: 0.189360\n",
            "[Epoch 181/200] [Batch 340/938] loss_G: 3.223593, loss_D: 0.182307\n",
            "[Epoch 181/200] [Batch 350/938] loss_G: 3.403806, loss_D: 0.136837\n",
            "[Epoch 181/200] [Batch 360/938] loss_G: 3.172637, loss_D: 0.209553\n",
            "[Epoch 181/200] [Batch 370/938] loss_G: 3.519543, loss_D: 0.134689\n",
            "[Epoch 181/200] [Batch 380/938] loss_G: 3.112580, loss_D: 0.113538\n",
            "[Epoch 181/200] [Batch 390/938] loss_G: 2.993866, loss_D: 0.243001\n",
            "[Epoch 181/200] [Batch 400/938] loss_G: 3.448767, loss_D: 0.187404\n",
            "[Epoch 181/200] [Batch 410/938] loss_G: 3.430502, loss_D: 0.198224\n",
            "[Epoch 181/200] [Batch 420/938] loss_G: 3.158825, loss_D: 0.132125\n",
            "[Epoch 181/200] [Batch 430/938] loss_G: 3.448720, loss_D: 0.176163\n",
            "[Epoch 181/200] [Batch 440/938] loss_G: 3.392226, loss_D: 0.197661\n",
            "[Epoch 181/200] [Batch 450/938] loss_G: 3.336293, loss_D: 0.287695\n",
            "[Epoch 181/200] [Batch 460/938] loss_G: 2.415020, loss_D: 0.301762\n",
            "[Epoch 181/200] [Batch 470/938] loss_G: 3.190873, loss_D: 0.261405\n",
            "[Epoch 181/200] [Batch 480/938] loss_G: 3.101081, loss_D: 0.182945\n",
            "[Epoch 181/200] [Batch 490/938] loss_G: 3.011695, loss_D: 0.232939\n",
            "[Epoch 181/200] [Batch 500/938] loss_G: 3.138905, loss_D: 0.192823\n",
            "[Epoch 181/200] [Batch 510/938] loss_G: 2.774021, loss_D: 0.240884\n",
            "[Epoch 181/200] [Batch 520/938] loss_G: 3.423297, loss_D: 0.230069\n",
            "[Epoch 181/200] [Batch 530/938] loss_G: 3.632979, loss_D: 0.197020\n",
            "[Epoch 181/200] [Batch 540/938] loss_G: 3.169777, loss_D: 0.282703\n",
            "[Epoch 181/200] [Batch 550/938] loss_G: 2.884446, loss_D: 0.144253\n",
            "[Epoch 181/200] [Batch 560/938] loss_G: 3.274973, loss_D: 0.183977\n",
            "[Epoch 181/200] [Batch 570/938] loss_G: 3.345133, loss_D: 0.161414\n",
            "[Epoch 181/200] [Batch 580/938] loss_G: 2.946382, loss_D: 0.238828\n",
            "[Epoch 181/200] [Batch 590/938] loss_G: 2.733255, loss_D: 0.170515\n",
            "[Epoch 181/200] [Batch 600/938] loss_G: 3.478406, loss_D: 0.222591\n",
            "[Epoch 181/200] [Batch 610/938] loss_G: 3.226166, loss_D: 0.140014\n",
            "[Epoch 181/200] [Batch 620/938] loss_G: 3.044521, loss_D: 0.220875\n",
            "[Epoch 181/200] [Batch 630/938] loss_G: 3.161273, loss_D: 0.232487\n",
            "[Epoch 181/200] [Batch 640/938] loss_G: 3.161813, loss_D: 0.266208\n",
            "[Epoch 181/200] [Batch 650/938] loss_G: 2.835894, loss_D: 0.302981\n",
            "[Epoch 181/200] [Batch 660/938] loss_G: 3.316187, loss_D: 0.199321\n",
            "[Epoch 181/200] [Batch 670/938] loss_G: 2.910143, loss_D: 0.183072\n",
            "[Epoch 181/200] [Batch 680/938] loss_G: 2.914615, loss_D: 0.264776\n",
            "[Epoch 181/200] [Batch 690/938] loss_G: 3.156676, loss_D: 0.139986\n",
            "[Epoch 181/200] [Batch 700/938] loss_G: 3.208169, loss_D: 0.203859\n",
            "[Epoch 181/200] [Batch 710/938] loss_G: 3.186397, loss_D: 0.158817\n",
            "[Epoch 181/200] [Batch 720/938] loss_G: 3.180381, loss_D: 0.173207\n",
            "[Epoch 181/200] [Batch 730/938] loss_G: 3.304173, loss_D: 0.174818\n",
            "[Epoch 181/200] [Batch 740/938] loss_G: 3.405693, loss_D: 0.128151\n",
            "[Epoch 181/200] [Batch 750/938] loss_G: 2.940563, loss_D: 0.190510\n",
            "[Epoch 181/200] [Batch 760/938] loss_G: 3.053842, loss_D: 0.145580\n",
            "[Epoch 181/200] [Batch 770/938] loss_G: 3.384226, loss_D: 0.135362\n",
            "[Epoch 181/200] [Batch 780/938] loss_G: 2.731305, loss_D: 0.166176\n",
            "[Epoch 181/200] [Batch 790/938] loss_G: 3.131220, loss_D: 0.326257\n",
            "[Epoch 181/200] [Batch 800/938] loss_G: 3.138364, loss_D: 0.150695\n",
            "[Epoch 181/200] [Batch 810/938] loss_G: 3.257752, loss_D: 0.172702\n",
            "[Epoch 181/200] [Batch 820/938] loss_G: 3.101816, loss_D: 0.251180\n",
            "[Epoch 181/200] [Batch 830/938] loss_G: 2.714284, loss_D: 0.219325\n",
            "[Epoch 181/200] [Batch 840/938] loss_G: 3.050622, loss_D: 0.176721\n",
            "[Epoch 181/200] [Batch 850/938] loss_G: 3.107989, loss_D: 0.271502\n",
            "[Epoch 181/200] [Batch 860/938] loss_G: 3.210302, loss_D: 0.232551\n",
            "[Epoch 181/200] [Batch 870/938] loss_G: 3.069579, loss_D: 0.178966\n",
            "[Epoch 181/200] [Batch 880/938] loss_G: 3.397351, loss_D: 0.191546\n",
            "[Epoch 181/200] [Batch 890/938] loss_G: 3.272120, loss_D: 0.114012\n",
            "[Epoch 181/200] [Batch 900/938] loss_G: 3.190442, loss_D: 0.265531\n",
            "[Epoch 181/200] [Batch 910/938] loss_G: 3.202906, loss_D: 0.144035\n",
            "[Epoch 181/200] [Batch 920/938] loss_G: 3.396746, loss_D: 0.240227\n",
            "[Epoch 181/200] [Batch 930/938] loss_G: 3.484725, loss_D: 0.120127\n",
            "[Epoch 182/200] [Batch 0/938] loss_G: 3.493928, loss_D: 0.123423\n",
            "[Epoch 182/200] [Batch 10/938] loss_G: 3.167328, loss_D: 0.193891\n",
            "[Epoch 182/200] [Batch 20/938] loss_G: 2.888052, loss_D: 0.211993\n",
            "[Epoch 182/200] [Batch 30/938] loss_G: 3.262872, loss_D: 0.198114\n",
            "[Epoch 182/200] [Batch 40/938] loss_G: 3.320006, loss_D: 0.169942\n",
            "[Epoch 182/200] [Batch 50/938] loss_G: 3.050679, loss_D: 0.186373\n",
            "[Epoch 182/200] [Batch 60/938] loss_G: 3.614776, loss_D: 0.100558\n",
            "[Epoch 182/200] [Batch 70/938] loss_G: 3.339198, loss_D: 0.185214\n",
            "[Epoch 182/200] [Batch 80/938] loss_G: 3.211670, loss_D: 0.153713\n",
            "[Epoch 182/200] [Batch 90/938] loss_G: 2.899577, loss_D: 0.213420\n",
            "[Epoch 182/200] [Batch 100/938] loss_G: 3.122431, loss_D: 0.229103\n",
            "[Epoch 182/200] [Batch 110/938] loss_G: 3.252378, loss_D: 0.200347\n",
            "[Epoch 182/200] [Batch 120/938] loss_G: 2.926338, loss_D: 0.141069\n",
            "[Epoch 182/200] [Batch 130/938] loss_G: 2.872435, loss_D: 0.193725\n",
            "[Epoch 182/200] [Batch 140/938] loss_G: 3.186529, loss_D: 0.226510\n",
            "[Epoch 182/200] [Batch 150/938] loss_G: 2.963988, loss_D: 0.110987\n",
            "[Epoch 182/200] [Batch 160/938] loss_G: 3.367070, loss_D: 0.192802\n",
            "[Epoch 182/200] [Batch 170/938] loss_G: 3.246524, loss_D: 0.174063\n",
            "[Epoch 182/200] [Batch 180/938] loss_G: 3.049254, loss_D: 0.160165\n",
            "[Epoch 182/200] [Batch 190/938] loss_G: 3.265271, loss_D: 0.217427\n",
            "[Epoch 182/200] [Batch 200/938] loss_G: 3.196606, loss_D: 0.232719\n",
            "[Epoch 182/200] [Batch 210/938] loss_G: 3.356217, loss_D: 0.179967\n",
            "[Epoch 182/200] [Batch 220/938] loss_G: 3.276802, loss_D: 0.239997\n",
            "[Epoch 182/200] [Batch 230/938] loss_G: 2.765931, loss_D: 0.216506\n",
            "[Epoch 182/200] [Batch 240/938] loss_G: 3.087684, loss_D: 0.206025\n",
            "[Epoch 182/200] [Batch 250/938] loss_G: 2.940067, loss_D: 0.204520\n",
            "[Epoch 182/200] [Batch 260/938] loss_G: 3.092495, loss_D: 0.203870\n",
            "[Epoch 182/200] [Batch 270/938] loss_G: 3.419892, loss_D: 0.157938\n",
            "[Epoch 182/200] [Batch 280/938] loss_G: 3.264342, loss_D: 0.181635\n",
            "[Epoch 182/200] [Batch 290/938] loss_G: 3.484578, loss_D: 0.100999\n",
            "[Epoch 182/200] [Batch 300/938] loss_G: 3.483885, loss_D: 0.121306\n",
            "[Epoch 182/200] [Batch 310/938] loss_G: 3.087855, loss_D: 0.187304\n",
            "[Epoch 182/200] [Batch 320/938] loss_G: 3.514612, loss_D: 0.184205\n",
            "[Epoch 182/200] [Batch 330/938] loss_G: 3.409820, loss_D: 0.174482\n",
            "[Epoch 182/200] [Batch 340/938] loss_G: 3.379546, loss_D: 0.202686\n",
            "[Epoch 182/200] [Batch 350/938] loss_G: 2.888385, loss_D: 0.211031\n",
            "[Epoch 182/200] [Batch 360/938] loss_G: 3.067253, loss_D: 0.188936\n",
            "[Epoch 182/200] [Batch 370/938] loss_G: 3.145081, loss_D: 0.240105\n",
            "[Epoch 182/200] [Batch 380/938] loss_G: 3.042693, loss_D: 0.233549\n",
            "[Epoch 182/200] [Batch 390/938] loss_G: 3.221535, loss_D: 0.184667\n",
            "[Epoch 182/200] [Batch 400/938] loss_G: 3.315233, loss_D: 0.125737\n",
            "[Epoch 182/200] [Batch 410/938] loss_G: 4.089267, loss_D: 0.263114\n",
            "[Epoch 182/200] [Batch 420/938] loss_G: 3.044220, loss_D: 0.160100\n",
            "[Epoch 182/200] [Batch 430/938] loss_G: 3.086841, loss_D: 0.195917\n",
            "[Epoch 182/200] [Batch 440/938] loss_G: 2.945851, loss_D: 0.186792\n",
            "[Epoch 182/200] [Batch 450/938] loss_G: 3.095682, loss_D: 0.211950\n",
            "[Epoch 182/200] [Batch 460/938] loss_G: 3.488048, loss_D: 0.169561\n",
            "[Epoch 182/200] [Batch 470/938] loss_G: 3.233185, loss_D: 0.189198\n",
            "[Epoch 182/200] [Batch 480/938] loss_G: 3.712711, loss_D: 0.158295\n",
            "[Epoch 182/200] [Batch 490/938] loss_G: 3.140162, loss_D: 0.304772\n",
            "[Epoch 182/200] [Batch 500/938] loss_G: 2.754876, loss_D: 0.241423\n",
            "[Epoch 182/200] [Batch 510/938] loss_G: 2.990807, loss_D: 0.186885\n",
            "[Epoch 182/200] [Batch 520/938] loss_G: 2.996789, loss_D: 0.172080\n",
            "[Epoch 182/200] [Batch 530/938] loss_G: 3.082629, loss_D: 0.162371\n",
            "[Epoch 182/200] [Batch 540/938] loss_G: 3.274706, loss_D: 0.208895\n",
            "[Epoch 182/200] [Batch 550/938] loss_G: 3.321634, loss_D: 0.223424\n",
            "[Epoch 182/200] [Batch 560/938] loss_G: 3.685794, loss_D: 0.232896\n",
            "[Epoch 182/200] [Batch 570/938] loss_G: 3.264604, loss_D: 0.262523\n",
            "[Epoch 182/200] [Batch 580/938] loss_G: 3.090775, loss_D: 0.245932\n",
            "[Epoch 182/200] [Batch 590/938] loss_G: 3.285233, loss_D: 0.217253\n",
            "[Epoch 182/200] [Batch 600/938] loss_G: 3.115064, loss_D: 0.287277\n",
            "[Epoch 182/200] [Batch 610/938] loss_G: 2.896230, loss_D: 0.226015\n",
            "[Epoch 182/200] [Batch 620/938] loss_G: 3.232808, loss_D: 0.167459\n",
            "[Epoch 182/200] [Batch 630/938] loss_G: 3.230209, loss_D: 0.183097\n",
            "[Epoch 182/200] [Batch 640/938] loss_G: 3.589271, loss_D: 0.220223\n",
            "[Epoch 182/200] [Batch 650/938] loss_G: 3.598928, loss_D: 0.198589\n",
            "[Epoch 182/200] [Batch 660/938] loss_G: 3.159565, loss_D: 0.156278\n",
            "[Epoch 182/200] [Batch 670/938] loss_G: 3.597729, loss_D: 0.198001\n",
            "[Epoch 182/200] [Batch 680/938] loss_G: 3.101005, loss_D: 0.130233\n",
            "[Epoch 182/200] [Batch 690/938] loss_G: 2.895925, loss_D: 0.178871\n",
            "[Epoch 182/200] [Batch 700/938] loss_G: 3.479300, loss_D: 0.193764\n",
            "[Epoch 182/200] [Batch 710/938] loss_G: 3.262302, loss_D: 0.109236\n",
            "[Epoch 182/200] [Batch 720/938] loss_G: 3.005056, loss_D: 0.200845\n",
            "[Epoch 182/200] [Batch 730/938] loss_G: 2.938506, loss_D: 0.231297\n",
            "[Epoch 182/200] [Batch 740/938] loss_G: 3.228539, loss_D: 0.239282\n",
            "[Epoch 182/200] [Batch 750/938] loss_G: 2.877477, loss_D: 0.287887\n",
            "[Epoch 182/200] [Batch 760/938] loss_G: 3.137273, loss_D: 0.165437\n",
            "[Epoch 182/200] [Batch 770/938] loss_G: 3.163398, loss_D: 0.303589\n",
            "[Epoch 182/200] [Batch 780/938] loss_G: 3.310877, loss_D: 0.162648\n",
            "[Epoch 182/200] [Batch 790/938] loss_G: 3.098669, loss_D: 0.229945\n",
            "[Epoch 182/200] [Batch 800/938] loss_G: 3.399738, loss_D: 0.204618\n",
            "[Epoch 182/200] [Batch 810/938] loss_G: 3.296546, loss_D: 0.150648\n",
            "[Epoch 182/200] [Batch 820/938] loss_G: 3.460724, loss_D: 0.111979\n",
            "[Epoch 182/200] [Batch 830/938] loss_G: 3.081047, loss_D: 0.168660\n",
            "[Epoch 182/200] [Batch 840/938] loss_G: 2.832279, loss_D: 0.262091\n",
            "[Epoch 182/200] [Batch 850/938] loss_G: 2.933284, loss_D: 0.211709\n",
            "[Epoch 182/200] [Batch 860/938] loss_G: 3.114039, loss_D: 0.209028\n",
            "[Epoch 182/200] [Batch 870/938] loss_G: 3.160763, loss_D: 0.312902\n",
            "[Epoch 182/200] [Batch 880/938] loss_G: 3.062014, loss_D: 0.222240\n",
            "[Epoch 182/200] [Batch 890/938] loss_G: 3.188780, loss_D: 0.249622\n",
            "[Epoch 182/200] [Batch 900/938] loss_G: 3.084677, loss_D: 0.165203\n",
            "[Epoch 182/200] [Batch 910/938] loss_G: 2.996736, loss_D: 0.207728\n",
            "[Epoch 182/200] [Batch 920/938] loss_G: 2.878397, loss_D: 0.167901\n",
            "[Epoch 182/200] [Batch 930/938] loss_G: 3.031970, loss_D: 0.201879\n",
            "[Epoch 183/200] [Batch 0/938] loss_G: 3.103084, loss_D: 0.220105\n",
            "[Epoch 183/200] [Batch 10/938] loss_G: 3.319960, loss_D: 0.140314\n",
            "[Epoch 183/200] [Batch 20/938] loss_G: 3.334184, loss_D: 0.217537\n",
            "[Epoch 183/200] [Batch 30/938] loss_G: 2.894778, loss_D: 0.190248\n",
            "[Epoch 183/200] [Batch 40/938] loss_G: 3.190895, loss_D: 0.196351\n",
            "[Epoch 183/200] [Batch 50/938] loss_G: 3.328261, loss_D: 0.261250\n",
            "[Epoch 183/200] [Batch 60/938] loss_G: 2.777593, loss_D: 0.172871\n",
            "[Epoch 183/200] [Batch 70/938] loss_G: 3.010496, loss_D: 0.178106\n",
            "[Epoch 183/200] [Batch 80/938] loss_G: 2.994201, loss_D: 0.165014\n",
            "[Epoch 183/200] [Batch 90/938] loss_G: 2.805183, loss_D: 0.174108\n",
            "[Epoch 183/200] [Batch 100/938] loss_G: 3.321289, loss_D: 0.226764\n",
            "[Epoch 183/200] [Batch 110/938] loss_G: 3.368858, loss_D: 0.205758\n",
            "[Epoch 183/200] [Batch 120/938] loss_G: 2.916874, loss_D: 0.208443\n",
            "[Epoch 183/200] [Batch 130/938] loss_G: 3.165471, loss_D: 0.211464\n",
            "[Epoch 183/200] [Batch 140/938] loss_G: 3.021199, loss_D: 0.188738\n",
            "[Epoch 183/200] [Batch 150/938] loss_G: 2.883995, loss_D: 0.313810\n",
            "[Epoch 183/200] [Batch 160/938] loss_G: 3.387800, loss_D: 0.180198\n",
            "[Epoch 183/200] [Batch 170/938] loss_G: 3.220048, loss_D: 0.198633\n",
            "[Epoch 183/200] [Batch 180/938] loss_G: 3.030468, loss_D: 0.193069\n",
            "[Epoch 183/200] [Batch 190/938] loss_G: 3.333591, loss_D: 0.180916\n",
            "[Epoch 183/200] [Batch 200/938] loss_G: 3.135266, loss_D: 0.142273\n",
            "[Epoch 183/200] [Batch 210/938] loss_G: 3.226203, loss_D: 0.180985\n",
            "[Epoch 183/200] [Batch 220/938] loss_G: 3.674899, loss_D: 0.245646\n",
            "[Epoch 183/200] [Batch 230/938] loss_G: 3.645686, loss_D: 0.193863\n",
            "[Epoch 183/200] [Batch 240/938] loss_G: 3.192295, loss_D: 0.095817\n",
            "[Epoch 183/200] [Batch 250/938] loss_G: 2.954222, loss_D: 0.169467\n",
            "[Epoch 183/200] [Batch 260/938] loss_G: 3.087389, loss_D: 0.166251\n",
            "[Epoch 183/200] [Batch 270/938] loss_G: 3.512557, loss_D: 0.202524\n",
            "[Epoch 183/200] [Batch 280/938] loss_G: 3.203140, loss_D: 0.239266\n",
            "[Epoch 183/200] [Batch 290/938] loss_G: 3.266334, loss_D: 0.216008\n",
            "[Epoch 183/200] [Batch 300/938] loss_G: 3.584973, loss_D: 0.240859\n",
            "[Epoch 183/200] [Batch 310/938] loss_G: 3.198134, loss_D: 0.160272\n",
            "[Epoch 183/200] [Batch 320/938] loss_G: 2.905515, loss_D: 0.271562\n",
            "[Epoch 183/200] [Batch 330/938] loss_G: 3.083766, loss_D: 0.208572\n",
            "[Epoch 183/200] [Batch 340/938] loss_G: 2.982796, loss_D: 0.135203\n",
            "[Epoch 183/200] [Batch 350/938] loss_G: 3.003405, loss_D: 0.175504\n",
            "[Epoch 183/200] [Batch 360/938] loss_G: 3.247293, loss_D: 0.204988\n",
            "[Epoch 183/200] [Batch 370/938] loss_G: 2.771838, loss_D: 0.221972\n",
            "[Epoch 183/200] [Batch 380/938] loss_G: 3.206689, loss_D: 0.208303\n",
            "[Epoch 183/200] [Batch 390/938] loss_G: 3.411060, loss_D: 0.234965\n",
            "[Epoch 183/200] [Batch 400/938] loss_G: 3.261867, loss_D: 0.128137\n",
            "[Epoch 183/200] [Batch 410/938] loss_G: 3.034988, loss_D: 0.284806\n",
            "[Epoch 183/200] [Batch 420/938] loss_G: 3.441496, loss_D: 0.236257\n",
            "[Epoch 183/200] [Batch 430/938] loss_G: 3.281854, loss_D: 0.215321\n",
            "[Epoch 183/200] [Batch 440/938] loss_G: 2.887494, loss_D: 0.190308\n",
            "[Epoch 183/200] [Batch 450/938] loss_G: 3.272087, loss_D: 0.138115\n",
            "[Epoch 183/200] [Batch 460/938] loss_G: 3.538435, loss_D: 0.193710\n",
            "[Epoch 183/200] [Batch 470/938] loss_G: 3.290968, loss_D: 0.172334\n",
            "[Epoch 183/200] [Batch 480/938] loss_G: 3.483551, loss_D: 0.171859\n",
            "[Epoch 183/200] [Batch 490/938] loss_G: 3.146541, loss_D: 0.191795\n",
            "[Epoch 183/200] [Batch 500/938] loss_G: 3.066159, loss_D: 0.190193\n",
            "[Epoch 183/200] [Batch 510/938] loss_G: 3.389515, loss_D: 0.275263\n",
            "[Epoch 183/200] [Batch 520/938] loss_G: 2.914318, loss_D: 0.267181\n",
            "[Epoch 183/200] [Batch 530/938] loss_G: 2.918738, loss_D: 0.162041\n",
            "[Epoch 183/200] [Batch 540/938] loss_G: 3.477424, loss_D: 0.136622\n",
            "[Epoch 183/200] [Batch 550/938] loss_G: 3.452285, loss_D: 0.174311\n",
            "[Epoch 183/200] [Batch 560/938] loss_G: 2.941378, loss_D: 0.198171\n",
            "[Epoch 183/200] [Batch 570/938] loss_G: 3.241111, loss_D: 0.136444\n",
            "[Epoch 183/200] [Batch 580/938] loss_G: 3.447066, loss_D: 0.224187\n",
            "[Epoch 183/200] [Batch 590/938] loss_G: 3.145729, loss_D: 0.271307\n",
            "[Epoch 183/200] [Batch 600/938] loss_G: 2.647494, loss_D: 0.165672\n",
            "[Epoch 183/200] [Batch 610/938] loss_G: 3.274621, loss_D: 0.240981\n",
            "[Epoch 183/200] [Batch 620/938] loss_G: 3.278005, loss_D: 0.230951\n",
            "[Epoch 183/200] [Batch 630/938] loss_G: 3.015963, loss_D: 0.265972\n",
            "[Epoch 183/200] [Batch 640/938] loss_G: 3.147936, loss_D: 0.154747\n",
            "[Epoch 183/200] [Batch 650/938] loss_G: 3.504974, loss_D: 0.166209\n",
            "[Epoch 183/200] [Batch 660/938] loss_G: 2.968422, loss_D: 0.282394\n",
            "[Epoch 183/200] [Batch 670/938] loss_G: 2.884287, loss_D: 0.166335\n",
            "[Epoch 183/200] [Batch 680/938] loss_G: 2.708954, loss_D: 0.284112\n",
            "[Epoch 183/200] [Batch 690/938] loss_G: 2.846283, loss_D: 0.188525\n",
            "[Epoch 183/200] [Batch 700/938] loss_G: 3.305510, loss_D: 0.269045\n",
            "[Epoch 183/200] [Batch 710/938] loss_G: 3.195842, loss_D: 0.258217\n",
            "[Epoch 183/200] [Batch 720/938] loss_G: 3.354629, loss_D: 0.177368\n",
            "[Epoch 183/200] [Batch 730/938] loss_G: 3.542379, loss_D: 0.189811\n",
            "[Epoch 183/200] [Batch 740/938] loss_G: 2.838831, loss_D: 0.136444\n",
            "[Epoch 183/200] [Batch 750/938] loss_G: 3.001832, loss_D: 0.171633\n",
            "[Epoch 183/200] [Batch 760/938] loss_G: 3.437508, loss_D: 0.286231\n",
            "[Epoch 183/200] [Batch 770/938] loss_G: 3.469753, loss_D: 0.164290\n",
            "[Epoch 183/200] [Batch 780/938] loss_G: 3.381601, loss_D: 0.123285\n",
            "[Epoch 183/200] [Batch 790/938] loss_G: 3.200641, loss_D: 0.230289\n",
            "[Epoch 183/200] [Batch 800/938] loss_G: 3.388052, loss_D: 0.090167\n",
            "[Epoch 183/200] [Batch 810/938] loss_G: 3.261663, loss_D: 0.183815\n",
            "[Epoch 183/200] [Batch 820/938] loss_G: 2.708941, loss_D: 0.260298\n",
            "[Epoch 183/200] [Batch 830/938] loss_G: 3.076208, loss_D: 0.141426\n",
            "[Epoch 183/200] [Batch 840/938] loss_G: 3.244379, loss_D: 0.143801\n",
            "[Epoch 183/200] [Batch 850/938] loss_G: 3.420676, loss_D: 0.141016\n",
            "[Epoch 183/200] [Batch 860/938] loss_G: 3.140941, loss_D: 0.192056\n",
            "[Epoch 183/200] [Batch 870/938] loss_G: 3.407968, loss_D: 0.137472\n",
            "[Epoch 183/200] [Batch 880/938] loss_G: 3.395558, loss_D: 0.222358\n",
            "[Epoch 183/200] [Batch 890/938] loss_G: 2.912807, loss_D: 0.196760\n",
            "[Epoch 183/200] [Batch 900/938] loss_G: 3.174086, loss_D: 0.196725\n",
            "[Epoch 183/200] [Batch 910/938] loss_G: 3.196365, loss_D: 0.178866\n",
            "[Epoch 183/200] [Batch 920/938] loss_G: 3.281573, loss_D: 0.125187\n",
            "[Epoch 183/200] [Batch 930/938] loss_G: 3.276060, loss_D: 0.133650\n",
            "[Epoch 184/200] [Batch 0/938] loss_G: 3.322151, loss_D: 0.217186\n",
            "[Epoch 184/200] [Batch 10/938] loss_G: 2.914243, loss_D: 0.200495\n",
            "[Epoch 184/200] [Batch 20/938] loss_G: 3.090996, loss_D: 0.200362\n",
            "[Epoch 184/200] [Batch 30/938] loss_G: 3.485305, loss_D: 0.258956\n",
            "[Epoch 184/200] [Batch 40/938] loss_G: 3.099324, loss_D: 0.254729\n",
            "[Epoch 184/200] [Batch 50/938] loss_G: 2.914419, loss_D: 0.196248\n",
            "[Epoch 184/200] [Batch 60/938] loss_G: 3.165889, loss_D: 0.150172\n",
            "[Epoch 184/200] [Batch 70/938] loss_G: 3.396707, loss_D: 0.192431\n",
            "[Epoch 184/200] [Batch 80/938] loss_G: 3.382297, loss_D: 0.153855\n",
            "[Epoch 184/200] [Batch 90/938] loss_G: 2.868082, loss_D: 0.202981\n",
            "[Epoch 184/200] [Batch 100/938] loss_G: 3.338630, loss_D: 0.163875\n",
            "[Epoch 184/200] [Batch 110/938] loss_G: 3.464065, loss_D: 0.117504\n",
            "[Epoch 184/200] [Batch 120/938] loss_G: 2.878624, loss_D: 0.269468\n",
            "[Epoch 184/200] [Batch 130/938] loss_G: 3.445275, loss_D: 0.191333\n",
            "[Epoch 184/200] [Batch 140/938] loss_G: 3.614178, loss_D: 0.100494\n",
            "[Epoch 184/200] [Batch 150/938] loss_G: 3.701313, loss_D: 0.163637\n",
            "[Epoch 184/200] [Batch 160/938] loss_G: 2.961256, loss_D: 0.222740\n",
            "[Epoch 184/200] [Batch 170/938] loss_G: 3.255748, loss_D: 0.113335\n",
            "[Epoch 184/200] [Batch 180/938] loss_G: 2.852709, loss_D: 0.346977\n",
            "[Epoch 184/200] [Batch 190/938] loss_G: 3.184152, loss_D: 0.179288\n",
            "[Epoch 184/200] [Batch 200/938] loss_G: 2.860320, loss_D: 0.188515\n",
            "[Epoch 184/200] [Batch 210/938] loss_G: 3.112531, loss_D: 0.251313\n",
            "[Epoch 184/200] [Batch 220/938] loss_G: 3.076124, loss_D: 0.209525\n",
            "[Epoch 184/200] [Batch 230/938] loss_G: 3.217377, loss_D: 0.243905\n",
            "[Epoch 184/200] [Batch 240/938] loss_G: 3.274425, loss_D: 0.195408\n",
            "[Epoch 184/200] [Batch 250/938] loss_G: 2.953758, loss_D: 0.190562\n",
            "[Epoch 184/200] [Batch 260/938] loss_G: 3.235044, loss_D: 0.237241\n",
            "[Epoch 184/200] [Batch 270/938] loss_G: 3.481705, loss_D: 0.173577\n",
            "[Epoch 184/200] [Batch 280/938] loss_G: 3.196643, loss_D: 0.291792\n",
            "[Epoch 184/200] [Batch 290/938] loss_G: 3.245082, loss_D: 0.155983\n",
            "[Epoch 184/200] [Batch 300/938] loss_G: 3.255341, loss_D: 0.264005\n",
            "[Epoch 184/200] [Batch 310/938] loss_G: 3.217593, loss_D: 0.212466\n",
            "[Epoch 184/200] [Batch 320/938] loss_G: 3.340595, loss_D: 0.205377\n",
            "[Epoch 184/200] [Batch 330/938] loss_G: 3.199422, loss_D: 0.163044\n",
            "[Epoch 184/200] [Batch 340/938] loss_G: 3.147081, loss_D: 0.205355\n",
            "[Epoch 184/200] [Batch 350/938] loss_G: 3.219213, loss_D: 0.135915\n",
            "[Epoch 184/200] [Batch 360/938] loss_G: 3.402138, loss_D: 0.194909\n",
            "[Epoch 184/200] [Batch 370/938] loss_G: 3.198116, loss_D: 0.277363\n",
            "[Epoch 184/200] [Batch 380/938] loss_G: 3.553943, loss_D: 0.181448\n",
            "[Epoch 184/200] [Batch 390/938] loss_G: 3.146523, loss_D: 0.261117\n",
            "[Epoch 184/200] [Batch 400/938] loss_G: 3.464373, loss_D: 0.184529\n",
            "[Epoch 184/200] [Batch 410/938] loss_G: 2.909444, loss_D: 0.238683\n",
            "[Epoch 184/200] [Batch 420/938] loss_G: 3.214834, loss_D: 0.176524\n",
            "[Epoch 184/200] [Batch 430/938] loss_G: 3.240440, loss_D: 0.218653\n",
            "[Epoch 184/200] [Batch 440/938] loss_G: 3.292006, loss_D: 0.232774\n",
            "[Epoch 184/200] [Batch 450/938] loss_G: 3.216621, loss_D: 0.184236\n",
            "[Epoch 184/200] [Batch 460/938] loss_G: 3.151782, loss_D: 0.186363\n",
            "[Epoch 184/200] [Batch 470/938] loss_G: 3.113957, loss_D: 0.220155\n",
            "[Epoch 184/200] [Batch 480/938] loss_G: 3.510432, loss_D: 0.193154\n",
            "[Epoch 184/200] [Batch 490/938] loss_G: 3.437613, loss_D: 0.232689\n",
            "[Epoch 184/200] [Batch 500/938] loss_G: 3.355512, loss_D: 0.258556\n",
            "[Epoch 184/200] [Batch 510/938] loss_G: 3.468993, loss_D: 0.166261\n",
            "[Epoch 184/200] [Batch 520/938] loss_G: 3.440302, loss_D: 0.152704\n",
            "[Epoch 184/200] [Batch 530/938] loss_G: 3.629476, loss_D: 0.187556\n",
            "[Epoch 184/200] [Batch 540/938] loss_G: 3.498977, loss_D: 0.186816\n",
            "[Epoch 184/200] [Batch 550/938] loss_G: 3.223353, loss_D: 0.141929\n",
            "[Epoch 184/200] [Batch 560/938] loss_G: 2.773052, loss_D: 0.309625\n",
            "[Epoch 184/200] [Batch 570/938] loss_G: 3.321808, loss_D: 0.182499\n",
            "[Epoch 184/200] [Batch 580/938] loss_G: 2.998456, loss_D: 0.193509\n",
            "[Epoch 184/200] [Batch 590/938] loss_G: 3.740698, loss_D: 0.206112\n",
            "[Epoch 184/200] [Batch 600/938] loss_G: 3.081211, loss_D: 0.272588\n",
            "[Epoch 184/200] [Batch 610/938] loss_G: 3.208441, loss_D: 0.182640\n",
            "[Epoch 184/200] [Batch 620/938] loss_G: 3.274045, loss_D: 0.167588\n",
            "[Epoch 184/200] [Batch 630/938] loss_G: 2.955721, loss_D: 0.228522\n",
            "[Epoch 184/200] [Batch 640/938] loss_G: 3.246381, loss_D: 0.289776\n",
            "[Epoch 184/200] [Batch 650/938] loss_G: 2.489020, loss_D: 0.199192\n",
            "[Epoch 184/200] [Batch 660/938] loss_G: 3.272373, loss_D: 0.292958\n",
            "[Epoch 184/200] [Batch 670/938] loss_G: 3.396277, loss_D: 0.216590\n",
            "[Epoch 184/200] [Batch 680/938] loss_G: 3.608033, loss_D: 0.233430\n",
            "[Epoch 184/200] [Batch 690/938] loss_G: 3.147898, loss_D: 0.225776\n",
            "[Epoch 184/200] [Batch 700/938] loss_G: 3.263307, loss_D: 0.131693\n",
            "[Epoch 184/200] [Batch 710/938] loss_G: 3.378633, loss_D: 0.205413\n",
            "[Epoch 184/200] [Batch 720/938] loss_G: 3.009534, loss_D: 0.145706\n",
            "[Epoch 184/200] [Batch 730/938] loss_G: 2.979438, loss_D: 0.279829\n",
            "[Epoch 184/200] [Batch 740/938] loss_G: 3.298863, loss_D: 0.172730\n",
            "[Epoch 184/200] [Batch 750/938] loss_G: 3.163433, loss_D: 0.215311\n",
            "[Epoch 184/200] [Batch 760/938] loss_G: 2.978486, loss_D: 0.236681\n",
            "[Epoch 184/200] [Batch 770/938] loss_G: 3.538475, loss_D: 0.201309\n",
            "[Epoch 184/200] [Batch 780/938] loss_G: 2.968734, loss_D: 0.106927\n",
            "[Epoch 184/200] [Batch 790/938] loss_G: 3.064269, loss_D: 0.209132\n",
            "[Epoch 184/200] [Batch 800/938] loss_G: 3.056046, loss_D: 0.177994\n",
            "[Epoch 184/200] [Batch 810/938] loss_G: 3.077639, loss_D: 0.216493\n",
            "[Epoch 184/200] [Batch 820/938] loss_G: 3.064375, loss_D: 0.257006\n",
            "[Epoch 184/200] [Batch 830/938] loss_G: 3.319119, loss_D: 0.134269\n",
            "[Epoch 184/200] [Batch 840/938] loss_G: 3.349842, loss_D: 0.212834\n",
            "[Epoch 184/200] [Batch 850/938] loss_G: 3.025329, loss_D: 0.163017\n",
            "[Epoch 184/200] [Batch 860/938] loss_G: 3.340919, loss_D: 0.185030\n",
            "[Epoch 184/200] [Batch 870/938] loss_G: 3.147311, loss_D: 0.179357\n",
            "[Epoch 184/200] [Batch 880/938] loss_G: 2.796276, loss_D: 0.189791\n",
            "[Epoch 184/200] [Batch 890/938] loss_G: 3.135042, loss_D: 0.184823\n",
            "[Epoch 184/200] [Batch 900/938] loss_G: 3.008836, loss_D: 0.199178\n",
            "[Epoch 184/200] [Batch 910/938] loss_G: 3.257750, loss_D: 0.203606\n",
            "[Epoch 184/200] [Batch 920/938] loss_G: 3.405203, loss_D: 0.238389\n",
            "[Epoch 184/200] [Batch 930/938] loss_G: 2.784032, loss_D: 0.229892\n",
            "[Epoch 185/200] [Batch 0/938] loss_G: 3.340761, loss_D: 0.192305\n",
            "[Epoch 185/200] [Batch 10/938] loss_G: 3.180745, loss_D: 0.236130\n",
            "[Epoch 185/200] [Batch 20/938] loss_G: 3.297361, loss_D: 0.203824\n",
            "[Epoch 185/200] [Batch 30/938] loss_G: 3.205205, loss_D: 0.288748\n",
            "[Epoch 185/200] [Batch 40/938] loss_G: 3.556636, loss_D: 0.170362\n",
            "[Epoch 185/200] [Batch 50/938] loss_G: 3.037441, loss_D: 0.188328\n",
            "[Epoch 185/200] [Batch 60/938] loss_G: 3.251584, loss_D: 0.148659\n",
            "[Epoch 185/200] [Batch 70/938] loss_G: 3.291647, loss_D: 0.254269\n",
            "[Epoch 185/200] [Batch 80/938] loss_G: 3.105256, loss_D: 0.208038\n",
            "[Epoch 185/200] [Batch 90/938] loss_G: 3.361812, loss_D: 0.258062\n",
            "[Epoch 185/200] [Batch 100/938] loss_G: 3.169518, loss_D: 0.188065\n",
            "[Epoch 185/200] [Batch 110/938] loss_G: 3.158162, loss_D: 0.175194\n",
            "[Epoch 185/200] [Batch 120/938] loss_G: 3.243484, loss_D: 0.199412\n",
            "[Epoch 185/200] [Batch 130/938] loss_G: 2.455455, loss_D: 0.241745\n",
            "[Epoch 185/200] [Batch 140/938] loss_G: 3.107272, loss_D: 0.259023\n",
            "[Epoch 185/200] [Batch 150/938] loss_G: 3.162349, loss_D: 0.235185\n",
            "[Epoch 185/200] [Batch 160/938] loss_G: 3.235477, loss_D: 0.155434\n",
            "[Epoch 185/200] [Batch 170/938] loss_G: 3.094595, loss_D: 0.191913\n",
            "[Epoch 185/200] [Batch 180/938] loss_G: 3.091361, loss_D: 0.244192\n",
            "[Epoch 185/200] [Batch 190/938] loss_G: 3.174893, loss_D: 0.212241\n",
            "[Epoch 185/200] [Batch 200/938] loss_G: 3.393004, loss_D: 0.108043\n",
            "[Epoch 185/200] [Batch 210/938] loss_G: 3.054635, loss_D: 0.224985\n",
            "[Epoch 185/200] [Batch 220/938] loss_G: 3.257572, loss_D: 0.241827\n",
            "[Epoch 185/200] [Batch 230/938] loss_G: 3.334855, loss_D: 0.262329\n",
            "[Epoch 185/200] [Batch 240/938] loss_G: 2.957798, loss_D: 0.267701\n",
            "[Epoch 185/200] [Batch 250/938] loss_G: 3.114254, loss_D: 0.194341\n",
            "[Epoch 185/200] [Batch 260/938] loss_G: 3.495869, loss_D: 0.233890\n",
            "[Epoch 185/200] [Batch 270/938] loss_G: 3.282363, loss_D: 0.168888\n",
            "[Epoch 185/200] [Batch 280/938] loss_G: 3.303133, loss_D: 0.190137\n",
            "[Epoch 185/200] [Batch 290/938] loss_G: 2.945282, loss_D: 0.171551\n",
            "[Epoch 185/200] [Batch 300/938] loss_G: 2.849693, loss_D: 0.195906\n",
            "[Epoch 185/200] [Batch 310/938] loss_G: 3.019936, loss_D: 0.143302\n",
            "[Epoch 185/200] [Batch 320/938] loss_G: 3.234053, loss_D: 0.110800\n",
            "[Epoch 185/200] [Batch 330/938] loss_G: 2.940994, loss_D: 0.138071\n",
            "[Epoch 185/200] [Batch 340/938] loss_G: 2.856327, loss_D: 0.169164\n",
            "[Epoch 185/200] [Batch 350/938] loss_G: 3.209691, loss_D: 0.137342\n",
            "[Epoch 185/200] [Batch 360/938] loss_G: 3.578701, loss_D: 0.205944\n",
            "[Epoch 185/200] [Batch 370/938] loss_G: 3.310456, loss_D: 0.123120\n",
            "[Epoch 185/200] [Batch 380/938] loss_G: 3.483969, loss_D: 0.263916\n",
            "[Epoch 185/200] [Batch 390/938] loss_G: 3.073636, loss_D: 0.226340\n",
            "[Epoch 185/200] [Batch 400/938] loss_G: 2.820138, loss_D: 0.182027\n",
            "[Epoch 185/200] [Batch 410/938] loss_G: 3.001724, loss_D: 0.115000\n",
            "[Epoch 185/200] [Batch 420/938] loss_G: 3.360076, loss_D: 0.177608\n",
            "[Epoch 185/200] [Batch 430/938] loss_G: 3.060217, loss_D: 0.219891\n",
            "[Epoch 185/200] [Batch 440/938] loss_G: 3.304253, loss_D: 0.128386\n",
            "[Epoch 185/200] [Batch 450/938] loss_G: 3.161425, loss_D: 0.155450\n",
            "[Epoch 185/200] [Batch 460/938] loss_G: 2.903817, loss_D: 0.174263\n",
            "[Epoch 185/200] [Batch 470/938] loss_G: 3.396367, loss_D: 0.230709\n",
            "[Epoch 185/200] [Batch 480/938] loss_G: 3.507002, loss_D: 0.273318\n",
            "[Epoch 185/200] [Batch 490/938] loss_G: 2.998325, loss_D: 0.297778\n",
            "[Epoch 185/200] [Batch 500/938] loss_G: 3.371634, loss_D: 0.120448\n",
            "[Epoch 185/200] [Batch 510/938] loss_G: 3.068277, loss_D: 0.267755\n",
            "[Epoch 185/200] [Batch 520/938] loss_G: 3.206215, loss_D: 0.191392\n",
            "[Epoch 185/200] [Batch 530/938] loss_G: 3.221442, loss_D: 0.179426\n",
            "[Epoch 185/200] [Batch 540/938] loss_G: 2.763565, loss_D: 0.249054\n",
            "[Epoch 185/200] [Batch 550/938] loss_G: 3.260400, loss_D: 0.175658\n",
            "[Epoch 185/200] [Batch 560/938] loss_G: 3.412596, loss_D: 0.154982\n",
            "[Epoch 185/200] [Batch 570/938] loss_G: 3.401613, loss_D: 0.083600\n",
            "[Epoch 185/200] [Batch 580/938] loss_G: 3.206136, loss_D: 0.237320\n",
            "[Epoch 185/200] [Batch 590/938] loss_G: 3.207634, loss_D: 0.150251\n",
            "[Epoch 185/200] [Batch 600/938] loss_G: 3.497670, loss_D: 0.127305\n",
            "[Epoch 185/200] [Batch 610/938] loss_G: 3.234298, loss_D: 0.181413\n",
            "[Epoch 185/200] [Batch 620/938] loss_G: 3.135694, loss_D: 0.206316\n",
            "[Epoch 185/200] [Batch 630/938] loss_G: 3.123756, loss_D: 0.211039\n",
            "[Epoch 185/200] [Batch 640/938] loss_G: 3.580602, loss_D: 0.153330\n",
            "[Epoch 185/200] [Batch 650/938] loss_G: 2.548035, loss_D: 0.289752\n",
            "[Epoch 185/200] [Batch 660/938] loss_G: 3.274193, loss_D: 0.158026\n",
            "[Epoch 185/200] [Batch 670/938] loss_G: 3.662793, loss_D: 0.240277\n",
            "[Epoch 185/200] [Batch 680/938] loss_G: 3.018640, loss_D: 0.222639\n",
            "[Epoch 185/200] [Batch 690/938] loss_G: 3.226689, loss_D: 0.267281\n",
            "[Epoch 185/200] [Batch 700/938] loss_G: 3.031707, loss_D: 0.302914\n",
            "[Epoch 185/200] [Batch 710/938] loss_G: 3.626861, loss_D: 0.205137\n",
            "[Epoch 185/200] [Batch 720/938] loss_G: 3.547910, loss_D: 0.140455\n",
            "[Epoch 185/200] [Batch 730/938] loss_G: 3.174697, loss_D: 0.282176\n",
            "[Epoch 185/200] [Batch 740/938] loss_G: 2.920861, loss_D: 0.137658\n",
            "[Epoch 185/200] [Batch 750/938] loss_G: 3.130320, loss_D: 0.128218\n",
            "[Epoch 185/200] [Batch 760/938] loss_G: 2.875020, loss_D: 0.267725\n",
            "[Epoch 185/200] [Batch 770/938] loss_G: 3.620282, loss_D: 0.185661\n",
            "[Epoch 185/200] [Batch 780/938] loss_G: 3.107612, loss_D: 0.261815\n",
            "[Epoch 185/200] [Batch 790/938] loss_G: 2.993388, loss_D: 0.224076\n",
            "[Epoch 185/200] [Batch 800/938] loss_G: 3.004836, loss_D: 0.128938\n",
            "[Epoch 185/200] [Batch 810/938] loss_G: 3.088222, loss_D: 0.234557\n",
            "[Epoch 185/200] [Batch 820/938] loss_G: 3.438379, loss_D: 0.185005\n",
            "[Epoch 185/200] [Batch 830/938] loss_G: 2.550650, loss_D: 0.165875\n",
            "[Epoch 185/200] [Batch 840/938] loss_G: 3.197875, loss_D: 0.179378\n",
            "[Epoch 185/200] [Batch 850/938] loss_G: 3.261193, loss_D: 0.147147\n",
            "[Epoch 185/200] [Batch 860/938] loss_G: 3.303149, loss_D: 0.230797\n",
            "[Epoch 185/200] [Batch 870/938] loss_G: 3.446767, loss_D: 0.171182\n",
            "[Epoch 185/200] [Batch 880/938] loss_G: 2.714180, loss_D: 0.278579\n",
            "[Epoch 185/200] [Batch 890/938] loss_G: 2.739149, loss_D: 0.213227\n",
            "[Epoch 185/200] [Batch 900/938] loss_G: 3.449794, loss_D: 0.231087\n",
            "[Epoch 185/200] [Batch 910/938] loss_G: 3.233550, loss_D: 0.171454\n",
            "[Epoch 185/200] [Batch 920/938] loss_G: 3.393487, loss_D: 0.161401\n",
            "[Epoch 185/200] [Batch 930/938] loss_G: 3.739774, loss_D: 0.137371\n",
            "[Epoch 186/200] [Batch 0/938] loss_G: 2.853505, loss_D: 0.131054\n",
            "[Epoch 186/200] [Batch 10/938] loss_G: 3.182374, loss_D: 0.173454\n",
            "[Epoch 186/200] [Batch 20/938] loss_G: 3.566020, loss_D: 0.246855\n",
            "[Epoch 186/200] [Batch 30/938] loss_G: 3.415285, loss_D: 0.171930\n",
            "[Epoch 186/200] [Batch 40/938] loss_G: 3.649117, loss_D: 0.220087\n",
            "[Epoch 186/200] [Batch 50/938] loss_G: 3.779644, loss_D: 0.178894\n",
            "[Epoch 186/200] [Batch 60/938] loss_G: 3.049296, loss_D: 0.285055\n",
            "[Epoch 186/200] [Batch 70/938] loss_G: 3.402498, loss_D: 0.250216\n",
            "[Epoch 186/200] [Batch 80/938] loss_G: 3.270880, loss_D: 0.176422\n",
            "[Epoch 186/200] [Batch 90/938] loss_G: 3.317498, loss_D: 0.157836\n",
            "[Epoch 186/200] [Batch 100/938] loss_G: 3.438533, loss_D: 0.135363\n",
            "[Epoch 186/200] [Batch 110/938] loss_G: 3.522704, loss_D: 0.101876\n",
            "[Epoch 186/200] [Batch 120/938] loss_G: 3.296114, loss_D: 0.256603\n",
            "[Epoch 186/200] [Batch 130/938] loss_G: 3.291251, loss_D: 0.207176\n",
            "[Epoch 186/200] [Batch 140/938] loss_G: 3.331268, loss_D: 0.262661\n",
            "[Epoch 186/200] [Batch 150/938] loss_G: 3.275849, loss_D: 0.143927\n",
            "[Epoch 186/200] [Batch 160/938] loss_G: 3.297295, loss_D: 0.207339\n",
            "[Epoch 186/200] [Batch 170/938] loss_G: 3.468495, loss_D: 0.128221\n",
            "[Epoch 186/200] [Batch 180/938] loss_G: 3.392387, loss_D: 0.152180\n",
            "[Epoch 186/200] [Batch 190/938] loss_G: 3.422672, loss_D: 0.100953\n",
            "[Epoch 186/200] [Batch 200/938] loss_G: 3.521916, loss_D: 0.162752\n",
            "[Epoch 186/200] [Batch 210/938] loss_G: 3.463563, loss_D: 0.192969\n",
            "[Epoch 186/200] [Batch 220/938] loss_G: 3.052468, loss_D: 0.116400\n",
            "[Epoch 186/200] [Batch 230/938] loss_G: 3.486847, loss_D: 0.218778\n",
            "[Epoch 186/200] [Batch 240/938] loss_G: 3.326563, loss_D: 0.204560\n",
            "[Epoch 186/200] [Batch 250/938] loss_G: 3.299609, loss_D: 0.149696\n",
            "[Epoch 186/200] [Batch 260/938] loss_G: 3.086071, loss_D: 0.306421\n",
            "[Epoch 186/200] [Batch 270/938] loss_G: 3.322950, loss_D: 0.207449\n",
            "[Epoch 186/200] [Batch 280/938] loss_G: 3.361204, loss_D: 0.142758\n",
            "[Epoch 186/200] [Batch 290/938] loss_G: 2.974298, loss_D: 0.245578\n",
            "[Epoch 186/200] [Batch 300/938] loss_G: 3.026590, loss_D: 0.218286\n",
            "[Epoch 186/200] [Batch 310/938] loss_G: 3.097004, loss_D: 0.214308\n",
            "[Epoch 186/200] [Batch 320/938] loss_G: 3.254543, loss_D: 0.264065\n",
            "[Epoch 186/200] [Batch 330/938] loss_G: 3.152875, loss_D: 0.198157\n",
            "[Epoch 186/200] [Batch 340/938] loss_G: 3.397040, loss_D: 0.214661\n",
            "[Epoch 186/200] [Batch 350/938] loss_G: 2.999954, loss_D: 0.190601\n",
            "[Epoch 186/200] [Batch 360/938] loss_G: 2.954909, loss_D: 0.163689\n",
            "[Epoch 186/200] [Batch 370/938] loss_G: 3.131834, loss_D: 0.179437\n",
            "[Epoch 186/200] [Batch 380/938] loss_G: 2.372289, loss_D: 0.278102\n",
            "[Epoch 186/200] [Batch 390/938] loss_G: 3.142041, loss_D: 0.154739\n",
            "[Epoch 186/200] [Batch 400/938] loss_G: 2.941576, loss_D: 0.256188\n",
            "[Epoch 186/200] [Batch 410/938] loss_G: 3.645468, loss_D: 0.149724\n",
            "[Epoch 186/200] [Batch 420/938] loss_G: 2.979219, loss_D: 0.233415\n",
            "[Epoch 186/200] [Batch 430/938] loss_G: 3.429903, loss_D: 0.178242\n",
            "[Epoch 186/200] [Batch 440/938] loss_G: 2.741703, loss_D: 0.187425\n",
            "[Epoch 186/200] [Batch 450/938] loss_G: 3.204726, loss_D: 0.227354\n",
            "[Epoch 186/200] [Batch 460/938] loss_G: 2.997063, loss_D: 0.212015\n",
            "[Epoch 186/200] [Batch 470/938] loss_G: 3.199892, loss_D: 0.249835\n",
            "[Epoch 186/200] [Batch 480/938] loss_G: 3.098827, loss_D: 0.222829\n",
            "[Epoch 186/200] [Batch 490/938] loss_G: 2.989249, loss_D: 0.231144\n",
            "[Epoch 186/200] [Batch 500/938] loss_G: 3.092910, loss_D: 0.229081\n",
            "[Epoch 186/200] [Batch 510/938] loss_G: 2.931607, loss_D: 0.272615\n",
            "[Epoch 186/200] [Batch 520/938] loss_G: 2.949393, loss_D: 0.197382\n",
            "[Epoch 186/200] [Batch 530/938] loss_G: 3.564966, loss_D: 0.131375\n",
            "[Epoch 186/200] [Batch 540/938] loss_G: 3.626664, loss_D: 0.173122\n",
            "[Epoch 186/200] [Batch 550/938] loss_G: 3.132027, loss_D: 0.118119\n",
            "[Epoch 186/200] [Batch 560/938] loss_G: 3.413299, loss_D: 0.185841\n",
            "[Epoch 186/200] [Batch 570/938] loss_G: 2.750293, loss_D: 0.275999\n",
            "[Epoch 186/200] [Batch 580/938] loss_G: 2.934977, loss_D: 0.117883\n",
            "[Epoch 186/200] [Batch 590/938] loss_G: 3.540610, loss_D: 0.214924\n",
            "[Epoch 186/200] [Batch 600/938] loss_G: 3.322259, loss_D: 0.201228\n",
            "[Epoch 186/200] [Batch 610/938] loss_G: 3.542116, loss_D: 0.202803\n",
            "[Epoch 186/200] [Batch 620/938] loss_G: 3.478519, loss_D: 0.179158\n",
            "[Epoch 186/200] [Batch 630/938] loss_G: 2.840368, loss_D: 0.252670\n",
            "[Epoch 186/200] [Batch 640/938] loss_G: 3.304112, loss_D: 0.182619\n",
            "[Epoch 186/200] [Batch 650/938] loss_G: 3.312456, loss_D: 0.284813\n",
            "[Epoch 186/200] [Batch 660/938] loss_G: 3.067769, loss_D: 0.225782\n",
            "[Epoch 186/200] [Batch 670/938] loss_G: 3.177203, loss_D: 0.208201\n",
            "[Epoch 186/200] [Batch 680/938] loss_G: 2.773128, loss_D: 0.169937\n",
            "[Epoch 186/200] [Batch 690/938] loss_G: 3.083686, loss_D: 0.192616\n",
            "[Epoch 186/200] [Batch 700/938] loss_G: 3.256886, loss_D: 0.148695\n",
            "[Epoch 186/200] [Batch 710/938] loss_G: 3.450520, loss_D: 0.162656\n",
            "[Epoch 186/200] [Batch 720/938] loss_G: 3.293784, loss_D: 0.157306\n",
            "[Epoch 186/200] [Batch 730/938] loss_G: 3.397149, loss_D: 0.204383\n",
            "[Epoch 186/200] [Batch 740/938] loss_G: 3.185360, loss_D: 0.173791\n",
            "[Epoch 186/200] [Batch 750/938] loss_G: 3.229476, loss_D: 0.175046\n",
            "[Epoch 186/200] [Batch 760/938] loss_G: 3.448604, loss_D: 0.315023\n",
            "[Epoch 186/200] [Batch 770/938] loss_G: 3.054087, loss_D: 0.199965\n",
            "[Epoch 186/200] [Batch 780/938] loss_G: 3.368967, loss_D: 0.292789\n",
            "[Epoch 186/200] [Batch 790/938] loss_G: 3.107620, loss_D: 0.220420\n",
            "[Epoch 186/200] [Batch 800/938] loss_G: 2.839352, loss_D: 0.196676\n",
            "[Epoch 186/200] [Batch 810/938] loss_G: 3.495169, loss_D: 0.187112\n",
            "[Epoch 186/200] [Batch 820/938] loss_G: 3.460096, loss_D: 0.174232\n",
            "[Epoch 186/200] [Batch 830/938] loss_G: 2.856012, loss_D: 0.227769\n",
            "[Epoch 186/200] [Batch 840/938] loss_G: 3.129566, loss_D: 0.215171\n",
            "[Epoch 186/200] [Batch 850/938] loss_G: 2.941100, loss_D: 0.184488\n",
            "[Epoch 186/200] [Batch 860/938] loss_G: 3.138657, loss_D: 0.172981\n",
            "[Epoch 186/200] [Batch 870/938] loss_G: 3.212494, loss_D: 0.181009\n",
            "[Epoch 186/200] [Batch 880/938] loss_G: 3.562337, loss_D: 0.181397\n",
            "[Epoch 186/200] [Batch 890/938] loss_G: 3.342351, loss_D: 0.126767\n",
            "[Epoch 186/200] [Batch 900/938] loss_G: 3.190392, loss_D: 0.265473\n",
            "[Epoch 186/200] [Batch 910/938] loss_G: 3.102024, loss_D: 0.248757\n",
            "[Epoch 186/200] [Batch 920/938] loss_G: 3.483306, loss_D: 0.123818\n",
            "[Epoch 186/200] [Batch 930/938] loss_G: 3.099638, loss_D: 0.206725\n",
            "[Epoch 187/200] [Batch 0/938] loss_G: 3.227834, loss_D: 0.367592\n",
            "[Epoch 187/200] [Batch 10/938] loss_G: 3.252656, loss_D: 0.219322\n",
            "[Epoch 187/200] [Batch 20/938] loss_G: 3.086369, loss_D: 0.205647\n",
            "[Epoch 187/200] [Batch 30/938] loss_G: 3.178758, loss_D: 0.205081\n",
            "[Epoch 187/200] [Batch 40/938] loss_G: 2.877284, loss_D: 0.275923\n",
            "[Epoch 187/200] [Batch 50/938] loss_G: 3.436018, loss_D: 0.119304\n",
            "[Epoch 187/200] [Batch 60/938] loss_G: 2.957605, loss_D: 0.161666\n",
            "[Epoch 187/200] [Batch 70/938] loss_G: 3.386246, loss_D: 0.211322\n",
            "[Epoch 187/200] [Batch 80/938] loss_G: 3.360131, loss_D: 0.156549\n",
            "[Epoch 187/200] [Batch 90/938] loss_G: 3.254577, loss_D: 0.216164\n",
            "[Epoch 187/200] [Batch 100/938] loss_G: 3.026778, loss_D: 0.197088\n",
            "[Epoch 187/200] [Batch 110/938] loss_G: 3.685149, loss_D: 0.298263\n",
            "[Epoch 187/200] [Batch 120/938] loss_G: 3.291301, loss_D: 0.139574\n",
            "[Epoch 187/200] [Batch 130/938] loss_G: 3.586205, loss_D: 0.211901\n",
            "[Epoch 187/200] [Batch 140/938] loss_G: 3.235696, loss_D: 0.217257\n",
            "[Epoch 187/200] [Batch 150/938] loss_G: 3.157732, loss_D: 0.156691\n",
            "[Epoch 187/200] [Batch 160/938] loss_G: 3.849830, loss_D: 0.126552\n",
            "[Epoch 187/200] [Batch 170/938] loss_G: 3.439875, loss_D: 0.190627\n",
            "[Epoch 187/200] [Batch 180/938] loss_G: 3.349813, loss_D: 0.211017\n",
            "[Epoch 187/200] [Batch 190/938] loss_G: 3.198891, loss_D: 0.246169\n",
            "[Epoch 187/200] [Batch 200/938] loss_G: 3.467947, loss_D: 0.223994\n",
            "[Epoch 187/200] [Batch 210/938] loss_G: 3.503736, loss_D: 0.185002\n",
            "[Epoch 187/200] [Batch 220/938] loss_G: 3.210566, loss_D: 0.172243\n",
            "[Epoch 187/200] [Batch 230/938] loss_G: 3.224565, loss_D: 0.216496\n",
            "[Epoch 187/200] [Batch 240/938] loss_G: 3.137622, loss_D: 0.214027\n",
            "[Epoch 187/200] [Batch 250/938] loss_G: 3.310863, loss_D: 0.232650\n",
            "[Epoch 187/200] [Batch 260/938] loss_G: 3.080946, loss_D: 0.268493\n",
            "[Epoch 187/200] [Batch 270/938] loss_G: 3.420401, loss_D: 0.118131\n",
            "[Epoch 187/200] [Batch 280/938] loss_G: 3.369405, loss_D: 0.167178\n",
            "[Epoch 187/200] [Batch 290/938] loss_G: 3.055636, loss_D: 0.265043\n",
            "[Epoch 187/200] [Batch 300/938] loss_G: 3.043573, loss_D: 0.228819\n",
            "[Epoch 187/200] [Batch 310/938] loss_G: 2.985983, loss_D: 0.137639\n",
            "[Epoch 187/200] [Batch 320/938] loss_G: 3.210689, loss_D: 0.161447\n",
            "[Epoch 187/200] [Batch 330/938] loss_G: 3.139810, loss_D: 0.122602\n",
            "[Epoch 187/200] [Batch 340/938] loss_G: 3.007968, loss_D: 0.274170\n",
            "[Epoch 187/200] [Batch 350/938] loss_G: 3.358490, loss_D: 0.254843\n",
            "[Epoch 187/200] [Batch 360/938] loss_G: 3.257945, loss_D: 0.203603\n",
            "[Epoch 187/200] [Batch 370/938] loss_G: 3.224702, loss_D: 0.179870\n",
            "[Epoch 187/200] [Batch 380/938] loss_G: 3.001360, loss_D: 0.176579\n",
            "[Epoch 187/200] [Batch 390/938] loss_G: 3.326009, loss_D: 0.131287\n",
            "[Epoch 187/200] [Batch 400/938] loss_G: 2.862409, loss_D: 0.218937\n",
            "[Epoch 187/200] [Batch 410/938] loss_G: 3.844361, loss_D: 0.150667\n",
            "[Epoch 187/200] [Batch 420/938] loss_G: 3.543328, loss_D: 0.234505\n",
            "[Epoch 187/200] [Batch 430/938] loss_G: 3.293460, loss_D: 0.136908\n",
            "[Epoch 187/200] [Batch 440/938] loss_G: 3.272491, loss_D: 0.147573\n",
            "[Epoch 187/200] [Batch 450/938] loss_G: 3.303219, loss_D: 0.283538\n",
            "[Epoch 187/200] [Batch 460/938] loss_G: 3.036246, loss_D: 0.184924\n",
            "[Epoch 187/200] [Batch 470/938] loss_G: 3.219128, loss_D: 0.227622\n",
            "[Epoch 187/200] [Batch 480/938] loss_G: 3.263855, loss_D: 0.231348\n",
            "[Epoch 187/200] [Batch 490/938] loss_G: 2.658485, loss_D: 0.179621\n",
            "[Epoch 187/200] [Batch 500/938] loss_G: 3.162084, loss_D: 0.112806\n",
            "[Epoch 187/200] [Batch 510/938] loss_G: 3.328804, loss_D: 0.327272\n",
            "[Epoch 187/200] [Batch 520/938] loss_G: 2.728715, loss_D: 0.207070\n",
            "[Epoch 187/200] [Batch 530/938] loss_G: 2.801676, loss_D: 0.213522\n",
            "[Epoch 187/200] [Batch 540/938] loss_G: 3.218225, loss_D: 0.255172\n",
            "[Epoch 187/200] [Batch 550/938] loss_G: 3.168121, loss_D: 0.148611\n",
            "[Epoch 187/200] [Batch 560/938] loss_G: 3.183255, loss_D: 0.182768\n",
            "[Epoch 187/200] [Batch 570/938] loss_G: 3.070565, loss_D: 0.180778\n",
            "[Epoch 187/200] [Batch 580/938] loss_G: 3.236979, loss_D: 0.217590\n",
            "[Epoch 187/200] [Batch 590/938] loss_G: 2.960111, loss_D: 0.160372\n",
            "[Epoch 187/200] [Batch 600/938] loss_G: 3.468072, loss_D: 0.169786\n",
            "[Epoch 187/200] [Batch 610/938] loss_G: 3.233523, loss_D: 0.149727\n",
            "[Epoch 187/200] [Batch 620/938] loss_G: 3.470160, loss_D: 0.101295\n",
            "[Epoch 187/200] [Batch 630/938] loss_G: 3.796072, loss_D: 0.215435\n",
            "[Epoch 187/200] [Batch 640/938] loss_G: 3.433146, loss_D: 0.172570\n",
            "[Epoch 187/200] [Batch 650/938] loss_G: 3.084363, loss_D: 0.273390\n",
            "[Epoch 187/200] [Batch 660/938] loss_G: 3.164018, loss_D: 0.197479\n",
            "[Epoch 187/200] [Batch 670/938] loss_G: 3.236532, loss_D: 0.184160\n",
            "[Epoch 187/200] [Batch 680/938] loss_G: 3.315885, loss_D: 0.246737\n",
            "[Epoch 187/200] [Batch 690/938] loss_G: 2.973896, loss_D: 0.154376\n",
            "[Epoch 187/200] [Batch 700/938] loss_G: 3.348256, loss_D: 0.254538\n",
            "[Epoch 187/200] [Batch 710/938] loss_G: 3.089654, loss_D: 0.179822\n",
            "[Epoch 187/200] [Batch 720/938] loss_G: 3.266812, loss_D: 0.215026\n",
            "[Epoch 187/200] [Batch 730/938] loss_G: 3.098972, loss_D: 0.231261\n",
            "[Epoch 187/200] [Batch 740/938] loss_G: 3.371466, loss_D: 0.259074\n",
            "[Epoch 187/200] [Batch 750/938] loss_G: 2.971426, loss_D: 0.207861\n",
            "[Epoch 187/200] [Batch 760/938] loss_G: 3.661894, loss_D: 0.262665\n",
            "[Epoch 187/200] [Batch 770/938] loss_G: 3.033621, loss_D: 0.304628\n",
            "[Epoch 187/200] [Batch 780/938] loss_G: 3.307497, loss_D: 0.177307\n",
            "[Epoch 187/200] [Batch 790/938] loss_G: 3.161581, loss_D: 0.324741\n",
            "[Epoch 187/200] [Batch 800/938] loss_G: 3.170271, loss_D: 0.206762\n",
            "[Epoch 187/200] [Batch 810/938] loss_G: 2.878292, loss_D: 0.280055\n",
            "[Epoch 187/200] [Batch 820/938] loss_G: 3.333157, loss_D: 0.258472\n",
            "[Epoch 187/200] [Batch 830/938] loss_G: 3.100460, loss_D: 0.211842\n",
            "[Epoch 187/200] [Batch 840/938] loss_G: 3.311680, loss_D: 0.180096\n",
            "[Epoch 187/200] [Batch 850/938] loss_G: 3.342668, loss_D: 0.158599\n",
            "[Epoch 187/200] [Batch 860/938] loss_G: 3.667270, loss_D: 0.267981\n",
            "[Epoch 187/200] [Batch 870/938] loss_G: 3.685853, loss_D: 0.185109\n",
            "[Epoch 187/200] [Batch 880/938] loss_G: 3.179898, loss_D: 0.301909\n",
            "[Epoch 187/200] [Batch 890/938] loss_G: 3.641560, loss_D: 0.132529\n",
            "[Epoch 187/200] [Batch 900/938] loss_G: 3.253768, loss_D: 0.159413\n",
            "[Epoch 187/200] [Batch 910/938] loss_G: 2.945477, loss_D: 0.212101\n",
            "[Epoch 187/200] [Batch 920/938] loss_G: 3.191419, loss_D: 0.193597\n",
            "[Epoch 187/200] [Batch 930/938] loss_G: 3.056166, loss_D: 0.244723\n",
            "[Epoch 188/200] [Batch 0/938] loss_G: 3.090611, loss_D: 0.271831\n",
            "[Epoch 188/200] [Batch 10/938] loss_G: 3.312061, loss_D: 0.202495\n",
            "[Epoch 188/200] [Batch 20/938] loss_G: 3.446873, loss_D: 0.160333\n",
            "[Epoch 188/200] [Batch 30/938] loss_G: 3.101970, loss_D: 0.153823\n",
            "[Epoch 188/200] [Batch 40/938] loss_G: 3.295964, loss_D: 0.232445\n",
            "[Epoch 188/200] [Batch 50/938] loss_G: 2.991118, loss_D: 0.290633\n",
            "[Epoch 188/200] [Batch 60/938] loss_G: 3.189533, loss_D: 0.191302\n",
            "[Epoch 188/200] [Batch 70/938] loss_G: 3.449759, loss_D: 0.100647\n",
            "[Epoch 188/200] [Batch 80/938] loss_G: 3.062505, loss_D: 0.208588\n",
            "[Epoch 188/200] [Batch 90/938] loss_G: 3.354206, loss_D: 0.270426\n",
            "[Epoch 188/200] [Batch 100/938] loss_G: 3.163091, loss_D: 0.224368\n",
            "[Epoch 188/200] [Batch 110/938] loss_G: 3.110329, loss_D: 0.161775\n",
            "[Epoch 188/200] [Batch 120/938] loss_G: 3.573772, loss_D: 0.221818\n",
            "[Epoch 188/200] [Batch 130/938] loss_G: 3.103328, loss_D: 0.193179\n",
            "[Epoch 188/200] [Batch 140/938] loss_G: 2.801178, loss_D: 0.245303\n",
            "[Epoch 188/200] [Batch 150/938] loss_G: 3.080225, loss_D: 0.171047\n",
            "[Epoch 188/200] [Batch 160/938] loss_G: 3.678536, loss_D: 0.163683\n",
            "[Epoch 188/200] [Batch 170/938] loss_G: 3.174830, loss_D: 0.202767\n",
            "[Epoch 188/200] [Batch 180/938] loss_G: 3.255995, loss_D: 0.143989\n",
            "[Epoch 188/200] [Batch 190/938] loss_G: 3.370477, loss_D: 0.218643\n",
            "[Epoch 188/200] [Batch 200/938] loss_G: 3.182168, loss_D: 0.167403\n",
            "[Epoch 188/200] [Batch 210/938] loss_G: 3.235143, loss_D: 0.274406\n",
            "[Epoch 188/200] [Batch 220/938] loss_G: 3.498299, loss_D: 0.122385\n",
            "[Epoch 188/200] [Batch 230/938] loss_G: 3.656882, loss_D: 0.209232\n",
            "[Epoch 188/200] [Batch 240/938] loss_G: 3.599024, loss_D: 0.192269\n",
            "[Epoch 188/200] [Batch 250/938] loss_G: 3.101314, loss_D: 0.180063\n",
            "[Epoch 188/200] [Batch 260/938] loss_G: 3.228222, loss_D: 0.204206\n",
            "[Epoch 188/200] [Batch 270/938] loss_G: 3.358208, loss_D: 0.225355\n",
            "[Epoch 188/200] [Batch 280/938] loss_G: 2.956821, loss_D: 0.200720\n",
            "[Epoch 188/200] [Batch 290/938] loss_G: 2.693110, loss_D: 0.146029\n",
            "[Epoch 188/200] [Batch 300/938] loss_G: 3.389994, loss_D: 0.188333\n",
            "[Epoch 188/200] [Batch 310/938] loss_G: 3.716145, loss_D: 0.209991\n",
            "[Epoch 188/200] [Batch 320/938] loss_G: 3.337834, loss_D: 0.150479\n",
            "[Epoch 188/200] [Batch 330/938] loss_G: 3.037962, loss_D: 0.196348\n",
            "[Epoch 188/200] [Batch 340/938] loss_G: 3.072062, loss_D: 0.233644\n",
            "[Epoch 188/200] [Batch 350/938] loss_G: 3.500549, loss_D: 0.183738\n",
            "[Epoch 188/200] [Batch 360/938] loss_G: 3.188237, loss_D: 0.183171\n",
            "[Epoch 188/200] [Batch 370/938] loss_G: 3.216594, loss_D: 0.159127\n",
            "[Epoch 188/200] [Batch 380/938] loss_G: 3.443043, loss_D: 0.345123\n",
            "[Epoch 188/200] [Batch 390/938] loss_G: 3.069453, loss_D: 0.183230\n",
            "[Epoch 188/200] [Batch 400/938] loss_G: 3.402633, loss_D: 0.215823\n",
            "[Epoch 188/200] [Batch 410/938] loss_G: 3.136239, loss_D: 0.221240\n",
            "[Epoch 188/200] [Batch 420/938] loss_G: 3.051552, loss_D: 0.202672\n",
            "[Epoch 188/200] [Batch 430/938] loss_G: 2.887387, loss_D: 0.207022\n",
            "[Epoch 188/200] [Batch 440/938] loss_G: 3.200981, loss_D: 0.203775\n",
            "[Epoch 188/200] [Batch 450/938] loss_G: 3.055621, loss_D: 0.166278\n",
            "[Epoch 188/200] [Batch 460/938] loss_G: 3.019515, loss_D: 0.268678\n",
            "[Epoch 188/200] [Batch 470/938] loss_G: 3.420865, loss_D: 0.228311\n",
            "[Epoch 188/200] [Batch 480/938] loss_G: 2.839813, loss_D: 0.208321\n",
            "[Epoch 188/200] [Batch 490/938] loss_G: 3.041811, loss_D: 0.205195\n",
            "[Epoch 188/200] [Batch 500/938] loss_G: 3.258976, loss_D: 0.199746\n",
            "[Epoch 188/200] [Batch 510/938] loss_G: 3.125940, loss_D: 0.234469\n",
            "[Epoch 188/200] [Batch 520/938] loss_G: 3.692923, loss_D: 0.156037\n",
            "[Epoch 188/200] [Batch 530/938] loss_G: 3.210235, loss_D: 0.228951\n",
            "[Epoch 188/200] [Batch 540/938] loss_G: 3.208316, loss_D: 0.225660\n",
            "[Epoch 188/200] [Batch 550/938] loss_G: 3.012077, loss_D: 0.215979\n",
            "[Epoch 188/200] [Batch 560/938] loss_G: 3.168099, loss_D: 0.165293\n",
            "[Epoch 188/200] [Batch 570/938] loss_G: 3.298996, loss_D: 0.215902\n",
            "[Epoch 188/200] [Batch 580/938] loss_G: 3.118884, loss_D: 0.174943\n",
            "[Epoch 188/200] [Batch 590/938] loss_G: 3.119005, loss_D: 0.170034\n",
            "[Epoch 188/200] [Batch 600/938] loss_G: 3.176600, loss_D: 0.192245\n",
            "[Epoch 188/200] [Batch 610/938] loss_G: 3.088138, loss_D: 0.218034\n",
            "[Epoch 188/200] [Batch 620/938] loss_G: 3.632949, loss_D: 0.273522\n",
            "[Epoch 188/200] [Batch 630/938] loss_G: 3.368275, loss_D: 0.258923\n",
            "[Epoch 188/200] [Batch 640/938] loss_G: 3.378666, loss_D: 0.162015\n",
            "[Epoch 188/200] [Batch 650/938] loss_G: 3.053299, loss_D: 0.169570\n",
            "[Epoch 188/200] [Batch 660/938] loss_G: 3.659204, loss_D: 0.114363\n",
            "[Epoch 188/200] [Batch 670/938] loss_G: 3.256493, loss_D: 0.283842\n",
            "[Epoch 188/200] [Batch 680/938] loss_G: 3.013265, loss_D: 0.240630\n",
            "[Epoch 188/200] [Batch 690/938] loss_G: 3.082723, loss_D: 0.235808\n",
            "[Epoch 188/200] [Batch 700/938] loss_G: 3.383486, loss_D: 0.245776\n",
            "[Epoch 188/200] [Batch 710/938] loss_G: 3.016982, loss_D: 0.160416\n",
            "[Epoch 188/200] [Batch 720/938] loss_G: 3.082766, loss_D: 0.199253\n",
            "[Epoch 188/200] [Batch 730/938] loss_G: 3.425828, loss_D: 0.298566\n",
            "[Epoch 188/200] [Batch 740/938] loss_G: 3.111837, loss_D: 0.156729\n",
            "[Epoch 188/200] [Batch 750/938] loss_G: 2.835702, loss_D: 0.228905\n",
            "[Epoch 188/200] [Batch 760/938] loss_G: 3.155292, loss_D: 0.201499\n",
            "[Epoch 188/200] [Batch 770/938] loss_G: 3.400360, loss_D: 0.226703\n",
            "[Epoch 188/200] [Batch 780/938] loss_G: 3.335076, loss_D: 0.194798\n",
            "[Epoch 188/200] [Batch 790/938] loss_G: 3.250766, loss_D: 0.260408\n",
            "[Epoch 188/200] [Batch 800/938] loss_G: 3.261821, loss_D: 0.289570\n",
            "[Epoch 188/200] [Batch 810/938] loss_G: 2.909890, loss_D: 0.230731\n",
            "[Epoch 188/200] [Batch 820/938] loss_G: 3.172151, loss_D: 0.183071\n",
            "[Epoch 188/200] [Batch 830/938] loss_G: 3.672658, loss_D: 0.192975\n",
            "[Epoch 188/200] [Batch 840/938] loss_G: 3.077865, loss_D: 0.144035\n",
            "[Epoch 188/200] [Batch 850/938] loss_G: 2.733798, loss_D: 0.186716\n",
            "[Epoch 188/200] [Batch 860/938] loss_G: 2.942959, loss_D: 0.264350\n",
            "[Epoch 188/200] [Batch 870/938] loss_G: 2.729918, loss_D: 0.236103\n",
            "[Epoch 188/200] [Batch 880/938] loss_G: 3.174076, loss_D: 0.197317\n",
            "[Epoch 188/200] [Batch 890/938] loss_G: 3.315439, loss_D: 0.223696\n",
            "[Epoch 188/200] [Batch 900/938] loss_G: 3.195722, loss_D: 0.154819\n",
            "[Epoch 188/200] [Batch 910/938] loss_G: 3.410740, loss_D: 0.147149\n",
            "[Epoch 188/200] [Batch 920/938] loss_G: 3.045686, loss_D: 0.089007\n",
            "[Epoch 188/200] [Batch 930/938] loss_G: 3.276737, loss_D: 0.154106\n",
            "[Epoch 189/200] [Batch 0/938] loss_G: 3.702023, loss_D: 0.208842\n",
            "[Epoch 189/200] [Batch 10/938] loss_G: 3.326840, loss_D: 0.188473\n",
            "[Epoch 189/200] [Batch 20/938] loss_G: 3.037623, loss_D: 0.205608\n",
            "[Epoch 189/200] [Batch 30/938] loss_G: 3.920029, loss_D: 0.115048\n",
            "[Epoch 189/200] [Batch 40/938] loss_G: 3.133321, loss_D: 0.168602\n",
            "[Epoch 189/200] [Batch 50/938] loss_G: 3.513786, loss_D: 0.183791\n",
            "[Epoch 189/200] [Batch 60/938] loss_G: 3.553566, loss_D: 0.166598\n",
            "[Epoch 189/200] [Batch 70/938] loss_G: 3.801142, loss_D: 0.164259\n",
            "[Epoch 189/200] [Batch 80/938] loss_G: 3.464455, loss_D: 0.169654\n",
            "[Epoch 189/200] [Batch 90/938] loss_G: 3.293791, loss_D: 0.210849\n",
            "[Epoch 189/200] [Batch 100/938] loss_G: 3.269826, loss_D: 0.171008\n",
            "[Epoch 189/200] [Batch 110/938] loss_G: 2.996312, loss_D: 0.163240\n",
            "[Epoch 189/200] [Batch 120/938] loss_G: 2.962806, loss_D: 0.249429\n",
            "[Epoch 189/200] [Batch 130/938] loss_G: 3.268102, loss_D: 0.279146\n",
            "[Epoch 189/200] [Batch 140/938] loss_G: 3.545709, loss_D: 0.185499\n",
            "[Epoch 189/200] [Batch 150/938] loss_G: 3.194047, loss_D: 0.176612\n",
            "[Epoch 189/200] [Batch 160/938] loss_G: 2.974481, loss_D: 0.176673\n",
            "[Epoch 189/200] [Batch 170/938] loss_G: 3.652056, loss_D: 0.112077\n",
            "[Epoch 189/200] [Batch 180/938] loss_G: 2.806986, loss_D: 0.235794\n",
            "[Epoch 189/200] [Batch 190/938] loss_G: 3.295423, loss_D: 0.203355\n",
            "[Epoch 189/200] [Batch 200/938] loss_G: 3.475089, loss_D: 0.231985\n",
            "[Epoch 189/200] [Batch 210/938] loss_G: 3.237305, loss_D: 0.207809\n",
            "[Epoch 189/200] [Batch 220/938] loss_G: 3.170182, loss_D: 0.239089\n",
            "[Epoch 189/200] [Batch 230/938] loss_G: 2.873809, loss_D: 0.185065\n",
            "[Epoch 189/200] [Batch 240/938] loss_G: 3.328668, loss_D: 0.229843\n",
            "[Epoch 189/200] [Batch 250/938] loss_G: 3.387107, loss_D: 0.170331\n",
            "[Epoch 189/200] [Batch 260/938] loss_G: 3.525288, loss_D: 0.211716\n",
            "[Epoch 189/200] [Batch 270/938] loss_G: 3.679928, loss_D: 0.156873\n",
            "[Epoch 189/200] [Batch 280/938] loss_G: 3.344786, loss_D: 0.161996\n",
            "[Epoch 189/200] [Batch 290/938] loss_G: 3.119597, loss_D: 0.289576\n",
            "[Epoch 189/200] [Batch 300/938] loss_G: 3.289231, loss_D: 0.205388\n",
            "[Epoch 189/200] [Batch 310/938] loss_G: 3.431115, loss_D: 0.222511\n",
            "[Epoch 189/200] [Batch 320/938] loss_G: 3.043237, loss_D: 0.241978\n",
            "[Epoch 189/200] [Batch 330/938] loss_G: 3.340588, loss_D: 0.173517\n",
            "[Epoch 189/200] [Batch 340/938] loss_G: 3.492116, loss_D: 0.153234\n",
            "[Epoch 189/200] [Batch 350/938] loss_G: 3.410304, loss_D: 0.187773\n",
            "[Epoch 189/200] [Batch 360/938] loss_G: 3.158619, loss_D: 0.214161\n",
            "[Epoch 189/200] [Batch 370/938] loss_G: 3.360161, loss_D: 0.208236\n",
            "[Epoch 189/200] [Batch 380/938] loss_G: 3.194478, loss_D: 0.204247\n",
            "[Epoch 189/200] [Batch 390/938] loss_G: 3.273697, loss_D: 0.197503\n",
            "[Epoch 189/200] [Batch 400/938] loss_G: 3.377374, loss_D: 0.190902\n",
            "[Epoch 189/200] [Batch 410/938] loss_G: 3.573131, loss_D: 0.176632\n",
            "[Epoch 189/200] [Batch 420/938] loss_G: 3.050916, loss_D: 0.223671\n",
            "[Epoch 189/200] [Batch 430/938] loss_G: 3.078343, loss_D: 0.197496\n",
            "[Epoch 189/200] [Batch 440/938] loss_G: 3.431410, loss_D: 0.178879\n",
            "[Epoch 189/200] [Batch 450/938] loss_G: 2.792369, loss_D: 0.286393\n",
            "[Epoch 189/200] [Batch 460/938] loss_G: 3.195803, loss_D: 0.204934\n",
            "[Epoch 189/200] [Batch 470/938] loss_G: 3.606315, loss_D: 0.152958\n",
            "[Epoch 189/200] [Batch 480/938] loss_G: 3.193779, loss_D: 0.221267\n",
            "[Epoch 189/200] [Batch 490/938] loss_G: 3.197392, loss_D: 0.165670\n",
            "[Epoch 189/200] [Batch 500/938] loss_G: 3.149798, loss_D: 0.252032\n",
            "[Epoch 189/200] [Batch 510/938] loss_G: 3.083503, loss_D: 0.222796\n",
            "[Epoch 189/200] [Batch 520/938] loss_G: 2.952249, loss_D: 0.166607\n",
            "[Epoch 189/200] [Batch 530/938] loss_G: 2.955293, loss_D: 0.281233\n",
            "[Epoch 189/200] [Batch 540/938] loss_G: 3.066572, loss_D: 0.394763\n",
            "[Epoch 189/200] [Batch 550/938] loss_G: 3.266068, loss_D: 0.266170\n",
            "[Epoch 189/200] [Batch 560/938] loss_G: 2.984237, loss_D: 0.210391\n",
            "[Epoch 189/200] [Batch 570/938] loss_G: 3.504650, loss_D: 0.118905\n",
            "[Epoch 189/200] [Batch 580/938] loss_G: 3.220577, loss_D: 0.190409\n",
            "[Epoch 189/200] [Batch 590/938] loss_G: 3.165448, loss_D: 0.313153\n",
            "[Epoch 189/200] [Batch 600/938] loss_G: 3.072785, loss_D: 0.179051\n",
            "[Epoch 189/200] [Batch 610/938] loss_G: 3.437384, loss_D: 0.135407\n",
            "[Epoch 189/200] [Batch 620/938] loss_G: 2.858791, loss_D: 0.208593\n",
            "[Epoch 189/200] [Batch 630/938] loss_G: 3.134586, loss_D: 0.154124\n",
            "[Epoch 189/200] [Batch 640/938] loss_G: 3.093124, loss_D: 0.207048\n",
            "[Epoch 189/200] [Batch 650/938] loss_G: 3.455642, loss_D: 0.197047\n",
            "[Epoch 189/200] [Batch 660/938] loss_G: 3.271189, loss_D: 0.194764\n",
            "[Epoch 189/200] [Batch 670/938] loss_G: 3.493179, loss_D: 0.228566\n",
            "[Epoch 189/200] [Batch 680/938] loss_G: 2.800638, loss_D: 0.246000\n",
            "[Epoch 189/200] [Batch 690/938] loss_G: 3.495234, loss_D: 0.228076\n",
            "[Epoch 189/200] [Batch 700/938] loss_G: 3.280223, loss_D: 0.166864\n",
            "[Epoch 189/200] [Batch 710/938] loss_G: 2.854285, loss_D: 0.258016\n",
            "[Epoch 189/200] [Batch 720/938] loss_G: 2.997998, loss_D: 0.216268\n",
            "[Epoch 189/200] [Batch 730/938] loss_G: 3.173789, loss_D: 0.290236\n",
            "[Epoch 189/200] [Batch 740/938] loss_G: 3.297709, loss_D: 0.183573\n",
            "[Epoch 189/200] [Batch 750/938] loss_G: 3.142206, loss_D: 0.270191\n",
            "[Epoch 189/200] [Batch 760/938] loss_G: 3.461152, loss_D: 0.144933\n",
            "[Epoch 189/200] [Batch 770/938] loss_G: 3.162660, loss_D: 0.235144\n",
            "[Epoch 189/200] [Batch 780/938] loss_G: 2.961246, loss_D: 0.200692\n",
            "[Epoch 189/200] [Batch 790/938] loss_G: 2.608683, loss_D: 0.201420\n",
            "[Epoch 189/200] [Batch 800/938] loss_G: 3.577586, loss_D: 0.270189\n",
            "[Epoch 189/200] [Batch 810/938] loss_G: 2.778160, loss_D: 0.156144\n",
            "[Epoch 189/200] [Batch 820/938] loss_G: 3.242574, loss_D: 0.190241\n",
            "[Epoch 189/200] [Batch 830/938] loss_G: 3.451209, loss_D: 0.156102\n",
            "[Epoch 189/200] [Batch 840/938] loss_G: 3.146154, loss_D: 0.131523\n",
            "[Epoch 189/200] [Batch 850/938] loss_G: 3.018953, loss_D: 0.154490\n",
            "[Epoch 189/200] [Batch 860/938] loss_G: 3.007634, loss_D: 0.122609\n",
            "[Epoch 189/200] [Batch 870/938] loss_G: 2.964369, loss_D: 0.201992\n",
            "[Epoch 189/200] [Batch 880/938] loss_G: 3.013395, loss_D: 0.212181\n",
            "[Epoch 189/200] [Batch 890/938] loss_G: 3.235024, loss_D: 0.193853\n",
            "[Epoch 189/200] [Batch 900/938] loss_G: 2.895715, loss_D: 0.239563\n",
            "[Epoch 189/200] [Batch 910/938] loss_G: 3.214712, loss_D: 0.125000\n",
            "[Epoch 189/200] [Batch 920/938] loss_G: 3.165004, loss_D: 0.184847\n",
            "[Epoch 189/200] [Batch 930/938] loss_G: 3.521713, loss_D: 0.244725\n",
            "[Epoch 190/200] [Batch 0/938] loss_G: 3.161763, loss_D: 0.212102\n",
            "[Epoch 190/200] [Batch 10/938] loss_G: 2.971355, loss_D: 0.148779\n",
            "[Epoch 190/200] [Batch 20/938] loss_G: 3.194531, loss_D: 0.138240\n",
            "[Epoch 190/200] [Batch 30/938] loss_G: 3.359132, loss_D: 0.257283\n",
            "[Epoch 190/200] [Batch 40/938] loss_G: 3.365808, loss_D: 0.246376\n",
            "[Epoch 190/200] [Batch 50/938] loss_G: 3.576751, loss_D: 0.235960\n",
            "[Epoch 190/200] [Batch 60/938] loss_G: 3.071172, loss_D: 0.170879\n",
            "[Epoch 190/200] [Batch 70/938] loss_G: 3.274460, loss_D: 0.174809\n",
            "[Epoch 190/200] [Batch 80/938] loss_G: 3.347894, loss_D: 0.361951\n",
            "[Epoch 190/200] [Batch 90/938] loss_G: 3.554002, loss_D: 0.227516\n",
            "[Epoch 190/200] [Batch 100/938] loss_G: 3.479300, loss_D: 0.204704\n",
            "[Epoch 190/200] [Batch 110/938] loss_G: 3.427969, loss_D: 0.185605\n",
            "[Epoch 190/200] [Batch 120/938] loss_G: 2.821633, loss_D: 0.318838\n",
            "[Epoch 190/200] [Batch 130/938] loss_G: 3.126116, loss_D: 0.236964\n",
            "[Epoch 190/200] [Batch 140/938] loss_G: 3.716640, loss_D: 0.141906\n",
            "[Epoch 190/200] [Batch 150/938] loss_G: 3.043207, loss_D: 0.187345\n",
            "[Epoch 190/200] [Batch 160/938] loss_G: 3.109447, loss_D: 0.139701\n",
            "[Epoch 190/200] [Batch 170/938] loss_G: 3.696923, loss_D: 0.243621\n",
            "[Epoch 190/200] [Batch 180/938] loss_G: 3.205035, loss_D: 0.144460\n",
            "[Epoch 190/200] [Batch 190/938] loss_G: 3.934151, loss_D: 0.216334\n",
            "[Epoch 190/200] [Batch 200/938] loss_G: 2.870106, loss_D: 0.212331\n",
            "[Epoch 190/200] [Batch 210/938] loss_G: 3.515143, loss_D: 0.269640\n",
            "[Epoch 190/200] [Batch 220/938] loss_G: 3.178947, loss_D: 0.218423\n",
            "[Epoch 190/200] [Batch 230/938] loss_G: 3.061691, loss_D: 0.130251\n",
            "[Epoch 190/200] [Batch 240/938] loss_G: 3.685915, loss_D: 0.133475\n",
            "[Epoch 190/200] [Batch 250/938] loss_G: 3.439987, loss_D: 0.243133\n",
            "[Epoch 190/200] [Batch 260/938] loss_G: 2.878984, loss_D: 0.122392\n",
            "[Epoch 190/200] [Batch 270/938] loss_G: 3.422073, loss_D: 0.278867\n",
            "[Epoch 190/200] [Batch 280/938] loss_G: 3.219214, loss_D: 0.266497\n",
            "[Epoch 190/200] [Batch 290/938] loss_G: 3.223947, loss_D: 0.161910\n",
            "[Epoch 190/200] [Batch 300/938] loss_G: 3.117479, loss_D: 0.226447\n",
            "[Epoch 190/200] [Batch 310/938] loss_G: 2.970756, loss_D: 0.160557\n",
            "[Epoch 190/200] [Batch 320/938] loss_G: 3.398145, loss_D: 0.238459\n",
            "[Epoch 190/200] [Batch 330/938] loss_G: 3.405187, loss_D: 0.169864\n",
            "[Epoch 190/200] [Batch 340/938] loss_G: 3.224285, loss_D: 0.213894\n",
            "[Epoch 190/200] [Batch 350/938] loss_G: 3.369695, loss_D: 0.156424\n",
            "[Epoch 190/200] [Batch 360/938] loss_G: 3.373333, loss_D: 0.162634\n",
            "[Epoch 190/200] [Batch 370/938] loss_G: 3.148742, loss_D: 0.278370\n",
            "[Epoch 190/200] [Batch 380/938] loss_G: 3.490722, loss_D: 0.237401\n",
            "[Epoch 190/200] [Batch 390/938] loss_G: 3.278684, loss_D: 0.179610\n",
            "[Epoch 190/200] [Batch 400/938] loss_G: 3.361306, loss_D: 0.145883\n",
            "[Epoch 190/200] [Batch 410/938] loss_G: 2.900451, loss_D: 0.241110\n",
            "[Epoch 190/200] [Batch 420/938] loss_G: 4.170749, loss_D: 0.214767\n",
            "[Epoch 190/200] [Batch 430/938] loss_G: 2.934772, loss_D: 0.256395\n",
            "[Epoch 190/200] [Batch 440/938] loss_G: 3.396866, loss_D: 0.218049\n",
            "[Epoch 190/200] [Batch 450/938] loss_G: 3.183967, loss_D: 0.161406\n",
            "[Epoch 190/200] [Batch 460/938] loss_G: 3.104041, loss_D: 0.299190\n",
            "[Epoch 190/200] [Batch 470/938] loss_G: 3.382127, loss_D: 0.209365\n",
            "[Epoch 190/200] [Batch 480/938] loss_G: 3.300885, loss_D: 0.134516\n",
            "[Epoch 190/200] [Batch 490/938] loss_G: 3.356343, loss_D: 0.156560\n",
            "[Epoch 190/200] [Batch 500/938] loss_G: 3.192629, loss_D: 0.221612\n",
            "[Epoch 190/200] [Batch 510/938] loss_G: 3.303802, loss_D: 0.142113\n",
            "[Epoch 190/200] [Batch 520/938] loss_G: 3.265343, loss_D: 0.206126\n",
            "[Epoch 190/200] [Batch 530/938] loss_G: 2.929161, loss_D: 0.237287\n",
            "[Epoch 190/200] [Batch 540/938] loss_G: 2.748116, loss_D: 0.215837\n",
            "[Epoch 190/200] [Batch 550/938] loss_G: 2.742057, loss_D: 0.202309\n",
            "[Epoch 190/200] [Batch 560/938] loss_G: 3.118134, loss_D: 0.238180\n",
            "[Epoch 190/200] [Batch 570/938] loss_G: 3.351692, loss_D: 0.163005\n",
            "[Epoch 190/200] [Batch 580/938] loss_G: 3.231818, loss_D: 0.132941\n",
            "[Epoch 190/200] [Batch 590/938] loss_G: 3.257782, loss_D: 0.151658\n",
            "[Epoch 190/200] [Batch 600/938] loss_G: 3.600874, loss_D: 0.243065\n",
            "[Epoch 190/200] [Batch 610/938] loss_G: 3.287004, loss_D: 0.190283\n",
            "[Epoch 190/200] [Batch 620/938] loss_G: 3.193192, loss_D: 0.251069\n",
            "[Epoch 190/200] [Batch 630/938] loss_G: 2.741366, loss_D: 0.201581\n",
            "[Epoch 190/200] [Batch 640/938] loss_G: 3.051800, loss_D: 0.189655\n",
            "[Epoch 190/200] [Batch 650/938] loss_G: 3.136065, loss_D: 0.142340\n",
            "[Epoch 190/200] [Batch 660/938] loss_G: 3.102287, loss_D: 0.154588\n",
            "[Epoch 190/200] [Batch 670/938] loss_G: 3.293138, loss_D: 0.166260\n",
            "[Epoch 190/200] [Batch 680/938] loss_G: 3.314727, loss_D: 0.211304\n",
            "[Epoch 190/200] [Batch 690/938] loss_G: 3.083734, loss_D: 0.261423\n",
            "[Epoch 190/200] [Batch 700/938] loss_G: 3.052999, loss_D: 0.181549\n",
            "[Epoch 190/200] [Batch 710/938] loss_G: 3.131870, loss_D: 0.258969\n",
            "[Epoch 190/200] [Batch 720/938] loss_G: 3.063705, loss_D: 0.121548\n",
            "[Epoch 190/200] [Batch 730/938] loss_G: 3.236321, loss_D: 0.214936\n",
            "[Epoch 190/200] [Batch 740/938] loss_G: 2.888248, loss_D: 0.182286\n",
            "[Epoch 190/200] [Batch 750/938] loss_G: 3.382952, loss_D: 0.228054\n",
            "[Epoch 190/200] [Batch 760/938] loss_G: 3.066214, loss_D: 0.231425\n",
            "[Epoch 190/200] [Batch 770/938] loss_G: 2.991278, loss_D: 0.302653\n",
            "[Epoch 190/200] [Batch 780/938] loss_G: 3.331770, loss_D: 0.181337\n",
            "[Epoch 190/200] [Batch 790/938] loss_G: 2.983440, loss_D: 0.211698\n",
            "[Epoch 190/200] [Batch 800/938] loss_G: 2.966974, loss_D: 0.255449\n",
            "[Epoch 190/200] [Batch 810/938] loss_G: 3.646395, loss_D: 0.173447\n",
            "[Epoch 190/200] [Batch 820/938] loss_G: 3.308850, loss_D: 0.145261\n",
            "[Epoch 190/200] [Batch 830/938] loss_G: 3.218879, loss_D: 0.201496\n",
            "[Epoch 190/200] [Batch 840/938] loss_G: 3.242885, loss_D: 0.202503\n",
            "[Epoch 190/200] [Batch 850/938] loss_G: 3.027571, loss_D: 0.218877\n",
            "[Epoch 190/200] [Batch 860/938] loss_G: 3.085241, loss_D: 0.199909\n",
            "[Epoch 190/200] [Batch 870/938] loss_G: 3.078465, loss_D: 0.168665\n",
            "[Epoch 190/200] [Batch 880/938] loss_G: 3.194746, loss_D: 0.174328\n",
            "[Epoch 190/200] [Batch 890/938] loss_G: 2.981222, loss_D: 0.160021\n",
            "[Epoch 190/200] [Batch 900/938] loss_G: 2.986098, loss_D: 0.214559\n",
            "[Epoch 190/200] [Batch 910/938] loss_G: 3.123168, loss_D: 0.194944\n",
            "[Epoch 190/200] [Batch 920/938] loss_G: 3.217177, loss_D: 0.194595\n",
            "[Epoch 190/200] [Batch 930/938] loss_G: 3.410388, loss_D: 0.148393\n",
            "[Epoch 191/200] [Batch 0/938] loss_G: 3.220628, loss_D: 0.282811\n",
            "[Epoch 191/200] [Batch 10/938] loss_G: 3.063350, loss_D: 0.187086\n",
            "[Epoch 191/200] [Batch 20/938] loss_G: 3.130197, loss_D: 0.213059\n",
            "[Epoch 191/200] [Batch 30/938] loss_G: 3.265525, loss_D: 0.278477\n",
            "[Epoch 191/200] [Batch 40/938] loss_G: 3.072682, loss_D: 0.223290\n",
            "[Epoch 191/200] [Batch 50/938] loss_G: 3.022177, loss_D: 0.171101\n",
            "[Epoch 191/200] [Batch 60/938] loss_G: 3.198969, loss_D: 0.204713\n",
            "[Epoch 191/200] [Batch 70/938] loss_G: 2.866454, loss_D: 0.195884\n",
            "[Epoch 191/200] [Batch 80/938] loss_G: 3.103917, loss_D: 0.201039\n",
            "[Epoch 191/200] [Batch 90/938] loss_G: 3.082753, loss_D: 0.247843\n",
            "[Epoch 191/200] [Batch 100/938] loss_G: 2.844052, loss_D: 0.270021\n",
            "[Epoch 191/200] [Batch 110/938] loss_G: 3.189502, loss_D: 0.159893\n",
            "[Epoch 191/200] [Batch 120/938] loss_G: 3.080276, loss_D: 0.171956\n",
            "[Epoch 191/200] [Batch 130/938] loss_G: 3.095395, loss_D: 0.163642\n",
            "[Epoch 191/200] [Batch 140/938] loss_G: 2.730034, loss_D: 0.158603\n",
            "[Epoch 191/200] [Batch 150/938] loss_G: 3.282833, loss_D: 0.237827\n",
            "[Epoch 191/200] [Batch 160/938] loss_G: 3.669986, loss_D: 0.185710\n",
            "[Epoch 191/200] [Batch 170/938] loss_G: 2.978327, loss_D: 0.247393\n",
            "[Epoch 191/200] [Batch 180/938] loss_G: 2.649656, loss_D: 0.216148\n",
            "[Epoch 191/200] [Batch 190/938] loss_G: 3.161943, loss_D: 0.217685\n",
            "[Epoch 191/200] [Batch 200/938] loss_G: 2.960099, loss_D: 0.197717\n",
            "[Epoch 191/200] [Batch 210/938] loss_G: 3.333122, loss_D: 0.153784\n",
            "[Epoch 191/200] [Batch 220/938] loss_G: 2.932876, loss_D: 0.119017\n",
            "[Epoch 191/200] [Batch 230/938] loss_G: 2.878634, loss_D: 0.283538\n",
            "[Epoch 191/200] [Batch 240/938] loss_G: 3.008520, loss_D: 0.197083\n",
            "[Epoch 191/200] [Batch 250/938] loss_G: 3.075125, loss_D: 0.258150\n",
            "[Epoch 191/200] [Batch 260/938] loss_G: 3.191013, loss_D: 0.188791\n",
            "[Epoch 191/200] [Batch 270/938] loss_G: 3.025070, loss_D: 0.210961\n",
            "[Epoch 191/200] [Batch 280/938] loss_G: 2.578924, loss_D: 0.211908\n",
            "[Epoch 191/200] [Batch 290/938] loss_G: 2.752431, loss_D: 0.200104\n",
            "[Epoch 191/200] [Batch 300/938] loss_G: 3.011245, loss_D: 0.212149\n",
            "[Epoch 191/200] [Batch 310/938] loss_G: 3.214175, loss_D: 0.219912\n",
            "[Epoch 191/200] [Batch 320/938] loss_G: 3.282492, loss_D: 0.265917\n",
            "[Epoch 191/200] [Batch 330/938] loss_G: 3.452031, loss_D: 0.156757\n",
            "[Epoch 191/200] [Batch 340/938] loss_G: 3.502627, loss_D: 0.198306\n",
            "[Epoch 191/200] [Batch 350/938] loss_G: 3.578253, loss_D: 0.127315\n",
            "[Epoch 191/200] [Batch 360/938] loss_G: 3.277007, loss_D: 0.227943\n",
            "[Epoch 191/200] [Batch 370/938] loss_G: 3.477507, loss_D: 0.149892\n",
            "[Epoch 191/200] [Batch 380/938] loss_G: 2.907004, loss_D: 0.214009\n",
            "[Epoch 191/200] [Batch 390/938] loss_G: 3.361336, loss_D: 0.298938\n",
            "[Epoch 191/200] [Batch 400/938] loss_G: 3.386487, loss_D: 0.182550\n",
            "[Epoch 191/200] [Batch 410/938] loss_G: 2.802652, loss_D: 0.214220\n",
            "[Epoch 191/200] [Batch 420/938] loss_G: 3.296511, loss_D: 0.234676\n",
            "[Epoch 191/200] [Batch 430/938] loss_G: 3.183752, loss_D: 0.179406\n",
            "[Epoch 191/200] [Batch 440/938] loss_G: 3.258899, loss_D: 0.212998\n",
            "[Epoch 191/200] [Batch 450/938] loss_G: 2.998478, loss_D: 0.167557\n",
            "[Epoch 191/200] [Batch 460/938] loss_G: 3.191157, loss_D: 0.146248\n",
            "[Epoch 191/200] [Batch 470/938] loss_G: 3.354700, loss_D: 0.265926\n",
            "[Epoch 191/200] [Batch 480/938] loss_G: 3.397451, loss_D: 0.316786\n",
            "[Epoch 191/200] [Batch 490/938] loss_G: 3.102318, loss_D: 0.166234\n",
            "[Epoch 191/200] [Batch 500/938] loss_G: 3.017946, loss_D: 0.193373\n",
            "[Epoch 191/200] [Batch 510/938] loss_G: 3.224545, loss_D: 0.236102\n",
            "[Epoch 191/200] [Batch 520/938] loss_G: 3.060297, loss_D: 0.194897\n",
            "[Epoch 191/200] [Batch 530/938] loss_G: 3.218294, loss_D: 0.212511\n",
            "[Epoch 191/200] [Batch 540/938] loss_G: 2.961346, loss_D: 0.160356\n",
            "[Epoch 191/200] [Batch 550/938] loss_G: 3.621899, loss_D: 0.198698\n",
            "[Epoch 191/200] [Batch 560/938] loss_G: 3.037536, loss_D: 0.250326\n",
            "[Epoch 191/200] [Batch 570/938] loss_G: 3.167032, loss_D: 0.143209\n",
            "[Epoch 191/200] [Batch 580/938] loss_G: 3.268524, loss_D: 0.184535\n",
            "[Epoch 191/200] [Batch 590/938] loss_G: 2.928143, loss_D: 0.243512\n",
            "[Epoch 191/200] [Batch 600/938] loss_G: 3.060121, loss_D: 0.287443\n",
            "[Epoch 191/200] [Batch 610/938] loss_G: 3.313166, loss_D: 0.203408\n",
            "[Epoch 191/200] [Batch 620/938] loss_G: 3.210035, loss_D: 0.119811\n",
            "[Epoch 191/200] [Batch 630/938] loss_G: 2.949360, loss_D: 0.269303\n",
            "[Epoch 191/200] [Batch 640/938] loss_G: 3.291019, loss_D: 0.221014\n",
            "[Epoch 191/200] [Batch 650/938] loss_G: 3.402817, loss_D: 0.139506\n",
            "[Epoch 191/200] [Batch 660/938] loss_G: 3.455335, loss_D: 0.167779\n",
            "[Epoch 191/200] [Batch 670/938] loss_G: 3.038848, loss_D: 0.224014\n",
            "[Epoch 191/200] [Batch 680/938] loss_G: 3.248398, loss_D: 0.147026\n",
            "[Epoch 191/200] [Batch 690/938] loss_G: 3.223135, loss_D: 0.198354\n",
            "[Epoch 191/200] [Batch 700/938] loss_G: 2.916681, loss_D: 0.220992\n",
            "[Epoch 191/200] [Batch 710/938] loss_G: 3.113631, loss_D: 0.179242\n",
            "[Epoch 191/200] [Batch 720/938] loss_G: 3.248542, loss_D: 0.225974"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-bcac516b9422>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Print progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midx_batch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         print(\"[Epoch {}/{}] [Batch {}/{}] loss_G: {:.6f}, loss_D: {:.6f}\".format(idx_epoch, num_epochs,\n\u001b[0m\u001b[1;32m     35\u001b[0m                                                                                   \u001b[0midx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                                                                   loss_G, loss_D))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "새롭게 알게된 점:\n",
        "- loss function의 구현을 BCELoss로 하는 것, 실제 loss는 따로 명시를 안한다는 점"
      ],
      "metadata": {
        "id": "l6Lv1icSm8hD"
      }
    }
  ]
}