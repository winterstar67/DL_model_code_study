# GPT implementation

이 코드 구현은 Andrej Karpathy님의 코드(https://www.youtube.com/watch?v=kCc8FmEb1nY)가 출처임을 밝힙니다.

구현 후기:
GPT 구현에 매우 좋은 영상이라고 생각한다.
1. 일단 Transformer 논문 자체와 유사하게 코드를 작성해주신다.
2. Step by step으로 원리 하나하나를 자세히 설명해주셔서 이해도 잘 되고 코드가 왜 이러한 과정으로 짜이는 것인지 받아들이기 쉬운 편인 것 같다.
3. Attention is all you need에서 언급되지 않은 Pre-norm과 Post-norm의 개념에 대해서 언급해주신다.

전체적으로, GPT 구현에 관심이 있다면 꼭 봐두면 좋을 영상인 것 같다.
